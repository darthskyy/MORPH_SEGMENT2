INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: train - ['data/ndebele/ndebele.train']
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: dev - ['data/ndebele/ndebele.dev']
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: test - ['data/ndebele/ndebele.test']
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.3/ndebele'
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: init - 'init/test/large/seed-0/ndebele'
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: dropout - 0.3
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 00:56:46 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 00:56:46 - 0:00:00 - src vocab size 68
INFO - 10/17/22 00:56:46 - 0:00:00 - trg vocab size 66
INFO - 10/17/22 00:56:46 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 00:56:46 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', "'", '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 00:56:46 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(68, 100, padding_idx=0)
                                       (trg_embed): Embedding(66, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.3, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.3, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.3, inplace=False)
                                     )
INFO - 10/17/22 00:56:46 - 0:00:00 - number of parameter 1218666
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: train - ['data/ndebele/ndebele.train']
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: dev - ['data/ndebele/ndebele.dev']
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: test - ['data/ndebele/ndebele.test']
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.3/ndebele'
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: init - 'init/test/large/seed-0/ndebele/small'
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: dropout - 0.3
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 02:33:49 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 02:33:49 - 0:00:00 - src vocab size 68
INFO - 10/17/22 02:33:49 - 0:00:00 - trg vocab size 66
INFO - 10/17/22 02:33:49 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:33:49 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', "'", '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:33:49 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(68, 100, padding_idx=0)
                                       (trg_embed): Embedding(66, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.3, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.3, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.3, inplace=False)
                                     )
INFO - 10/17/22 02:33:49 - 0:00:00 - number of parameter 1218666
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: train - ['data/ndebele/ndebele.train']
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: dev - ['data/ndebele/ndebele.dev']
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: test - ['data/ndebele/ndebele.test']
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.3/ndebele'
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: init - ''
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: dropout - 0.3
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 06:16:13 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 06:16:14 - 0:00:00 - src vocab size 68
INFO - 10/17/22 06:16:14 - 0:00:00 - trg vocab size 66
INFO - 10/17/22 06:16:14 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 06:16:14 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', "'", '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 06:16:14 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(68, 100, padding_idx=0)
                                       (trg_embed): Embedding(66, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.3, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.3, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.3, inplace=False)
                                     )
INFO - 10/17/22 06:16:14 - 0:00:00 - number of parameter 1218666
INFO - 10/17/22 06:16:16 - 0:00:03 - maximum training 32350 steps (50 epochs)
INFO - 10/17/22 06:16:16 - 0:00:03 - evaluate every 1 epochs
INFO - 10/17/22 06:16:16 - 0:00:03 - At 0-th epoch with lr 0.001000.
INFO - 10/17/22 06:16:34 - 0:00:21 - Running average train loss is 0.5192007639631053 at epoch 0
INFO - 10/17/22 06:16:34 - 0:00:21 - At 1-th epoch with lr 0.001000.
INFO - 10/17/22 06:16:52 - 0:00:38 - Running average train loss is 0.1713514291037916 at epoch 1
INFO - 10/17/22 06:16:52 - 0:00:39 - Average dev loss is 0.13359928583869568 at epoch 1
INFO - 10/17/22 06:16:53 - 0:00:40 - dev accuracy is 52.3381 at epoch 1
INFO - 10/17/22 06:16:53 - 0:00:40 - dev phenome error rate is 0.1022 at epoch 1
INFO - 10/17/22 06:16:53 - 0:00:40 - At 2-th epoch with lr 0.001000.
INFO - 10/17/22 06:17:11 - 0:00:57 - Running average train loss is 0.12730718817176093 at epoch 2
INFO - 10/17/22 06:17:11 - 0:00:58 - Average dev loss is 0.09524969005813966 at epoch 2
INFO - 10/17/22 06:17:12 - 0:00:59 - dev accuracy is 65.1079 at epoch 2
INFO - 10/17/22 06:17:12 - 0:00:59 - dev phenome error rate is 0.0636 at epoch 2
INFO - 10/17/22 06:17:12 - 0:00:59 - At 3-th epoch with lr 0.001000.
INFO - 10/17/22 06:17:30 - 0:01:16 - Running average train loss is 0.10120961150381905 at epoch 3
INFO - 10/17/22 06:17:30 - 0:01:17 - Average dev loss is 0.07836612133452525 at epoch 3
INFO - 10/17/22 06:17:31 - 0:01:18 - dev accuracy is 70.6835 at epoch 3
INFO - 10/17/22 06:17:31 - 0:01:18 - dev phenome error rate is 0.0636 at epoch 3
INFO - 10/17/22 06:17:31 - 0:01:18 - At 4-th epoch with lr 0.001000.
INFO - 10/17/22 06:17:49 - 0:01:35 - Running average train loss is 0.08547953658462308 at epoch 4
INFO - 10/17/22 06:17:49 - 0:01:36 - Average dev loss is 0.07274565444542812 at epoch 4
INFO - 10/17/22 06:17:50 - 0:01:37 - dev accuracy is 72.482 at epoch 4
INFO - 10/17/22 06:17:50 - 0:01:37 - dev phenome error rate is 0.0478 at epoch 4
INFO - 10/17/22 06:17:50 - 0:01:37 - At 5-th epoch with lr 0.001000.
INFO - 10/17/22 06:18:08 - 0:01:54 - Running average train loss is 0.07703051471239218 at epoch 5
INFO - 10/17/22 06:18:08 - 0:01:55 - Average dev loss is 0.0642588438322911 at epoch 5
INFO - 10/17/22 06:18:09 - 0:01:56 - dev accuracy is 75.0 at epoch 5
INFO - 10/17/22 06:18:09 - 0:01:56 - dev phenome error rate is 0.039 at epoch 5
INFO - 10/17/22 06:18:09 - 0:01:56 - At 6-th epoch with lr 0.001000.
INFO - 10/17/22 06:18:27 - 0:02:13 - Running average train loss is 0.06680413708522616 at epoch 6
INFO - 10/17/22 06:18:27 - 0:02:14 - Average dev loss is 0.05785541577407947 at epoch 6
INFO - 10/17/22 06:18:28 - 0:02:15 - dev accuracy is 77.6079 at epoch 6
INFO - 10/17/22 06:18:28 - 0:02:15 - dev phenome error rate is 0.0335 at epoch 6
INFO - 10/17/22 06:18:28 - 0:02:15 - At 7-th epoch with lr 0.001000.
INFO - 10/17/22 06:18:46 - 0:02:32 - Running average train loss is 0.06123816899068573 at epoch 7
INFO - 10/17/22 06:18:46 - 0:02:33 - Average dev loss is 0.050294899840194446 at epoch 7
INFO - 10/17/22 06:18:47 - 0:02:34 - dev accuracy is 79.0468 at epoch 7
INFO - 10/17/22 06:18:47 - 0:02:34 - dev phenome error rate is 0.03 at epoch 7
INFO - 10/17/22 06:18:47 - 0:02:34 - At 8-th epoch with lr 0.001000.
INFO - 10/17/22 06:19:05 - 0:02:51 - Running average train loss is 0.05716535832208957 at epoch 8
INFO - 10/17/22 06:19:05 - 0:02:52 - Average dev loss is 0.04863874084101273 at epoch 8
INFO - 10/17/22 06:19:06 - 0:02:53 - dev accuracy is 78.9568 at epoch 8
INFO - 10/17/22 06:19:06 - 0:02:53 - dev phenome error rate is 0.032 at epoch 8
INFO - 10/17/22 06:19:06 - 0:02:53 - At 9-th epoch with lr 0.001000.
INFO - 10/17/22 06:19:24 - 0:03:10 - Running average train loss is 0.05308535850896188 at epoch 9
INFO - 10/17/22 06:19:24 - 0:03:11 - Average dev loss is 0.04918299352463621 at epoch 9
INFO - 10/17/22 06:19:25 - 0:03:12 - dev accuracy is 80.8453 at epoch 9
INFO - 10/17/22 06:19:25 - 0:03:12 - dev phenome error rate is 0.0276 at epoch 9
INFO - 10/17/22 06:19:25 - 0:03:12 - At 10-th epoch with lr 0.000500.
INFO - 10/17/22 06:19:43 - 0:03:29 - Running average train loss is 0.037916032780952166 at epoch 10
INFO - 10/17/22 06:19:43 - 0:03:30 - Average dev loss is 0.036276558901254946 at epoch 10
INFO - 10/17/22 06:19:44 - 0:03:31 - dev accuracy is 85.0719 at epoch 10
INFO - 10/17/22 06:19:44 - 0:03:31 - dev phenome error rate is 0.02 at epoch 10
INFO - 10/17/22 06:19:44 - 0:03:31 - At 11-th epoch with lr 0.000500.
INFO - 10/17/22 06:20:02 - 0:03:48 - Running average train loss is 0.03166472612789485 at epoch 11
INFO - 10/17/22 06:20:02 - 0:03:49 - Average dev loss is 0.03273664749800586 at epoch 11
INFO - 10/17/22 06:20:03 - 0:03:50 - dev accuracy is 86.1511 at epoch 11
INFO - 10/17/22 06:20:03 - 0:03:50 - dev phenome error rate is 0.0174 at epoch 11
INFO - 10/17/22 06:20:03 - 0:03:50 - At 12-th epoch with lr 0.000500.
INFO - 10/17/22 06:20:21 - 0:04:08 - Running average train loss is 0.02916243910311593 at epoch 12
INFO - 10/17/22 06:20:22 - 0:04:08 - Average dev loss is 0.03329118890687823 at epoch 12
INFO - 10/17/22 06:20:23 - 0:04:09 - dev accuracy is 86.4209 at epoch 12
INFO - 10/17/22 06:20:23 - 0:04:09 - dev phenome error rate is 0.0159 at epoch 12
INFO - 10/17/22 06:20:23 - 0:04:09 - At 13-th epoch with lr 0.000250.
INFO - 10/17/22 06:20:40 - 0:04:27 - Running average train loss is 0.024826694116891698 at epoch 13
INFO - 10/17/22 06:20:41 - 0:04:27 - Average dev loss is 0.02725941906683147 at epoch 13
INFO - 10/17/22 06:20:42 - 0:04:28 - dev accuracy is 87.8597 at epoch 13
INFO - 10/17/22 06:20:42 - 0:04:28 - dev phenome error rate is 0.0143 at epoch 13
INFO - 10/17/22 06:20:42 - 0:04:28 - At 14-th epoch with lr 0.000250.
INFO - 10/17/22 06:20:59 - 0:04:46 - Running average train loss is 0.023507235509845813 at epoch 14
INFO - 10/17/22 06:21:00 - 0:04:46 - Average dev loss is 0.02597560697915749 at epoch 14
INFO - 10/17/22 06:21:01 - 0:04:47 - dev accuracy is 88.759 at epoch 14
INFO - 10/17/22 06:21:01 - 0:04:47 - dev phenome error rate is 0.013 at epoch 14
INFO - 10/17/22 06:21:01 - 0:04:47 - At 15-th epoch with lr 0.000250.
INFO - 10/17/22 06:21:18 - 0:05:05 - Running average train loss is 0.021326533235520286 at epoch 15
INFO - 10/17/22 06:21:19 - 0:05:05 - Average dev loss is 0.02553914974604805 at epoch 15
INFO - 10/17/22 06:21:20 - 0:05:06 - dev accuracy is 88.759 at epoch 15
INFO - 10/17/22 06:21:20 - 0:05:06 - dev phenome error rate is 0.0129 at epoch 15
INFO - 10/17/22 06:21:20 - 0:05:06 - At 16-th epoch with lr 0.000250.
INFO - 10/17/22 06:21:37 - 0:05:24 - Running average train loss is 0.020039759499490134 at epoch 16
INFO - 10/17/22 06:21:38 - 0:05:24 - Average dev loss is 0.024883816830025843 at epoch 16
INFO - 10/17/22 06:21:39 - 0:05:25 - dev accuracy is 88.759 at epoch 16
INFO - 10/17/22 06:21:39 - 0:05:25 - dev phenome error rate is 0.0124 at epoch 16
INFO - 10/17/22 06:21:39 - 0:05:26 - At 17-th epoch with lr 0.000250.
INFO - 10/17/22 06:21:57 - 0:05:43 - Running average train loss is 0.01946565927595758 at epoch 17
INFO - 10/17/22 06:21:57 - 0:05:44 - Average dev loss is 0.025244649408313516 at epoch 17
INFO - 10/17/22 06:21:58 - 0:05:45 - dev accuracy is 89.2986 at epoch 17
INFO - 10/17/22 06:21:58 - 0:05:45 - dev phenome error rate is 0.0114 at epoch 17
INFO - 10/17/22 06:21:58 - 0:05:45 - At 18-th epoch with lr 0.000125.
INFO - 10/17/22 06:22:16 - 0:06:02 - Running average train loss is 0.01848177418618001 at epoch 18
INFO - 10/17/22 06:22:16 - 0:06:03 - Average dev loss is 0.02136320758234853 at epoch 18
INFO - 10/17/22 06:22:17 - 0:06:04 - dev accuracy is 89.8381 at epoch 18
INFO - 10/17/22 06:22:17 - 0:06:04 - dev phenome error rate is 0.0108 at epoch 18
INFO - 10/17/22 06:22:17 - 0:06:04 - At 19-th epoch with lr 0.000125.
INFO - 10/17/22 06:22:35 - 0:06:21 - Running average train loss is 0.01680240773511662 at epoch 19
INFO - 10/17/22 06:22:35 - 0:06:22 - Average dev loss is 0.020264682275816227 at epoch 19
INFO - 10/17/22 06:22:36 - 0:06:23 - dev accuracy is 90.4676 at epoch 19
INFO - 10/17/22 06:22:36 - 0:06:23 - dev phenome error rate is 0.0104 at epoch 19
INFO - 10/17/22 06:22:36 - 0:06:23 - At 20-th epoch with lr 0.000125.
INFO - 10/17/22 06:22:54 - 0:06:40 - Running average train loss is 0.016789126420793752 at epoch 20
INFO - 10/17/22 06:22:54 - 0:06:41 - Average dev loss is 0.020899452490266413 at epoch 20
INFO - 10/17/22 06:22:55 - 0:06:42 - dev accuracy is 90.4676 at epoch 20
INFO - 10/17/22 06:22:55 - 0:06:42 - dev phenome error rate is 0.0103 at epoch 20
INFO - 10/17/22 06:22:55 - 0:06:42 - At 21-th epoch with lr 0.000063.
INFO - 10/17/22 06:23:13 - 0:06:59 - Running average train loss is 0.01621831862993288 at epoch 21
INFO - 10/17/22 06:23:13 - 0:07:00 - Average dev loss is 0.01933340566465631 at epoch 21
INFO - 10/17/22 06:23:14 - 0:07:01 - dev accuracy is 90.4676 at epoch 21
INFO - 10/17/22 06:23:14 - 0:07:01 - dev phenome error rate is 0.0103 at epoch 21
INFO - 10/17/22 06:23:14 - 0:07:01 - At 22-th epoch with lr 0.000063.
INFO - 10/17/22 06:23:32 - 0:07:18 - Running average train loss is 0.015672073347948873 at epoch 22
INFO - 10/17/22 06:23:32 - 0:07:19 - Average dev loss is 0.018642872438515323 at epoch 22
INFO - 10/17/22 06:23:33 - 0:07:20 - dev accuracy is 90.7374 at epoch 22
INFO - 10/17/22 06:23:33 - 0:07:20 - dev phenome error rate is 0.0102 at epoch 22
INFO - 10/17/22 06:23:33 - 0:07:20 - At 23-th epoch with lr 0.000063.
INFO - 10/17/22 06:23:51 - 0:07:37 - Running average train loss is 0.015293388274265093 at epoch 23
INFO - 10/17/22 06:23:51 - 0:07:38 - Average dev loss is 0.018537602826164894 at epoch 23
INFO - 10/17/22 06:23:52 - 0:07:39 - dev accuracy is 90.6475 at epoch 23
INFO - 10/17/22 06:23:52 - 0:07:39 - dev phenome error rate is 0.0103 at epoch 23
INFO - 10/17/22 06:23:52 - 0:07:39 - At 24-th epoch with lr 0.000063.
INFO - 10/17/22 06:24:10 - 0:07:56 - Running average train loss is 0.015583924006151073 at epoch 24
INFO - 10/17/22 06:24:10 - 0:07:57 - Average dev loss is 0.017987410785057223 at epoch 24
INFO - 10/17/22 06:24:11 - 0:07:58 - dev accuracy is 91.0971 at epoch 24
INFO - 10/17/22 06:24:11 - 0:07:58 - dev phenome error rate is 0.0096 at epoch 24
INFO - 10/17/22 06:24:11 - 0:07:58 - At 25-th epoch with lr 0.000063.
INFO - 10/17/22 06:24:29 - 0:08:15 - Running average train loss is 0.015113479373947799 at epoch 25
INFO - 10/17/22 06:24:29 - 0:08:16 - Average dev loss is 0.01765526110986964 at epoch 25
INFO - 10/17/22 06:24:30 - 0:08:17 - dev accuracy is 91.1871 at epoch 25
INFO - 10/17/22 06:24:30 - 0:08:17 - dev phenome error rate is 0.0097 at epoch 25
INFO - 10/17/22 06:24:31 - 0:08:17 - At 26-th epoch with lr 0.000063.
INFO - 10/17/22 06:24:48 - 0:08:34 - Running average train loss is 0.014768515322702883 at epoch 26
INFO - 10/17/22 06:24:48 - 0:08:35 - Average dev loss is 0.018308685416391548 at epoch 26
INFO - 10/17/22 06:24:49 - 0:08:36 - dev accuracy is 90.8273 at epoch 26
INFO - 10/17/22 06:24:49 - 0:08:36 - dev phenome error rate is 0.0099 at epoch 26
INFO - 10/17/22 06:24:49 - 0:08:36 - At 27-th epoch with lr 0.000031.
INFO - 10/17/22 06:25:06 - 0:08:53 - Running average train loss is 0.015442783674772202 at epoch 27
INFO - 10/17/22 06:25:07 - 0:08:53 - Average dev loss is 0.016432883691651603 at epoch 27
INFO - 10/17/22 06:25:08 - 0:08:54 - dev accuracy is 91.9065 at epoch 27
INFO - 10/17/22 06:25:08 - 0:08:54 - dev phenome error rate is 0.009 at epoch 27
INFO - 10/17/22 06:25:08 - 0:08:54 - At 28-th epoch with lr 0.000031.
INFO - 10/17/22 06:25:25 - 0:09:12 - Running average train loss is 0.01464494034594682 at epoch 28
INFO - 10/17/22 06:25:26 - 0:09:12 - Average dev loss is 0.016245989590131033 at epoch 28
INFO - 10/17/22 06:25:27 - 0:09:13 - dev accuracy is 91.9065 at epoch 28
INFO - 10/17/22 06:25:27 - 0:09:13 - dev phenome error rate is 0.0088 at epoch 28
INFO - 10/17/22 06:25:27 - 0:09:13 - At 29-th epoch with lr 0.000031.
INFO - 10/17/22 06:25:44 - 0:09:31 - Running average train loss is 0.014298779501830165 at epoch 29
INFO - 10/17/22 06:25:45 - 0:09:31 - Average dev loss is 0.015995909116015984 at epoch 29
INFO - 10/17/22 06:25:46 - 0:09:32 - dev accuracy is 91.9065 at epoch 29
INFO - 10/17/22 06:25:46 - 0:09:32 - dev phenome error rate is 0.009 at epoch 29
INFO - 10/17/22 06:25:46 - 0:09:32 - At 30-th epoch with lr 0.000031.
INFO - 10/17/22 06:26:03 - 0:09:50 - Running average train loss is 0.01446324170723995 at epoch 30
INFO - 10/17/22 06:26:04 - 0:09:50 - Average dev loss is 0.016237870032021488 at epoch 30
INFO - 10/17/22 06:26:05 - 0:09:51 - dev accuracy is 91.8165 at epoch 30
INFO - 10/17/22 06:26:05 - 0:09:51 - dev phenome error rate is 0.0092 at epoch 30
INFO - 10/17/22 06:26:05 - 0:09:51 - At 31-th epoch with lr 0.000016.
INFO - 10/17/22 06:26:22 - 0:10:09 - Running average train loss is 0.015221070435971967 at epoch 31
INFO - 10/17/22 06:26:23 - 0:10:09 - Average dev loss is 0.015013241878030105 at epoch 31
INFO - 10/17/22 06:26:24 - 0:10:10 - dev accuracy is 92.7158 at epoch 31
INFO - 10/17/22 06:26:24 - 0:10:10 - dev phenome error rate is 0.0087 at epoch 31
INFO - 10/17/22 06:26:24 - 0:10:10 - At 32-th epoch with lr 0.000016.
INFO - 10/17/22 06:26:41 - 0:10:28 - Running average train loss is 0.014737279082387917 at epoch 32
INFO - 10/17/22 06:26:42 - 0:10:28 - Average dev loss is 0.01484504166426352 at epoch 32
INFO - 10/17/22 06:26:43 - 0:10:29 - dev accuracy is 92.9856 at epoch 32
INFO - 10/17/22 06:26:43 - 0:10:29 - dev phenome error rate is 0.0082 at epoch 32
INFO - 10/17/22 06:26:43 - 0:10:29 - At 33-th epoch with lr 0.000016.
INFO - 10/17/22 06:27:01 - 0:10:48 - Running average train loss is 0.014737456654798718 at epoch 33
INFO - 10/17/22 06:27:02 - 0:10:48 - Average dev loss is 0.014711265912942159 at epoch 33
INFO - 10/17/22 06:27:03 - 0:10:49 - dev accuracy is 93.0755 at epoch 33
INFO - 10/17/22 06:27:03 - 0:10:49 - dev phenome error rate is 0.0079 at epoch 33
INFO - 10/17/22 06:27:03 - 0:10:49 - At 34-th epoch with lr 0.000016.
INFO - 10/17/22 06:27:22 - 0:11:09 - Running average train loss is 0.014554171621442485 at epoch 34
INFO - 10/17/22 06:27:23 - 0:11:09 - Average dev loss is 0.014484473634869433 at epoch 34
INFO - 10/17/22 06:27:24 - 0:11:10 - dev accuracy is 93.2554 at epoch 34
INFO - 10/17/22 06:27:24 - 0:11:10 - dev phenome error rate is 0.0077 at epoch 34
INFO - 10/17/22 06:27:24 - 0:11:10 - At 35-th epoch with lr 0.000016.
INFO - 10/17/22 06:27:43 - 0:11:30 - Running average train loss is 0.014642220408111592 at epoch 35
INFO - 10/17/22 06:27:44 - 0:11:30 - Average dev loss is 0.014188148224583039 at epoch 35
INFO - 10/17/22 06:27:45 - 0:11:31 - dev accuracy is 93.3453 at epoch 35
INFO - 10/17/22 06:27:45 - 0:11:31 - dev phenome error rate is 0.0077 at epoch 35
INFO - 10/17/22 06:27:45 - 0:11:31 - At 36-th epoch with lr 0.000016.
INFO - 10/17/22 06:28:04 - 0:11:51 - Running average train loss is 0.014366812242549114 at epoch 36
INFO - 10/17/22 06:28:05 - 0:11:51 - Average dev loss is 0.01413895120897975 at epoch 36
INFO - 10/17/22 06:28:06 - 0:11:52 - dev accuracy is 93.0755 at epoch 36
INFO - 10/17/22 06:28:06 - 0:11:52 - dev phenome error rate is 0.0081 at epoch 36
INFO - 10/17/22 06:28:06 - 0:11:52 - At 37-th epoch with lr 0.000016.
INFO - 10/17/22 06:28:25 - 0:12:11 - Running average train loss is 0.014141321347967377 at epoch 37
INFO - 10/17/22 06:28:25 - 0:12:12 - Average dev loss is 0.01406116403119925 at epoch 37
INFO - 10/17/22 06:28:26 - 0:12:13 - dev accuracy is 93.3453 at epoch 37
INFO - 10/17/22 06:28:26 - 0:12:13 - dev phenome error rate is 0.0077 at epoch 37
INFO - 10/17/22 06:28:26 - 0:12:13 - At 38-th epoch with lr 0.000016.
INFO - 10/17/22 06:28:44 - 0:12:30 - Running average train loss is 0.014403568262358843 at epoch 38
INFO - 10/17/22 06:28:44 - 0:12:31 - Average dev loss is 0.01404373376728752 at epoch 38
INFO - 10/17/22 06:28:45 - 0:12:32 - dev accuracy is 93.2554 at epoch 38
INFO - 10/17/22 06:28:45 - 0:12:32 - dev phenome error rate is 0.0079 at epoch 38
INFO - 10/17/22 06:28:45 - 0:12:32 - At 39-th epoch with lr 0.000016.
INFO - 10/17/22 06:29:04 - 0:12:50 - Running average train loss is 0.014030349229273877 at epoch 39
INFO - 10/17/22 06:29:04 - 0:12:51 - Average dev loss is 0.014062315909765088 at epoch 39
INFO - 10/17/22 06:29:05 - 0:12:52 - dev accuracy is 93.2554 at epoch 39
INFO - 10/17/22 06:29:05 - 0:12:52 - dev phenome error rate is 0.0077 at epoch 39
INFO - 10/17/22 06:29:05 - 0:12:52 - At 40-th epoch with lr 0.000010.
INFO - 10/17/22 06:29:24 - 0:13:11 - Running average train loss is 0.014778182148383542 at epoch 40
INFO - 10/17/22 06:29:25 - 0:13:11 - Average dev loss is 0.013138841373774295 at epoch 40
INFO - 10/17/22 06:29:26 - 0:13:12 - dev accuracy is 93.2554 at epoch 40
INFO - 10/17/22 06:29:26 - 0:13:12 - dev phenome error rate is 0.0079 at epoch 40
INFO - 10/17/22 06:29:26 - 0:13:12 - At 41-th epoch with lr 0.000010.
INFO - 10/17/22 06:29:47 - 0:13:33 - Running average train loss is 0.014576532610244415 at epoch 41
INFO - 10/17/22 06:29:47 - 0:13:34 - Average dev loss is 0.013209314465236205 at epoch 41
INFO - 10/17/22 06:29:48 - 0:13:35 - dev accuracy is 93.6151 at epoch 41
INFO - 10/17/22 06:29:48 - 0:13:35 - dev phenome error rate is 0.0076 at epoch 41
INFO - 10/17/22 06:29:48 - 0:13:35 - Early stopping triggered with epoch 41 (previous dev loss: 0.013139, current: 0.013209)
INFO - 10/17/22 06:29:48 - 0:13:35 - loading model/test/hardattention/small/transformer0.3/ndebele.nll_0.0141.acc_93.3453.per_0.0077.epoch_37 for testing
INFO - 10/17/22 06:29:48 - 0:13:35 - load model in model/test/hardattention/small/transformer0.3/ndebele.nll_0.0141.acc_93.3453.per_0.0077.epoch_37
INFO - 10/17/22 06:29:49 - 0:13:35 - Average dev loss is 0.01406116403119925 at epoch -1
INFO - 10/17/22 06:29:49 - 0:13:35 - decoding dev set
INFO - 10/17/22 06:29:51 - 0:13:37 - finished decoding 1292 dev instance
INFO - 10/17/22 06:29:51 - 0:13:37 - DEV accuracy is 93.3453 at epoch -1
INFO - 10/17/22 06:29:51 - 0:13:37 - DEV phenome error rate is 0.0077 at epoch -1
INFO - 10/17/22 06:29:51 - 0:13:37 - DEV ndebele acc 93.3453 per 0.0077
INFO - 10/17/22 06:29:52 - 0:13:38 - Average test loss is 0.3121245747897774 at epoch -1
INFO - 10/17/22 06:29:52 - 0:13:38 - decoding test set
INFO - 10/17/22 06:29:55 - 0:13:42 - finished decoding 2552 test instance
INFO - 10/17/22 06:29:55 - 0:13:42 - TEST accuracy is 52.899 at epoch -1
INFO - 10/17/22 06:29:55 - 0:13:42 - TEST phenome error rate is 0.1075 at epoch -1
INFO - 10/17/22 06:29:55 - 0:13:42 - TEST ndebele acc 52.899 per 0.1075
