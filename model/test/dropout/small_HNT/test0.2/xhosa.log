INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: train - ['data/xhosa/xhosa.train']
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: dev - ['data/xhosa/xhosa.dev']
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: test - ['data/xhosa/xhosa.test']
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.2/xhosa'
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: init - 'init/test/large/seed-0/xhosa'
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: dropout - 0.2
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 00:57:51 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 00:57:51 - 0:00:00 - src vocab size 69
INFO - 10/17/22 00:57:51 - 0:00:00 - trg vocab size 66
INFO - 10/17/22 00:57:51 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 00:57:51 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 00:57:51 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(69, 100, padding_idx=0)
                                       (trg_embed): Embedding(66, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.2, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.2, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.2, inplace=False)
                                     )
INFO - 10/17/22 00:57:51 - 0:00:00 - number of parameter 1218766
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: train - ['data/xhosa/xhosa.train']
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: dev - ['data/xhosa/xhosa.dev']
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: test - ['data/xhosa/xhosa.test']
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.2/xhosa'
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: init - 'init/test/large/seed-0/xhosa'
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: dropout - 0.2
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 02:25:32 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 02:25:32 - 0:00:00 - src vocab size 69
INFO - 10/17/22 02:25:32 - 0:00:00 - trg vocab size 66
INFO - 10/17/22 02:25:32 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:25:32 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:25:32 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(69, 100, padding_idx=0)
                                       (trg_embed): Embedding(66, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.2, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.2, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.2, inplace=False)
                                     )
INFO - 10/17/22 02:25:32 - 0:00:00 - number of parameter 1218766
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: train - ['data/xhosa/xhosa.train']
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: dev - ['data/xhosa/xhosa.dev']
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: test - ['data/xhosa/xhosa.test']
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.2/xhosa'
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: init - 'init/test/large/seed-0/xhosa/small'
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: dropout - 0.2
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 02:32:56 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 02:32:56 - 0:00:00 - src vocab size 69
INFO - 10/17/22 02:32:56 - 0:00:00 - trg vocab size 66
INFO - 10/17/22 02:32:56 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:32:56 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:32:56 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(69, 100, padding_idx=0)
                                       (trg_embed): Embedding(66, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.2, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.2, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.2, inplace=False)
                                     )
INFO - 10/17/22 02:32:56 - 0:00:00 - number of parameter 1218766
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: train - ['data/xhosa/xhosa.train']
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: dev - ['data/xhosa/xhosa.dev']
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: test - ['data/xhosa/xhosa.test']
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.2/xhosa'
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: init - ''
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: dropout - 0.2
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 07:12:16 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 07:12:16 - 0:00:00 - src vocab size 69
INFO - 10/17/22 07:12:16 - 0:00:00 - trg vocab size 66
INFO - 10/17/22 07:12:16 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 07:12:16 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 07:12:16 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(69, 100, padding_idx=0)
                                       (trg_embed): Embedding(66, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.2, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.2, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.2, inplace=False)
                                     )
INFO - 10/17/22 07:12:16 - 0:00:00 - number of parameter 1218766
INFO - 10/17/22 07:12:19 - 0:00:03 - maximum training 42200 steps (50 epochs)
INFO - 10/17/22 07:12:19 - 0:00:03 - evaluate every 1 epochs
INFO - 10/17/22 07:12:19 - 0:00:03 - At 0-th epoch with lr 0.001000.
INFO - 10/17/22 07:12:45 - 0:00:29 - Running average train loss is 0.4392102268078669 at epoch 0
INFO - 10/17/22 07:12:45 - 0:00:29 - At 1-th epoch with lr 0.001000.
INFO - 10/17/22 07:13:10 - 0:00:54 - Running average train loss is 0.14547871669613144 at epoch 1
INFO - 10/17/22 07:13:11 - 0:00:55 - Average dev loss is 0.10917590286801843 at epoch 1
INFO - 10/17/22 07:13:12 - 0:00:56 - dev accuracy is 64.1342 at epoch 1
INFO - 10/17/22 07:13:12 - 0:00:56 - dev phenome error rate is 0.0831 at epoch 1
INFO - 10/17/22 07:13:12 - 0:00:56 - At 2-th epoch with lr 0.001000.
INFO - 10/17/22 07:13:39 - 0:01:23 - Running average train loss is 0.10372871686748596 at epoch 2
INFO - 10/17/22 07:13:40 - 0:01:24 - Average dev loss is 0.08600990868666593 at epoch 2
INFO - 10/17/22 07:13:41 - 0:01:25 - dev accuracy is 70.3628 at epoch 2
INFO - 10/17/22 07:13:41 - 0:01:25 - dev phenome error rate is 0.073 at epoch 2
INFO - 10/17/22 07:13:41 - 0:01:25 - At 3-th epoch with lr 0.001000.
INFO - 10/17/22 07:14:06 - 0:01:50 - Running average train loss is 0.08108418373064408 at epoch 3
INFO - 10/17/22 07:14:07 - 0:01:51 - Average dev loss is 0.058877125371466665 at epoch 3
INFO - 10/17/22 07:14:08 - 0:01:52 - dev accuracy is 77.0705 at epoch 3
INFO - 10/17/22 07:14:08 - 0:01:52 - dev phenome error rate is 0.0515 at epoch 3
INFO - 10/17/22 07:14:08 - 0:01:52 - At 4-th epoch with lr 0.001000.
INFO - 10/17/22 07:14:32 - 0:02:16 - Running average train loss is 0.06447501203003317 at epoch 4
INFO - 10/17/22 07:14:32 - 0:02:16 - Average dev loss is 0.04604591078070157 at epoch 4
INFO - 10/17/22 07:14:34 - 0:02:18 - dev accuracy is 81.4511 at epoch 4
INFO - 10/17/22 07:14:34 - 0:02:18 - dev phenome error rate is 0.0395 at epoch 4
INFO - 10/17/22 07:14:34 - 0:02:18 - At 5-th epoch with lr 0.001000.
INFO - 10/17/22 07:14:57 - 0:02:41 - Running average train loss is 0.05465825644743263 at epoch 5
INFO - 10/17/22 07:14:58 - 0:02:42 - Average dev loss is 0.04050059979781508 at epoch 5
INFO - 10/17/22 07:14:59 - 0:02:43 - dev accuracy is 85.4209 at epoch 5
INFO - 10/17/22 07:14:59 - 0:02:43 - dev phenome error rate is 0.0311 at epoch 5
INFO - 10/17/22 07:14:59 - 0:02:43 - At 6-th epoch with lr 0.001000.
INFO - 10/17/22 07:15:22 - 0:03:06 - Running average train loss is 0.048050464187214655 at epoch 6
INFO - 10/17/22 07:15:23 - 0:03:07 - Average dev loss is 0.03411638288046507 at epoch 6
INFO - 10/17/22 07:15:24 - 0:03:08 - dev accuracy is 86.1739 at epoch 6
INFO - 10/17/22 07:15:24 - 0:03:08 - dev phenome error rate is 0.029 at epoch 6
INFO - 10/17/22 07:15:24 - 0:03:08 - At 7-th epoch with lr 0.001000.
INFO - 10/17/22 07:15:47 - 0:03:31 - Running average train loss is 0.040710962877357246 at epoch 7
INFO - 10/17/22 07:15:48 - 0:03:32 - Average dev loss is 0.027081458771820454 at epoch 7
INFO - 10/17/22 07:15:49 - 0:03:33 - dev accuracy is 88.4326 at epoch 7
INFO - 10/17/22 07:15:49 - 0:03:33 - dev phenome error rate is 0.0276 at epoch 7
INFO - 10/17/22 07:15:49 - 0:03:33 - At 8-th epoch with lr 0.001000.
INFO - 10/17/22 07:16:13 - 0:03:56 - Running average train loss is 0.036250381252559576 at epoch 8
INFO - 10/17/22 07:16:13 - 0:03:57 - Average dev loss is 0.023397081452147927 at epoch 8
INFO - 10/17/22 07:16:15 - 0:03:59 - dev accuracy is 89.87 at epoch 8
INFO - 10/17/22 07:16:15 - 0:03:59 - dev phenome error rate is 0.0241 at epoch 8
INFO - 10/17/22 07:16:15 - 0:03:59 - At 9-th epoch with lr 0.001000.
INFO - 10/17/22 07:16:38 - 0:04:22 - Running average train loss is 0.03073617893062042 at epoch 9
INFO - 10/17/22 07:16:38 - 0:04:22 - Average dev loss is 0.01741038251476472 at epoch 9
INFO - 10/17/22 07:16:40 - 0:04:24 - dev accuracy is 92.2656 at epoch 9
INFO - 10/17/22 07:16:40 - 0:04:24 - dev phenome error rate is 0.0173 at epoch 9
INFO - 10/17/22 07:16:40 - 0:04:24 - At 10-th epoch with lr 0.001000.
INFO - 10/17/22 07:17:03 - 0:04:47 - Running average train loss is 0.02837151648404719 at epoch 10
INFO - 10/17/22 07:17:04 - 0:04:47 - Average dev loss is 0.019186821905896066 at epoch 10
INFO - 10/17/22 07:17:05 - 0:04:49 - dev accuracy is 92.0602 at epoch 10
INFO - 10/17/22 07:17:05 - 0:04:49 - dev phenome error rate is 0.0185 at epoch 10
INFO - 10/17/22 07:17:05 - 0:04:49 - At 11-th epoch with lr 0.000500.
INFO - 10/17/22 07:17:28 - 0:05:12 - Running average train loss is 0.01763685275291554 at epoch 11
INFO - 10/17/22 07:17:29 - 0:05:13 - Average dev loss is 0.006658912380910752 at epoch 11
INFO - 10/17/22 07:17:30 - 0:05:14 - dev accuracy is 96.5777 at epoch 11
INFO - 10/17/22 07:17:30 - 0:05:14 - dev phenome error rate is 0.0086 at epoch 11
INFO - 10/17/22 07:17:30 - 0:05:14 - At 12-th epoch with lr 0.000500.
INFO - 10/17/22 07:17:53 - 0:05:37 - Running average train loss is 0.011727873142905229 at epoch 12
INFO - 10/17/22 07:17:54 - 0:05:38 - Average dev loss is 0.005199059313984917 at epoch 12
INFO - 10/17/22 07:17:55 - 0:05:39 - dev accuracy is 97.6044 at epoch 12
INFO - 10/17/22 07:17:55 - 0:05:39 - dev phenome error rate is 0.0058 at epoch 12
INFO - 10/17/22 07:17:55 - 0:05:39 - At 13-th epoch with lr 0.000500.
INFO - 10/17/22 07:18:18 - 0:06:02 - Running average train loss is 0.010603631289254584 at epoch 13
INFO - 10/17/22 07:18:19 - 0:06:03 - Average dev loss is 0.005932851492338266 at epoch 13
INFO - 10/17/22 07:18:20 - 0:06:04 - dev accuracy is 97.1937 at epoch 13
INFO - 10/17/22 07:18:20 - 0:06:04 - dev phenome error rate is 0.007 at epoch 13
INFO - 10/17/22 07:18:20 - 0:06:04 - At 14-th epoch with lr 0.000250.
INFO - 10/17/22 07:18:43 - 0:06:27 - Running average train loss is 0.007541357022552901 at epoch 14
INFO - 10/17/22 07:18:44 - 0:06:28 - Average dev loss is 0.0028575549259959887 at epoch 14
INFO - 10/17/22 07:18:46 - 0:06:30 - dev accuracy is 98.768 at epoch 14
INFO - 10/17/22 07:18:46 - 0:06:30 - dev phenome error rate is 0.0036 at epoch 14
INFO - 10/17/22 07:18:46 - 0:06:30 - At 15-th epoch with lr 0.000250.
INFO - 10/17/22 07:19:09 - 0:06:53 - Running average train loss is 0.005298104773156104 at epoch 15
INFO - 10/17/22 07:19:09 - 0:06:53 - Average dev loss is 0.0021440737428801023 at epoch 15
INFO - 10/17/22 07:19:11 - 0:06:55 - dev accuracy is 99.3155 at epoch 15
INFO - 10/17/22 07:19:11 - 0:06:55 - dev phenome error rate is 0.0021 at epoch 15
INFO - 10/17/22 07:19:11 - 0:06:55 - At 16-th epoch with lr 0.000250.
INFO - 10/17/22 07:19:34 - 0:07:18 - Running average train loss is 0.005146402766146963 at epoch 16
INFO - 10/17/22 07:19:34 - 0:07:18 - Average dev loss is 0.0017367957204388563 at epoch 16
INFO - 10/17/22 07:19:36 - 0:07:20 - dev accuracy is 99.2471 at epoch 16
INFO - 10/17/22 07:19:36 - 0:07:20 - dev phenome error rate is 0.0025 at epoch 16
INFO - 10/17/22 07:19:36 - 0:07:20 - At 17-th epoch with lr 0.000250.
INFO - 10/17/22 07:19:59 - 0:07:43 - Running average train loss is 0.004480467354059117 at epoch 17
INFO - 10/17/22 07:20:00 - 0:07:44 - Average dev loss is 0.0017336224070544739 at epoch 17
INFO - 10/17/22 07:20:01 - 0:07:45 - dev accuracy is 99.384 at epoch 17
INFO - 10/17/22 07:20:01 - 0:07:45 - dev phenome error rate is 0.0019 at epoch 17
INFO - 10/17/22 07:20:01 - 0:07:45 - At 18-th epoch with lr 0.000250.
INFO - 10/17/22 07:20:24 - 0:08:08 - Running average train loss is 0.004647781139929885 at epoch 18
INFO - 10/17/22 07:20:25 - 0:08:09 - Average dev loss is 0.0014655965258819324 at epoch 18
INFO - 10/17/22 07:20:26 - 0:08:10 - dev accuracy is 99.6578 at epoch 18
INFO - 10/17/22 07:20:26 - 0:08:10 - dev phenome error rate is 0.0011 at epoch 18
INFO - 10/17/22 07:20:26 - 0:08:10 - At 19-th epoch with lr 0.000250.
INFO - 10/17/22 07:20:49 - 0:08:33 - Running average train loss is 0.004328993117635804 at epoch 19
INFO - 10/17/22 07:20:50 - 0:08:34 - Average dev loss is 0.0015616194565903725 at epoch 19
INFO - 10/17/22 07:20:51 - 0:08:35 - dev accuracy is 99.5893 at epoch 19
INFO - 10/17/22 07:20:51 - 0:08:35 - dev phenome error rate is 0.0015 at epoch 19
INFO - 10/17/22 07:20:51 - 0:08:35 - At 20-th epoch with lr 0.000125.
INFO - 10/17/22 07:21:14 - 0:08:58 - Running average train loss is 0.0033162367335923173 at epoch 20
INFO - 10/17/22 07:21:15 - 0:08:59 - Average dev loss is 0.0009957032344947733 at epoch 20
INFO - 10/17/22 07:21:16 - 0:09:00 - dev accuracy is 99.7262 at epoch 20
INFO - 10/17/22 07:21:16 - 0:09:00 - dev phenome error rate is 0.0011 at epoch 20
INFO - 10/17/22 07:21:16 - 0:09:00 - At 21-th epoch with lr 0.000125.
INFO - 10/17/22 07:21:39 - 0:09:23 - Running average train loss is 0.002714723883641821 at epoch 21
INFO - 10/17/22 07:21:40 - 0:09:24 - Average dev loss is 0.0008396128323083223 at epoch 21
INFO - 10/17/22 07:21:41 - 0:09:25 - dev accuracy is 99.7262 at epoch 21
INFO - 10/17/22 07:21:41 - 0:09:25 - dev phenome error rate is 0.0011 at epoch 21
INFO - 10/17/22 07:21:41 - 0:09:25 - At 22-th epoch with lr 0.000125.
INFO - 10/17/22 07:22:04 - 0:09:48 - Running average train loss is 0.0025540837796574063 at epoch 22
INFO - 10/17/22 07:22:05 - 0:09:49 - Average dev loss is 0.0008678604811875095 at epoch 22
INFO - 10/17/22 07:22:07 - 0:09:51 - dev accuracy is 99.7262 at epoch 22
INFO - 10/17/22 07:22:07 - 0:09:51 - dev phenome error rate is 0.0011 at epoch 22
INFO - 10/17/22 07:22:07 - 0:09:51 - At 23-th epoch with lr 0.000063.
INFO - 10/17/22 07:22:30 - 0:10:14 - Running average train loss is 0.002260925648662766 at epoch 23
INFO - 10/17/22 07:22:30 - 0:10:14 - Average dev loss is 0.0006768134702510639 at epoch 23
INFO - 10/17/22 07:22:32 - 0:10:16 - dev accuracy is 99.7947 at epoch 23
INFO - 10/17/22 07:22:32 - 0:10:16 - dev phenome error rate is 0.0009 at epoch 23
INFO - 10/17/22 07:22:32 - 0:10:16 - At 24-th epoch with lr 0.000063.
INFO - 10/17/22 07:22:55 - 0:10:39 - Running average train loss is 0.002040892973528351 at epoch 24
INFO - 10/17/22 07:22:55 - 0:10:39 - Average dev loss is 0.0006491843227516203 at epoch 24
INFO - 10/17/22 07:22:57 - 0:10:41 - dev accuracy is 99.8631 at epoch 24
INFO - 10/17/22 07:22:57 - 0:10:41 - dev phenome error rate is 0.0007 at epoch 24
INFO - 10/17/22 07:22:57 - 0:10:41 - At 25-th epoch with lr 0.000063.
INFO - 10/17/22 07:23:20 - 0:11:04 - Running average train loss is 0.0017511887722989374 at epoch 25
INFO - 10/17/22 07:23:21 - 0:11:05 - Average dev loss is 0.0006637139820240383 at epoch 25
INFO - 10/17/22 07:23:22 - 0:11:06 - dev accuracy is 99.7947 at epoch 25
INFO - 10/17/22 07:23:22 - 0:11:06 - dev phenome error rate is 0.0009 at epoch 25
INFO - 10/17/22 07:23:22 - 0:11:06 - At 26-th epoch with lr 0.000031.
INFO - 10/17/22 07:23:45 - 0:11:29 - Running average train loss is 0.001721540006156135 at epoch 26
INFO - 10/17/22 07:23:46 - 0:11:30 - Average dev loss is 0.0006104252176181249 at epoch 26
INFO - 10/17/22 07:23:47 - 0:11:31 - dev accuracy is 99.8631 at epoch 26
INFO - 10/17/22 07:23:47 - 0:11:31 - dev phenome error rate is 0.0007 at epoch 26
INFO - 10/17/22 07:23:47 - 0:11:31 - At 27-th epoch with lr 0.000031.
INFO - 10/17/22 07:24:11 - 0:11:55 - Running average train loss is 0.0015981406658115854 at epoch 27
INFO - 10/17/22 07:24:11 - 0:11:55 - Average dev loss is 0.0005838459781978814 at epoch 27
INFO - 10/17/22 07:24:13 - 0:11:57 - dev accuracy is 99.8631 at epoch 27
INFO - 10/17/22 07:24:13 - 0:11:57 - dev phenome error rate is 0.0007 at epoch 27
INFO - 10/17/22 07:24:13 - 0:11:57 - At 28-th epoch with lr 0.000031.
INFO - 10/17/22 07:24:36 - 0:12:20 - Running average train loss is 0.0016235909062756234 at epoch 28
INFO - 10/17/22 07:24:37 - 0:12:21 - Average dev loss is 0.0005728365051147514 at epoch 28
INFO - 10/17/22 07:24:38 - 0:12:22 - dev accuracy is 99.8631 at epoch 28
INFO - 10/17/22 07:24:38 - 0:12:22 - dev phenome error rate is 0.0007 at epoch 28
INFO - 10/17/22 07:24:38 - 0:12:22 - At 29-th epoch with lr 0.000031.
INFO - 10/17/22 07:25:01 - 0:12:45 - Running average train loss is 0.0015820788979460402 at epoch 29
INFO - 10/17/22 07:25:02 - 0:12:46 - Average dev loss is 0.0005546510247607812 at epoch 29
INFO - 10/17/22 07:25:03 - 0:12:47 - dev accuracy is 99.8631 at epoch 29
INFO - 10/17/22 07:25:03 - 0:12:47 - dev phenome error rate is 0.0007 at epoch 29
INFO - 10/17/22 07:25:03 - 0:12:47 - At 30-th epoch with lr 0.000031.
INFO - 10/17/22 07:25:26 - 0:13:10 - Running average train loss is 0.0015917939061665316 at epoch 30
INFO - 10/17/22 07:25:27 - 0:13:11 - Average dev loss is 0.0005345567112218465 at epoch 30
INFO - 10/17/22 07:25:29 - 0:13:13 - dev accuracy is 99.8631 at epoch 30
INFO - 10/17/22 07:25:29 - 0:13:13 - dev phenome error rate is 0.0007 at epoch 30
INFO - 10/17/22 07:25:29 - 0:13:13 - At 31-th epoch with lr 0.000031.
INFO - 10/17/22 07:25:52 - 0:13:36 - Running average train loss is 0.0014468489968201632 at epoch 31
INFO - 10/17/22 07:25:52 - 0:13:36 - Average dev loss is 0.0004977355759097811 at epoch 31
INFO - 10/17/22 07:25:54 - 0:13:38 - dev accuracy is 99.8631 at epoch 31
INFO - 10/17/22 07:25:54 - 0:13:38 - dev phenome error rate is 0.0007 at epoch 31
INFO - 10/17/22 07:25:54 - 0:13:38 - At 32-th epoch with lr 0.000031.
INFO - 10/17/22 07:26:17 - 0:14:01 - Running average train loss is 0.001509645800117262 at epoch 32
INFO - 10/17/22 07:26:18 - 0:14:01 - Average dev loss is 0.0005220571143795764 at epoch 32
INFO - 10/17/22 07:26:19 - 0:14:03 - dev accuracy is 99.7947 at epoch 32
INFO - 10/17/22 07:26:19 - 0:14:03 - dev phenome error rate is 0.0009 at epoch 32
INFO - 10/17/22 07:26:19 - 0:14:03 - At 33-th epoch with lr 0.000016.
INFO - 10/17/22 07:26:42 - 0:14:26 - Running average train loss is 0.0013810089524094718 at epoch 33
INFO - 10/17/22 07:26:43 - 0:14:27 - Average dev loss is 0.000515108448705766 at epoch 33
INFO - 10/17/22 07:26:44 - 0:14:28 - dev accuracy is 99.8631 at epoch 33
INFO - 10/17/22 07:26:44 - 0:14:28 - dev phenome error rate is 0.0007 at epoch 33
INFO - 10/17/22 07:26:44 - 0:14:28 - At 34-th epoch with lr 0.000010.
INFO - 10/17/22 07:27:07 - 0:14:51 - Running average train loss is 0.0013612947645601297 at epoch 34
INFO - 10/17/22 07:27:08 - 0:14:52 - Average dev loss is 0.0004886963862672394 at epoch 34
INFO - 10/17/22 07:27:09 - 0:14:53 - dev accuracy is 99.8631 at epoch 34
INFO - 10/17/22 07:27:09 - 0:14:53 - dev phenome error rate is 0.0007 at epoch 34
INFO - 10/17/22 07:27:09 - 0:14:53 - At 35-th epoch with lr 0.000010.
INFO - 10/17/22 07:27:32 - 0:15:16 - Running average train loss is 0.0012820573162605718 at epoch 35
INFO - 10/17/22 07:27:33 - 0:15:17 - Average dev loss is 0.00047385805651976946 at epoch 35
INFO - 10/17/22 07:27:34 - 0:15:18 - dev accuracy is 99.8631 at epoch 35
INFO - 10/17/22 07:27:34 - 0:15:18 - dev phenome error rate is 0.0007 at epoch 35
INFO - 10/17/22 07:27:35 - 0:15:18 - At 36-th epoch with lr 0.000010.
INFO - 10/17/22 07:27:58 - 0:15:42 - Running average train loss is 0.0012478213682232445 at epoch 36
INFO - 10/17/22 07:27:58 - 0:15:42 - Average dev loss is 0.0004678074558315155 at epoch 36
INFO - 10/17/22 07:28:00 - 0:15:44 - dev accuracy is 99.8631 at epoch 36
INFO - 10/17/22 07:28:00 - 0:15:44 - dev phenome error rate is 0.0007 at epoch 36
INFO - 10/17/22 07:28:00 - 0:15:44 - At 37-th epoch with lr 0.000010.
INFO - 10/17/22 07:28:23 - 0:16:07 - Running average train loss is 0.0013750247617712315 at epoch 37
INFO - 10/17/22 07:28:23 - 0:16:07 - Average dev loss is 0.00046837501891679813 at epoch 37
INFO - 10/17/22 07:28:25 - 0:16:09 - dev accuracy is 99.8631 at epoch 37
INFO - 10/17/22 07:28:25 - 0:16:09 - dev phenome error rate is 0.0007 at epoch 37
INFO - 10/17/22 07:28:25 - 0:16:09 - Early stopping triggered with epoch 37 (previous dev loss: 0.000468, current: 0.000468)
INFO - 10/17/22 07:28:25 - 0:16:09 - loading model/test/hardattention/small/transformer0.2/xhosa.nll_0.0005.acc_99.8631.per_0.0007.epoch_36 for testing
INFO - 10/17/22 07:28:25 - 0:16:09 - load model in model/test/hardattention/small/transformer0.2/xhosa.nll_0.0005.acc_99.8631.per_0.0007.epoch_36
INFO - 10/17/22 07:28:25 - 0:16:09 - Average dev loss is 0.0004678074558315155 at epoch -1
INFO - 10/17/22 07:28:25 - 0:16:09 - decoding dev set
INFO - 10/17/22 07:28:28 - 0:16:12 - finished decoding 1687 dev instance
INFO - 10/17/22 07:28:28 - 0:16:12 - DEV accuracy is 99.8631 at epoch -1
INFO - 10/17/22 07:28:28 - 0:16:12 - DEV phenome error rate is 0.0007 at epoch -1
INFO - 10/17/22 07:28:28 - 0:16:12 - DEV xhosa acc 99.8631 per 0.0007
INFO - 10/17/22 07:28:29 - 0:16:13 - Average test loss is 0.42441889012096734 at epoch -1
INFO - 10/17/22 07:28:29 - 0:16:13 - decoding test set
INFO - 10/17/22 07:28:33 - 0:16:17 - finished decoding 3003 test instance
INFO - 10/17/22 07:28:33 - 0:16:17 - TEST accuracy is 55.8869 at epoch -1
INFO - 10/17/22 07:28:33 - 0:16:17 - TEST phenome error rate is 0.1147 at epoch -1
INFO - 10/17/22 07:28:33 - 0:16:17 - TEST xhosa acc 55.8869 per 0.1147
