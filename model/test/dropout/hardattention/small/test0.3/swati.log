INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: train - ['data/swati/swati.train']
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: dev - ['data/swati/swati.dev']
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: test - ['data/swati/swati.test']
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.3/swati'
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: init - 'init/test/large/seed-0/swati'
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: dropout - 0.3
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 00:56:51 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 00:56:51 - 0:00:00 - src vocab size 70
INFO - 10/17/22 00:56:51 - 0:00:00 - trg vocab size 71
INFO - 10/17/22 00:56:51 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 00:56:51 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 00:56:51 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(70, 100, padding_idx=0)
                                       (trg_embed): Embedding(71, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.3, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.3, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=71, bias=True)
                                       (dropout): Dropout(p=0.3, inplace=False)
                                     )
INFO - 10/17/22 00:56:51 - 0:00:00 - number of parameter 1222371
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: train - ['data/swati/swati.train']
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: dev - ['data/swati/swati.dev']
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: test - ['data/swati/swati.test']
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.3/swati'
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: init - 'init/test/large/seed-0/swati/small'
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: dropout - 0.3
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 02:33:55 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 02:33:55 - 0:00:00 - src vocab size 70
INFO - 10/17/22 02:33:55 - 0:00:00 - trg vocab size 71
INFO - 10/17/22 02:33:55 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:33:55 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:33:55 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(70, 100, padding_idx=0)
                                       (trg_embed): Embedding(71, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.3, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.3, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=71, bias=True)
                                       (dropout): Dropout(p=0.3, inplace=False)
                                     )
INFO - 10/17/22 02:33:55 - 0:00:00 - number of parameter 1222371
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: train - ['data/swati/swati.train']
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: dev - ['data/swati/swati.dev']
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: test - ['data/swati/swati.test']
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.3/swati'
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: init - ''
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: dropout - 0.3
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 06:29:57 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 06:29:58 - 0:00:00 - src vocab size 70
INFO - 10/17/22 06:29:58 - 0:00:00 - trg vocab size 71
INFO - 10/17/22 06:29:58 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 06:29:58 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 06:29:58 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(70, 100, padding_idx=0)
                                       (trg_embed): Embedding(71, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.3, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.3, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=71, bias=True)
                                       (dropout): Dropout(p=0.3, inplace=False)
                                     )
INFO - 10/17/22 06:29:58 - 0:00:00 - number of parameter 1222371
INFO - 10/17/22 06:30:00 - 0:00:02 - maximum training 27000 steps (50 epochs)
INFO - 10/17/22 06:30:00 - 0:00:02 - evaluate every 1 epochs
INFO - 10/17/22 06:30:00 - 0:00:02 - At 0-th epoch with lr 0.001000.
INFO - 10/17/22 06:30:13 - 0:00:16 - Running average train loss is 0.47474431045077464 at epoch 0
INFO - 10/17/22 06:30:13 - 0:00:16 - At 1-th epoch with lr 0.001000.
INFO - 10/17/22 06:30:25 - 0:00:28 - Running average train loss is 0.10190338818183928 at epoch 1
INFO - 10/17/22 06:30:26 - 0:00:28 - Average dev loss is 0.05481846680588744 at epoch 1
INFO - 10/17/22 06:30:26 - 0:00:29 - dev accuracy is 79.2804 at epoch 1
INFO - 10/17/22 06:30:26 - 0:00:29 - dev phenome error rate is 0.0469 at epoch 1
INFO - 10/17/22 06:30:26 - 0:00:29 - At 2-th epoch with lr 0.001000.
INFO - 10/17/22 06:30:39 - 0:00:41 - Running average train loss is 0.06398247418476752 at epoch 2
INFO - 10/17/22 06:30:39 - 0:00:42 - Average dev loss is 0.04128326700689892 at epoch 2
INFO - 10/17/22 06:30:40 - 0:00:42 - dev accuracy is 85.4839 at epoch 2
INFO - 10/17/22 06:30:40 - 0:00:42 - dev phenome error rate is 0.0264 at epoch 2
INFO - 10/17/22 06:30:40 - 0:00:42 - At 3-th epoch with lr 0.001000.
INFO - 10/17/22 06:30:52 - 0:00:55 - Running average train loss is 0.051884985757405286 at epoch 3
INFO - 10/17/22 06:30:53 - 0:00:55 - Average dev loss is 0.03474454233785056 at epoch 3
INFO - 10/17/22 06:30:53 - 0:00:56 - dev accuracy is 88.5856 at epoch 3
INFO - 10/17/22 06:30:53 - 0:00:56 - dev phenome error rate is 0.0218 at epoch 3
INFO - 10/17/22 06:30:53 - 0:00:56 - At 4-th epoch with lr 0.001000.
INFO - 10/17/22 06:31:06 - 0:01:08 - Running average train loss is 0.03984259095008451 at epoch 4
INFO - 10/17/22 06:31:06 - 0:01:09 - Average dev loss is 0.027183602354920434 at epoch 4
INFO - 10/17/22 06:31:07 - 0:01:09 - dev accuracy is 89.8263 at epoch 4
INFO - 10/17/22 06:31:07 - 0:01:09 - dev phenome error rate is 0.0276 at epoch 4
INFO - 10/17/22 06:31:07 - 0:01:09 - At 5-th epoch with lr 0.001000.
INFO - 10/17/22 06:31:19 - 0:01:22 - Running average train loss is 0.035424187737172125 at epoch 5
INFO - 10/17/22 06:31:20 - 0:01:22 - Average dev loss is 0.02879591787846207 at epoch 5
INFO - 10/17/22 06:31:20 - 0:01:23 - dev accuracy is 89.5782 at epoch 5
INFO - 10/17/22 06:31:20 - 0:01:23 - dev phenome error rate is 0.0195 at epoch 5
INFO - 10/17/22 06:31:20 - 0:01:23 - At 6-th epoch with lr 0.000500.
INFO - 10/17/22 06:31:33 - 0:01:36 - Running average train loss is 0.02105648695012658 at epoch 6
INFO - 10/17/22 06:31:33 - 0:01:36 - Average dev loss is 0.009513671489441078 at epoch 6
INFO - 10/17/22 06:31:34 - 0:01:37 - dev accuracy is 96.2779 at epoch 6
INFO - 10/17/22 06:31:34 - 0:01:37 - dev phenome error rate is 0.0082 at epoch 6
INFO - 10/17/22 06:31:34 - 0:01:37 - At 7-th epoch with lr 0.000500.
INFO - 10/17/22 06:31:46 - 0:01:49 - Running average train loss is 0.01543720105395618 at epoch 7
INFO - 10/17/22 06:31:47 - 0:01:49 - Average dev loss is 0.0070760884867653384 at epoch 7
INFO - 10/17/22 06:31:47 - 0:01:50 - dev accuracy is 97.3945 at epoch 7
INFO - 10/17/22 06:31:47 - 0:01:50 - dev phenome error rate is 0.0052 at epoch 7
INFO - 10/17/22 06:31:47 - 0:01:50 - At 8-th epoch with lr 0.000500.
INFO - 10/17/22 06:32:00 - 0:02:02 - Running average train loss is 0.012227191496317067 at epoch 8
INFO - 10/17/22 06:32:00 - 0:02:03 - Average dev loss is 0.007452178082732846 at epoch 8
INFO - 10/17/22 06:32:01 - 0:02:04 - dev accuracy is 96.402 at epoch 8
INFO - 10/17/22 06:32:01 - 0:02:04 - dev phenome error rate is 0.0063 at epoch 8
INFO - 10/17/22 06:32:01 - 0:02:04 - At 9-th epoch with lr 0.000250.
INFO - 10/17/22 06:32:13 - 0:02:16 - Running average train loss is 0.009167853080510178 at epoch 9
INFO - 10/17/22 06:32:14 - 0:02:16 - Average dev loss is 0.004642235500661492 at epoch 9
INFO - 10/17/22 06:32:14 - 0:02:17 - dev accuracy is 98.139 at epoch 9
INFO - 10/17/22 06:32:14 - 0:02:17 - dev phenome error rate is 0.0037 at epoch 9
INFO - 10/17/22 06:32:14 - 0:02:17 - At 10-th epoch with lr 0.000250.
INFO - 10/17/22 06:32:27 - 0:02:29 - Running average train loss is 0.007942710671287151 at epoch 10
INFO - 10/17/22 06:32:27 - 0:02:30 - Average dev loss is 0.003603072108321444 at epoch 10
INFO - 10/17/22 06:32:28 - 0:02:30 - dev accuracy is 98.8834 at epoch 10
INFO - 10/17/22 06:32:28 - 0:02:30 - dev phenome error rate is 0.0019 at epoch 10
INFO - 10/17/22 06:32:28 - 0:02:31 - At 11-th epoch with lr 0.000250.
INFO - 10/17/22 06:32:40 - 0:02:43 - Running average train loss is 0.007059417201876554 at epoch 11
INFO - 10/17/22 06:32:41 - 0:02:43 - Average dev loss is 0.002952861141912527 at epoch 11
INFO - 10/17/22 06:32:41 - 0:02:44 - dev accuracy is 98.8834 at epoch 11
INFO - 10/17/22 06:32:41 - 0:02:44 - dev phenome error rate is 0.002 at epoch 11
INFO - 10/17/22 06:32:41 - 0:02:44 - At 12-th epoch with lr 0.000250.
INFO - 10/17/22 06:32:54 - 0:02:56 - Running average train loss is 0.006096767786948476 at epoch 12
INFO - 10/17/22 06:32:54 - 0:02:57 - Average dev loss is 0.003141200158333285 at epoch 12
INFO - 10/17/22 06:32:55 - 0:02:57 - dev accuracy is 99.1315 at epoch 12
INFO - 10/17/22 06:32:55 - 0:02:57 - dev phenome error rate is 0.0015 at epoch 12
INFO - 10/17/22 06:32:55 - 0:02:57 - At 13-th epoch with lr 0.000125.
INFO - 10/17/22 06:33:07 - 0:03:10 - Running average train loss is 0.005207467084067132 at epoch 13
INFO - 10/17/22 06:33:08 - 0:03:10 - Average dev loss is 0.0021098425620746436 at epoch 13
INFO - 10/17/22 06:33:08 - 0:03:11 - dev accuracy is 99.3797 at epoch 13
INFO - 10/17/22 06:33:08 - 0:03:11 - dev phenome error rate is 0.0011 at epoch 13
INFO - 10/17/22 06:33:08 - 0:03:11 - At 14-th epoch with lr 0.000125.
INFO - 10/17/22 06:33:21 - 0:03:23 - Running average train loss is 0.0045569215253635775 at epoch 14
INFO - 10/17/22 06:33:21 - 0:03:24 - Average dev loss is 0.001874230867879642 at epoch 14
INFO - 10/17/22 06:33:22 - 0:03:24 - dev accuracy is 99.6278 at epoch 14
INFO - 10/17/22 06:33:22 - 0:03:24 - dev phenome error rate is 0.0008 at epoch 14
INFO - 10/17/22 06:33:22 - 0:03:24 - At 15-th epoch with lr 0.000125.
INFO - 10/17/22 06:33:34 - 0:03:37 - Running average train loss is 0.004245254839972606 at epoch 15
INFO - 10/17/22 06:33:35 - 0:03:37 - Average dev loss is 0.002251847273631332 at epoch 15
INFO - 10/17/22 06:33:35 - 0:03:38 - dev accuracy is 99.2556 at epoch 15
INFO - 10/17/22 06:33:35 - 0:03:38 - dev phenome error rate is 0.0019 at epoch 15
INFO - 10/17/22 06:33:35 - 0:03:38 - At 16-th epoch with lr 0.000063.
INFO - 10/17/22 06:33:48 - 0:03:50 - Running average train loss is 0.003841810836416294 at epoch 16
INFO - 10/17/22 06:33:48 - 0:03:51 - Average dev loss is 0.0012249525579035333 at epoch 16
INFO - 10/17/22 06:33:49 - 0:03:51 - dev accuracy is 99.7519 at epoch 16
INFO - 10/17/22 06:33:49 - 0:03:51 - dev phenome error rate is 0.0004 at epoch 16
INFO - 10/17/22 06:33:49 - 0:03:51 - At 17-th epoch with lr 0.000063.
INFO - 10/17/22 06:34:01 - 0:04:04 - Running average train loss is 0.003343442568748961 at epoch 17
INFO - 10/17/22 06:34:01 - 0:04:04 - Average dev loss is 0.0013199949772334312 at epoch 17
INFO - 10/17/22 06:34:02 - 0:04:05 - dev accuracy is 99.5037 at epoch 17
INFO - 10/17/22 06:34:02 - 0:04:05 - dev phenome error rate is 0.0008 at epoch 17
INFO - 10/17/22 06:34:02 - 0:04:05 - At 18-th epoch with lr 0.000031.
INFO - 10/17/22 06:34:14 - 0:04:17 - Running average train loss is 0.0031630327211907435 at epoch 18
INFO - 10/17/22 06:34:15 - 0:04:17 - Average dev loss is 0.0012702880012511741 at epoch 18
INFO - 10/17/22 06:34:16 - 0:04:18 - dev accuracy is 99.6278 at epoch 18
INFO - 10/17/22 06:34:16 - 0:04:18 - dev phenome error rate is 0.0006 at epoch 18
INFO - 10/17/22 06:34:16 - 0:04:18 - At 19-th epoch with lr 0.000016.
INFO - 10/17/22 06:34:28 - 0:04:31 - Running average train loss is 0.003071811126991869 at epoch 19
INFO - 10/17/22 06:34:28 - 0:04:31 - Average dev loss is 0.0011503020878417711 at epoch 19
INFO - 10/17/22 06:34:29 - 0:04:32 - dev accuracy is 99.6278 at epoch 19
INFO - 10/17/22 06:34:29 - 0:04:32 - dev phenome error rate is 0.0006 at epoch 19
INFO - 10/17/22 06:34:29 - 0:04:32 - At 20-th epoch with lr 0.000016.
INFO - 10/17/22 06:34:41 - 0:04:44 - Running average train loss is 0.0027939204089004 at epoch 20
INFO - 10/17/22 06:34:42 - 0:04:44 - Average dev loss is 0.0011273162364415367 at epoch 20
INFO - 10/17/22 06:34:42 - 0:04:45 - dev accuracy is 99.6278 at epoch 20
INFO - 10/17/22 06:34:42 - 0:04:45 - dev phenome error rate is 0.0006 at epoch 20
INFO - 10/17/22 06:34:42 - 0:04:45 - At 21-th epoch with lr 0.000016.
INFO - 10/17/22 06:34:55 - 0:04:57 - Running average train loss is 0.002789002177302825 at epoch 21
INFO - 10/17/22 06:34:55 - 0:04:58 - Average dev loss is 0.0010953090200524053 at epoch 21
INFO - 10/17/22 06:34:56 - 0:04:58 - dev accuracy is 99.6278 at epoch 21
INFO - 10/17/22 06:34:56 - 0:04:58 - dev phenome error rate is 0.0006 at epoch 21
INFO - 10/17/22 06:34:56 - 0:04:59 - At 22-th epoch with lr 0.000016.
INFO - 10/17/22 06:35:08 - 0:05:11 - Running average train loss is 0.0027337208187317528 at epoch 22
INFO - 10/17/22 06:35:09 - 0:05:11 - Average dev loss is 0.0011162202152061379 at epoch 22
INFO - 10/17/22 06:35:09 - 0:05:12 - dev accuracy is 99.6278 at epoch 22
INFO - 10/17/22 06:35:09 - 0:05:12 - dev phenome error rate is 0.0006 at epoch 22
INFO - 10/17/22 06:35:09 - 0:05:12 - At 23-th epoch with lr 0.000010.
INFO - 10/17/22 06:35:22 - 0:05:24 - Running average train loss is 0.0029222244610233854 at epoch 23
INFO - 10/17/22 06:35:22 - 0:05:25 - Average dev loss is 0.0011113868556465066 at epoch 23
INFO - 10/17/22 06:35:23 - 0:05:25 - dev accuracy is 99.6278 at epoch 23
INFO - 10/17/22 06:35:23 - 0:05:25 - dev phenome error rate is 0.0006 at epoch 23
INFO - 10/17/22 06:35:23 - 0:05:25 - At 24-th epoch with lr 0.000010.
INFO - 10/17/22 06:35:35 - 0:05:38 - Running average train loss is 0.0026134496526706414 at epoch 24
INFO - 10/17/22 06:35:35 - 0:05:38 - Average dev loss is 0.0010722258948253174 at epoch 24
INFO - 10/17/22 06:35:36 - 0:05:39 - dev accuracy is 99.6278 at epoch 24
INFO - 10/17/22 06:35:36 - 0:05:39 - dev phenome error rate is 0.0006 at epoch 24
INFO - 10/17/22 06:35:36 - 0:05:39 - At 25-th epoch with lr 0.000010.
INFO - 10/17/22 06:35:49 - 0:05:51 - Running average train loss is 0.0026626171107771504 at epoch 25
INFO - 10/17/22 06:35:49 - 0:05:51 - Average dev loss is 0.0010148456979179711 at epoch 25
INFO - 10/17/22 06:35:50 - 0:05:52 - dev accuracy is 99.6278 at epoch 25
INFO - 10/17/22 06:35:50 - 0:05:52 - dev phenome error rate is 0.0006 at epoch 25
INFO - 10/17/22 06:35:50 - 0:05:52 - At 26-th epoch with lr 0.000010.
INFO - 10/17/22 06:36:02 - 0:06:05 - Running average train loss is 0.0028221332729487956 at epoch 26
INFO - 10/17/22 06:36:02 - 0:06:05 - Average dev loss is 0.001019114613949636 at epoch 26
INFO - 10/17/22 06:36:03 - 0:06:06 - dev accuracy is 99.6278 at epoch 26
INFO - 10/17/22 06:36:03 - 0:06:06 - dev phenome error rate is 0.0006 at epoch 26
INFO - 10/17/22 06:36:03 - 0:06:06 - Early stopping triggered with epoch 26 (previous dev loss: 0.001015, current: 0.001019)
INFO - 10/17/22 06:36:03 - 0:06:06 - loading model/test/hardattention/small/transformer0.3/swati.nll_0.0012.acc_99.7519.per_0.0004.epoch_16 for testing
INFO - 10/17/22 06:36:03 - 0:06:06 - load model in model/test/hardattention/small/transformer0.3/swati.nll_0.0012.acc_99.7519.per_0.0004.epoch_16
INFO - 10/17/22 06:36:03 - 0:06:06 - Average dev loss is 0.0012249525579035333 at epoch -1
INFO - 10/17/22 06:36:03 - 0:06:06 - decoding dev set
INFO - 10/17/22 06:36:05 - 0:06:07 - finished decoding 1079 dev instance
INFO - 10/17/22 06:36:05 - 0:06:07 - DEV accuracy is 99.7519 at epoch -1
INFO - 10/17/22 06:36:05 - 0:06:07 - DEV phenome error rate is 0.0004 at epoch -1
INFO - 10/17/22 06:36:05 - 0:06:07 - DEV swati acc 99.7519 per 0.0004
INFO - 10/17/22 06:36:06 - 0:06:09 - Average test loss is 0.3211128379627798 at epoch -1
INFO - 10/17/22 06:36:06 - 0:06:09 - decoding test set
INFO - 10/17/22 06:36:11 - 0:06:14 - finished decoding 5639 test instance
INFO - 10/17/22 06:36:11 - 0:06:14 - TEST accuracy is 73.0556 at epoch -1
INFO - 10/17/22 06:36:11 - 0:06:14 - TEST phenome error rate is 0.0525 at epoch -1
INFO - 10/17/22 06:36:11 - 0:06:14 - TEST swati acc 73.0556 per 0.0525
