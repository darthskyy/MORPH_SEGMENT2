INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: train - ['data/xhosa/xhosa.train']
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: dev - ['data/xhosa/xhosa.dev']
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: test - ['data/xhosa/xhosa.test']
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.3/xhosa'
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: init - 'init/test/large/seed-0/xhosa'
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: dropout - 0.3
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 00:56:56 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 00:56:56 - 0:00:00 - src vocab size 69
INFO - 10/17/22 00:56:56 - 0:00:00 - trg vocab size 66
INFO - 10/17/22 00:56:56 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 00:56:56 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 00:56:56 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(69, 100, padding_idx=0)
                                       (trg_embed): Embedding(66, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.3, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.3, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.3, inplace=False)
                                     )
INFO - 10/17/22 00:56:56 - 0:00:00 - number of parameter 1218766
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: train - ['data/xhosa/xhosa.train']
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: dev - ['data/xhosa/xhosa.dev']
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: test - ['data/xhosa/xhosa.test']
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.3/xhosa'
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: init - 'init/test/large/seed-0/xhosa/small'
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: dropout - 0.3
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 02:34:02 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 02:34:02 - 0:00:00 - src vocab size 69
INFO - 10/17/22 02:34:02 - 0:00:00 - trg vocab size 66
INFO - 10/17/22 02:34:02 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:34:02 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:34:02 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(69, 100, padding_idx=0)
                                       (trg_embed): Embedding(66, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.3, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.3, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.3, inplace=False)
                                     )
INFO - 10/17/22 02:34:02 - 0:00:00 - number of parameter 1218766
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: train - ['data/xhosa/xhosa.train']
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: dev - ['data/xhosa/xhosa.dev']
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: test - ['data/xhosa/xhosa.test']
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.3/xhosa'
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: init - ''
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: dropout - 0.3
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 06:36:13 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 06:36:14 - 0:00:00 - src vocab size 69
INFO - 10/17/22 06:36:14 - 0:00:00 - trg vocab size 66
INFO - 10/17/22 06:36:14 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 06:36:14 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 06:36:14 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(69, 100, padding_idx=0)
                                       (trg_embed): Embedding(66, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.3, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.3, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.3, inplace=False)
                                     )
INFO - 10/17/22 06:36:14 - 0:00:00 - number of parameter 1218766
INFO - 10/17/22 06:36:16 - 0:00:03 - maximum training 42200 steps (50 epochs)
INFO - 10/17/22 06:36:16 - 0:00:03 - evaluate every 1 epochs
INFO - 10/17/22 06:36:16 - 0:00:03 - At 0-th epoch with lr 0.001000.
INFO - 10/17/22 06:36:40 - 0:00:26 - Running average train loss is 0.4740390379767494 at epoch 0
INFO - 10/17/22 06:36:40 - 0:00:26 - At 1-th epoch with lr 0.001000.
INFO - 10/17/22 06:37:03 - 0:00:49 - Running average train loss is 0.16443664415064158 at epoch 1
INFO - 10/17/22 06:37:03 - 0:00:50 - Average dev loss is 0.10733682414626373 at epoch 1
INFO - 10/17/22 06:37:05 - 0:00:51 - dev accuracy is 64.8186 at epoch 1
INFO - 10/17/22 06:37:05 - 0:00:51 - dev phenome error rate is 0.0783 at epoch 1
INFO - 10/17/22 06:37:05 - 0:00:51 - At 2-th epoch with lr 0.001000.
INFO - 10/17/22 06:37:28 - 0:01:14 - Running average train loss is 0.11789656089292178 at epoch 2
INFO - 10/17/22 06:37:28 - 0:01:15 - Average dev loss is 0.08138882117893766 at epoch 2
INFO - 10/17/22 06:37:30 - 0:01:16 - dev accuracy is 72.3477 at epoch 2
INFO - 10/17/22 06:37:30 - 0:01:16 - dev phenome error rate is 0.0625 at epoch 2
INFO - 10/17/22 06:37:30 - 0:01:17 - At 3-th epoch with lr 0.001000.
INFO - 10/17/22 06:37:54 - 0:01:40 - Running average train loss is 0.09315111405564852 at epoch 3
INFO - 10/17/22 06:37:54 - 0:01:41 - Average dev loss is 0.0586966699865811 at epoch 3
INFO - 10/17/22 06:37:56 - 0:01:42 - dev accuracy is 77.8234 at epoch 3
INFO - 10/17/22 06:37:56 - 0:01:42 - dev phenome error rate is 0.0497 at epoch 3
INFO - 10/17/22 06:37:56 - 0:01:42 - At 4-th epoch with lr 0.001000.
INFO - 10/17/22 06:38:20 - 0:02:07 - Running average train loss is 0.07719481418403616 at epoch 4
INFO - 10/17/22 06:38:21 - 0:02:07 - Average dev loss is 0.04852141489220016 at epoch 4
INFO - 10/17/22 06:38:22 - 0:02:09 - dev accuracy is 81.1088 at epoch 4
INFO - 10/17/22 06:38:22 - 0:02:09 - dev phenome error rate is 0.0423 at epoch 4
INFO - 10/17/22 06:38:22 - 0:02:09 - At 5-th epoch with lr 0.001000.
INFO - 10/17/22 06:38:46 - 0:02:33 - Running average train loss is 0.06560750124022648 at epoch 5
INFO - 10/17/22 06:38:47 - 0:02:33 - Average dev loss is 0.04177910042926669 at epoch 5
INFO - 10/17/22 06:38:48 - 0:02:35 - dev accuracy is 83.8467 at epoch 5
INFO - 10/17/22 06:38:48 - 0:02:35 - dev phenome error rate is 0.0372 at epoch 5
INFO - 10/17/22 06:38:48 - 0:02:35 - At 6-th epoch with lr 0.001000.
INFO - 10/17/22 06:39:13 - 0:03:00 - Running average train loss is 0.056942650702918804 at epoch 6
INFO - 10/17/22 06:39:14 - 0:03:01 - Average dev loss is 0.032608511381070404 at epoch 6
INFO - 10/17/22 06:39:15 - 0:03:02 - dev accuracy is 86.7214 at epoch 6
INFO - 10/17/22 06:39:15 - 0:03:02 - dev phenome error rate is 0.0285 at epoch 6
INFO - 10/17/22 06:39:15 - 0:03:02 - At 7-th epoch with lr 0.001000.
INFO - 10/17/22 06:39:40 - 0:03:26 - Running average train loss is 0.05096796308688254 at epoch 7
INFO - 10/17/22 06:39:40 - 0:03:27 - Average dev loss is 0.02814326764029615 at epoch 7
INFO - 10/17/22 06:39:42 - 0:03:28 - dev accuracy is 88.2957 at epoch 7
INFO - 10/17/22 06:39:42 - 0:03:28 - dev phenome error rate is 0.0271 at epoch 7
INFO - 10/17/22 06:39:42 - 0:03:28 - At 8-th epoch with lr 0.001000.
INFO - 10/17/22 06:40:06 - 0:03:53 - Running average train loss is 0.04463279535370477 at epoch 8
INFO - 10/17/22 06:40:07 - 0:03:53 - Average dev loss is 0.023260093310519175 at epoch 8
INFO - 10/17/22 06:40:08 - 0:03:55 - dev accuracy is 89.6646 at epoch 8
INFO - 10/17/22 06:40:08 - 0:03:55 - dev phenome error rate is 0.0261 at epoch 8
INFO - 10/17/22 06:40:08 - 0:03:55 - At 9-th epoch with lr 0.001000.
INFO - 10/17/22 06:40:32 - 0:04:19 - Running average train loss is 0.04058125984117883 at epoch 9
INFO - 10/17/22 06:40:33 - 0:04:20 - Average dev loss is 0.025838033224949066 at epoch 9
INFO - 10/17/22 06:40:34 - 0:04:21 - dev accuracy is 88.8433 at epoch 9
INFO - 10/17/22 06:40:34 - 0:04:21 - dev phenome error rate is 0.0333 at epoch 9
INFO - 10/17/22 06:40:35 - 0:04:21 - At 10-th epoch with lr 0.000500.
INFO - 10/17/22 06:40:58 - 0:04:45 - Running average train loss is 0.026321166596359958 at epoch 10
INFO - 10/17/22 06:40:59 - 0:04:45 - Average dev loss is 0.010402675190776148 at epoch 10
INFO - 10/17/22 06:41:00 - 0:04:47 - dev accuracy is 95.2088 at epoch 10
INFO - 10/17/22 06:41:00 - 0:04:47 - dev phenome error rate is 0.0116 at epoch 10
INFO - 10/17/22 06:41:00 - 0:04:47 - At 11-th epoch with lr 0.000500.
INFO - 10/17/22 06:41:26 - 0:05:12 - Running average train loss is 0.02053062757325438 at epoch 11
INFO - 10/17/22 06:41:26 - 0:05:13 - Average dev loss is 0.008660098385777982 at epoch 11
INFO - 10/17/22 06:41:28 - 0:05:14 - dev accuracy is 95.8248 at epoch 11
INFO - 10/17/22 06:41:28 - 0:05:14 - dev phenome error rate is 0.0099 at epoch 11
INFO - 10/17/22 06:41:28 - 0:05:14 - At 12-th epoch with lr 0.000500.
INFO - 10/17/22 06:41:54 - 0:05:41 - Running average train loss is 0.017220283118261452 at epoch 12
INFO - 10/17/22 06:41:55 - 0:05:42 - Average dev loss is 0.008343896221862558 at epoch 12
INFO - 10/17/22 06:41:57 - 0:05:43 - dev accuracy is 96.2355 at epoch 12
INFO - 10/17/22 06:41:57 - 0:05:43 - dev phenome error rate is 0.009 at epoch 12
INFO - 10/17/22 06:41:57 - 0:05:43 - At 13-th epoch with lr 0.000500.
INFO - 10/17/22 06:42:21 - 0:06:08 - Running average train loss is 0.01649409850882212 at epoch 13
INFO - 10/17/22 06:42:22 - 0:06:08 - Average dev loss is 0.007925004397710676 at epoch 13
INFO - 10/17/22 06:42:23 - 0:06:10 - dev accuracy is 97.1253 at epoch 13
INFO - 10/17/22 06:42:23 - 0:06:10 - dev phenome error rate is 0.0066 at epoch 13
INFO - 10/17/22 06:42:23 - 0:06:10 - At 14-th epoch with lr 0.000500.
INFO - 10/17/22 06:42:47 - 0:06:34 - Running average train loss is 0.014576535313599853 at epoch 14
INFO - 10/17/22 06:42:48 - 0:06:34 - Average dev loss is 0.00617106427465949 at epoch 14
INFO - 10/17/22 06:42:49 - 0:06:36 - dev accuracy is 97.1937 at epoch 14
INFO - 10/17/22 06:42:49 - 0:06:36 - dev phenome error rate is 0.0066 at epoch 14
INFO - 10/17/22 06:42:49 - 0:06:36 - At 15-th epoch with lr 0.000500.
INFO - 10/17/22 06:43:12 - 0:06:58 - Running average train loss is 0.013625878306953745 at epoch 15
INFO - 10/17/22 06:43:12 - 0:06:59 - Average dev loss is 0.004532338623025948 at epoch 15
INFO - 10/17/22 06:43:14 - 0:07:00 - dev accuracy is 97.8097 at epoch 15
INFO - 10/17/22 06:43:14 - 0:07:00 - dev phenome error rate is 0.0054 at epoch 15
INFO - 10/17/22 06:43:14 - 0:07:00 - At 16-th epoch with lr 0.000500.
INFO - 10/17/22 06:43:36 - 0:07:23 - Running average train loss is 0.013635662344158285 at epoch 16
INFO - 10/17/22 06:43:37 - 0:07:24 - Average dev loss is 0.004728273971362368 at epoch 16
INFO - 10/17/22 06:43:38 - 0:07:25 - dev accuracy is 97.8097 at epoch 16
INFO - 10/17/22 06:43:38 - 0:07:25 - dev phenome error rate is 0.0047 at epoch 16
INFO - 10/17/22 06:43:38 - 0:07:25 - At 17-th epoch with lr 0.000250.
INFO - 10/17/22 06:44:04 - 0:07:50 - Running average train loss is 0.009149927290279107 at epoch 17
INFO - 10/17/22 06:44:04 - 0:07:51 - Average dev loss is 0.003030361845808597 at epoch 17
INFO - 10/17/22 06:44:06 - 0:07:52 - dev accuracy is 98.9049 at epoch 17
INFO - 10/17/22 06:44:06 - 0:07:52 - dev phenome error rate is 0.0025 at epoch 17
INFO - 10/17/22 06:44:06 - 0:07:52 - At 18-th epoch with lr 0.000250.
INFO - 10/17/22 06:44:28 - 0:08:15 - Running average train loss is 0.007805945023370717 at epoch 18
INFO - 10/17/22 06:44:29 - 0:08:16 - Average dev loss is 0.002209318338667371 at epoch 18
INFO - 10/17/22 06:44:30 - 0:08:17 - dev accuracy is 99.3155 at epoch 18
INFO - 10/17/22 06:44:30 - 0:08:17 - dev phenome error rate is 0.0019 at epoch 18
INFO - 10/17/22 06:44:30 - 0:08:17 - At 19-th epoch with lr 0.000250.
INFO - 10/17/22 06:44:53 - 0:08:40 - Running average train loss is 0.007481633037555206 at epoch 19
INFO - 10/17/22 06:44:54 - 0:08:41 - Average dev loss is 0.0022267365824732493 at epoch 19
INFO - 10/17/22 06:44:55 - 0:08:42 - dev accuracy is 99.1786 at epoch 19
INFO - 10/17/22 06:44:55 - 0:08:42 - dev phenome error rate is 0.0019 at epoch 19
INFO - 10/17/22 06:44:56 - 0:08:42 - At 20-th epoch with lr 0.000125.
INFO - 10/17/22 06:45:20 - 0:09:06 - Running average train loss is 0.005996605168453002 at epoch 20
INFO - 10/17/22 06:45:20 - 0:09:07 - Average dev loss is 0.0016208402074613226 at epoch 20
INFO - 10/17/22 06:45:22 - 0:09:08 - dev accuracy is 99.4524 at epoch 20
INFO - 10/17/22 06:45:22 - 0:09:08 - dev phenome error rate is 0.0019 at epoch 20
INFO - 10/17/22 06:45:22 - 0:09:08 - At 21-th epoch with lr 0.000125.
INFO - 10/17/22 06:45:45 - 0:09:32 - Running average train loss is 0.005094206464551781 at epoch 21
INFO - 10/17/22 06:45:46 - 0:09:33 - Average dev loss is 0.0012527002193725338 at epoch 21
INFO - 10/17/22 06:45:47 - 0:09:34 - dev accuracy is 99.5893 at epoch 21
INFO - 10/17/22 06:45:47 - 0:09:34 - dev phenome error rate is 0.0012 at epoch 21
INFO - 10/17/22 06:45:48 - 0:09:34 - At 22-th epoch with lr 0.000125.
INFO - 10/17/22 06:46:14 - 0:10:00 - Running average train loss is 0.004820857582947899 at epoch 22
INFO - 10/17/22 06:46:14 - 0:10:01 - Average dev loss is 0.001385367039919776 at epoch 22
INFO - 10/17/22 06:46:16 - 0:10:03 - dev accuracy is 99.4524 at epoch 22
INFO - 10/17/22 06:46:16 - 0:10:03 - dev phenome error rate is 0.0016 at epoch 22
INFO - 10/17/22 06:46:16 - 0:10:03 - At 23-th epoch with lr 0.000063.
INFO - 10/17/22 06:46:42 - 0:10:29 - Running average train loss is 0.004287938571401808 at epoch 23
INFO - 10/17/22 06:46:43 - 0:10:30 - Average dev loss is 0.0011945181783042191 at epoch 23
INFO - 10/17/22 06:46:45 - 0:10:31 - dev accuracy is 99.5209 at epoch 23
INFO - 10/17/22 06:46:45 - 0:10:31 - dev phenome error rate is 0.0016 at epoch 23
INFO - 10/17/22 06:46:45 - 0:10:31 - At 24-th epoch with lr 0.000063.
INFO - 10/17/22 06:47:11 - 0:10:57 - Running average train loss is 0.00397947561515824 at epoch 24
INFO - 10/17/22 06:47:12 - 0:10:58 - Average dev loss is 0.0010887915707665824 at epoch 24
INFO - 10/17/22 06:47:13 - 0:11:00 - dev accuracy is 99.5893 at epoch 24
INFO - 10/17/22 06:47:13 - 0:11:00 - dev phenome error rate is 0.0014 at epoch 24
INFO - 10/17/22 06:47:13 - 0:11:00 - At 25-th epoch with lr 0.000063.
INFO - 10/17/22 06:47:39 - 0:11:26 - Running average train loss is 0.0036793185423810524 at epoch 25
INFO - 10/17/22 06:47:40 - 0:11:27 - Average dev loss is 0.0010301480178467875 at epoch 25
INFO - 10/17/22 06:47:42 - 0:11:28 - dev accuracy is 99.5893 at epoch 25
INFO - 10/17/22 06:47:42 - 0:11:28 - dev phenome error rate is 0.0014 at epoch 25
INFO - 10/17/22 06:47:42 - 0:11:28 - At 26-th epoch with lr 0.000063.
INFO - 10/17/22 06:48:08 - 0:11:54 - Running average train loss is 0.0036932150785377034 at epoch 26
INFO - 10/17/22 06:48:09 - 0:11:55 - Average dev loss is 0.0010051261338744285 at epoch 26
INFO - 10/17/22 06:48:10 - 0:11:57 - dev accuracy is 99.7262 at epoch 26
INFO - 10/17/22 06:48:10 - 0:11:57 - dev phenome error rate is 0.0009 at epoch 26
INFO - 10/17/22 06:48:10 - 0:11:57 - At 27-th epoch with lr 0.000063.
INFO - 10/17/22 06:48:34 - 0:12:21 - Running average train loss is 0.0036356936244455983 at epoch 27
INFO - 10/17/22 06:48:35 - 0:12:22 - Average dev loss is 0.0009447545174386024 at epoch 27
INFO - 10/17/22 06:48:36 - 0:12:23 - dev accuracy is 99.6578 at epoch 27
INFO - 10/17/22 06:48:36 - 0:12:23 - dev phenome error rate is 0.0012 at epoch 27
INFO - 10/17/22 06:48:36 - 0:12:23 - At 28-th epoch with lr 0.000063.
INFO - 10/17/22 06:48:59 - 0:12:46 - Running average train loss is 0.003511002675825465 at epoch 28
INFO - 10/17/22 06:49:00 - 0:12:46 - Average dev loss is 0.0009581226326083518 at epoch 28
INFO - 10/17/22 06:49:01 - 0:12:48 - dev accuracy is 99.7947 at epoch 28
INFO - 10/17/22 06:49:01 - 0:12:48 - dev phenome error rate is 0.0007 at epoch 28
INFO - 10/17/22 06:49:01 - 0:12:48 - At 29-th epoch with lr 0.000031.
INFO - 10/17/22 06:49:24 - 0:13:10 - Running average train loss is 0.0032293767866516327 at epoch 29
INFO - 10/17/22 06:49:24 - 0:13:11 - Average dev loss is 0.000795951241033275 at epoch 29
INFO - 10/17/22 06:49:26 - 0:13:12 - dev accuracy is 99.8631 at epoch 29
INFO - 10/17/22 06:49:26 - 0:13:12 - dev phenome error rate is 0.0007 at epoch 29
INFO - 10/17/22 06:49:26 - 0:13:12 - At 30-th epoch with lr 0.000031.
INFO - 10/17/22 06:49:48 - 0:13:35 - Running average train loss is 0.0032199091935421753 at epoch 30
INFO - 10/17/22 06:49:49 - 0:13:36 - Average dev loss is 0.000822754007693969 at epoch 30
INFO - 10/17/22 06:49:51 - 0:13:37 - dev accuracy is 99.7947 at epoch 30
INFO - 10/17/22 06:49:51 - 0:13:37 - dev phenome error rate is 0.0008 at epoch 30
INFO - 10/17/22 06:49:51 - 0:13:37 - At 31-th epoch with lr 0.000016.
INFO - 10/17/22 06:50:13 - 0:14:00 - Running average train loss is 0.002874893288867605 at epoch 31
INFO - 10/17/22 06:50:14 - 0:14:01 - Average dev loss is 0.0007826524398885393 at epoch 31
INFO - 10/17/22 06:50:15 - 0:14:02 - dev accuracy is 99.7947 at epoch 31
INFO - 10/17/22 06:50:15 - 0:14:02 - dev phenome error rate is 0.0008 at epoch 31
INFO - 10/17/22 06:50:15 - 0:14:02 - At 32-th epoch with lr 0.000016.
INFO - 10/17/22 06:50:38 - 0:14:25 - Running average train loss is 0.002809964112663792 at epoch 32
INFO - 10/17/22 06:50:39 - 0:14:25 - Average dev loss is 0.0007715410339776153 at epoch 32
INFO - 10/17/22 06:50:40 - 0:14:27 - dev accuracy is 99.7947 at epoch 32
INFO - 10/17/22 06:50:40 - 0:14:27 - dev phenome error rate is 0.0008 at epoch 32
INFO - 10/17/22 06:50:40 - 0:14:27 - At 33-th epoch with lr 0.000016.
INFO - 10/17/22 06:51:03 - 0:14:50 - Running average train loss is 0.0028154391413271096 at epoch 33
INFO - 10/17/22 06:51:04 - 0:14:50 - Average dev loss is 0.0007545137110676424 at epoch 33
INFO - 10/17/22 06:51:05 - 0:14:52 - dev accuracy is 99.7262 at epoch 33
INFO - 10/17/22 06:51:05 - 0:14:52 - dev phenome error rate is 0.001 at epoch 33
INFO - 10/17/22 06:51:05 - 0:14:52 - At 34-th epoch with lr 0.000016.
INFO - 10/17/22 06:51:28 - 0:15:14 - Running average train loss is 0.0027916102048624954 at epoch 34
INFO - 10/17/22 06:51:28 - 0:15:15 - Average dev loss is 0.0007228256914994049 at epoch 34
INFO - 10/17/22 06:51:30 - 0:15:16 - dev accuracy is 99.8631 at epoch 34
INFO - 10/17/22 06:51:30 - 0:15:16 - dev phenome error rate is 0.0007 at epoch 34
INFO - 10/17/22 06:51:30 - 0:15:16 - At 35-th epoch with lr 0.000016.
INFO - 10/17/22 06:51:53 - 0:15:39 - Running average train loss is 0.0028140795630296586 at epoch 35
INFO - 10/17/22 06:51:53 - 0:15:40 - Average dev loss is 0.0007324230533627355 at epoch 35
INFO - 10/17/22 06:51:55 - 0:15:41 - dev accuracy is 99.7262 at epoch 35
INFO - 10/17/22 06:51:55 - 0:15:41 - dev phenome error rate is 0.001 at epoch 35
INFO - 10/17/22 06:51:55 - 0:15:41 - At 36-th epoch with lr 0.000010.
INFO - 10/17/22 06:52:17 - 0:16:04 - Running average train loss is 0.0027731218811926505 at epoch 36
INFO - 10/17/22 06:52:18 - 0:16:05 - Average dev loss is 0.000705606493027196 at epoch 36
INFO - 10/17/22 06:52:20 - 0:16:06 - dev accuracy is 99.7262 at epoch 36
INFO - 10/17/22 06:52:20 - 0:16:06 - dev phenome error rate is 0.001 at epoch 36
INFO - 10/17/22 06:52:20 - 0:16:06 - At 37-th epoch with lr 0.000010.
INFO - 10/17/22 06:52:42 - 0:16:29 - Running average train loss is 0.0027975935725459635 at epoch 37
INFO - 10/17/22 06:52:43 - 0:16:30 - Average dev loss is 0.0006797779819702127 at epoch 37
INFO - 10/17/22 06:52:44 - 0:16:31 - dev accuracy is 99.7947 at epoch 37
INFO - 10/17/22 06:52:44 - 0:16:31 - dev phenome error rate is 0.0008 at epoch 37
INFO - 10/17/22 06:52:44 - 0:16:31 - At 38-th epoch with lr 0.000010.
INFO - 10/17/22 06:53:07 - 0:16:54 - Running average train loss is 0.0026712499185334517 at epoch 38
INFO - 10/17/22 06:53:08 - 0:16:54 - Average dev loss is 0.0006645190039040137 at epoch 38
INFO - 10/17/22 06:53:09 - 0:16:56 - dev accuracy is 99.7947 at epoch 38
INFO - 10/17/22 06:53:09 - 0:16:56 - dev phenome error rate is 0.0008 at epoch 38
INFO - 10/17/22 06:53:09 - 0:16:56 - At 39-th epoch with lr 0.000010.
INFO - 10/17/22 06:53:32 - 0:17:19 - Running average train loss is 0.002908748371310872 at epoch 39
INFO - 10/17/22 06:53:33 - 0:17:19 - Average dev loss is 0.0006603636558900368 at epoch 39
INFO - 10/17/22 06:53:34 - 0:17:21 - dev accuracy is 99.7947 at epoch 39
INFO - 10/17/22 06:53:34 - 0:17:21 - dev phenome error rate is 0.0009 at epoch 39
INFO - 10/17/22 06:53:34 - 0:17:21 - At 40-th epoch with lr 0.000010.
INFO - 10/17/22 06:53:57 - 0:17:43 - Running average train loss is 0.002694986895281864 at epoch 40
INFO - 10/17/22 06:53:58 - 0:17:44 - Average dev loss is 0.0006416500539190191 at epoch 40
INFO - 10/17/22 06:53:59 - 0:17:46 - dev accuracy is 99.8631 at epoch 40
INFO - 10/17/22 06:53:59 - 0:17:46 - dev phenome error rate is 0.0006 at epoch 40
INFO - 10/17/22 06:53:59 - 0:17:46 - At 41-th epoch with lr 0.000010.
INFO - 10/17/22 06:54:22 - 0:18:08 - Running average train loss is 0.0026890391906184336 at epoch 41
INFO - 10/17/22 06:54:23 - 0:18:09 - Average dev loss is 0.0006454151613819276 at epoch 41
INFO - 10/17/22 06:54:24 - 0:18:11 - dev accuracy is 99.8631 at epoch 41
INFO - 10/17/22 06:54:24 - 0:18:11 - dev phenome error rate is 0.0006 at epoch 41
INFO - 10/17/22 06:54:24 - 0:18:11 - Early stopping triggered with epoch 41 (previous dev loss: 0.000642, current: 0.000645)
INFO - 10/17/22 06:54:24 - 0:18:11 - loading model/test/hardattention/small/transformer0.3/xhosa.nll_0.0006.acc_99.8631.per_0.0006.epoch_40 for testing
INFO - 10/17/22 06:54:24 - 0:18:11 - load model in model/test/hardattention/small/transformer0.3/xhosa.nll_0.0006.acc_99.8631.per_0.0006.epoch_40
INFO - 10/17/22 06:54:25 - 0:18:11 - Average dev loss is 0.0006416500539190191 at epoch -1
INFO - 10/17/22 06:54:25 - 0:18:11 - decoding dev set
INFO - 10/17/22 06:54:27 - 0:18:14 - finished decoding 1687 dev instance
INFO - 10/17/22 06:54:27 - 0:18:14 - DEV accuracy is 99.8631 at epoch -1
INFO - 10/17/22 06:54:27 - 0:18:14 - DEV phenome error rate is 0.0006 at epoch -1
INFO - 10/17/22 06:54:27 - 0:18:14 - DEV xhosa acc 99.8631 per 0.0006
INFO - 10/17/22 06:54:28 - 0:18:15 - Average test loss is 0.3998297229840957 at epoch -1
INFO - 10/17/22 06:54:28 - 0:18:15 - decoding test set
INFO - 10/17/22 06:54:32 - 0:18:19 - finished decoding 3003 test instance
INFO - 10/17/22 06:54:32 - 0:18:19 - TEST accuracy is 56.401 at epoch -1
INFO - 10/17/22 06:54:32 - 0:18:19 - TEST phenome error rate is 0.1133 at epoch -1
INFO - 10/17/22 06:54:32 - 0:18:19 - TEST xhosa acc 56.401 per 0.1133
