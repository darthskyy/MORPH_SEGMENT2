INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: train - ['data/swati/swati.train']
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: dev - ['data/swati/swati.dev']
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: test - ['data/swati/swati.test']
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.2/swati'
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: init - 'init/test/large/seed-0/swati'
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: dropout - 0.2
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 00:57:46 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 00:57:46 - 0:00:00 - src vocab size 70
INFO - 10/17/22 00:57:46 - 0:00:00 - trg vocab size 71
INFO - 10/17/22 00:57:46 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 00:57:46 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 00:57:46 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(70, 100, padding_idx=0)
                                       (trg_embed): Embedding(71, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.2, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.2, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=71, bias=True)
                                       (dropout): Dropout(p=0.2, inplace=False)
                                     )
INFO - 10/17/22 00:57:46 - 0:00:00 - number of parameter 1222371
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: train - ['data/swati/swati.train']
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: dev - ['data/swati/swati.dev']
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: test - ['data/swati/swati.test']
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.2/swati'
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: init - 'init/test/large/seed-0/swati'
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: dropout - 0.2
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 02:25:28 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 02:25:28 - 0:00:00 - src vocab size 70
INFO - 10/17/22 02:25:28 - 0:00:00 - trg vocab size 71
INFO - 10/17/22 02:25:28 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:25:28 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:25:28 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(70, 100, padding_idx=0)
                                       (trg_embed): Embedding(71, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.2, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.2, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=71, bias=True)
                                       (dropout): Dropout(p=0.2, inplace=False)
                                     )
INFO - 10/17/22 02:25:28 - 0:00:00 - number of parameter 1222371
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: train - ['data/swati/swati.train']
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: dev - ['data/swati/swati.dev']
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: test - ['data/swati/swati.test']
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.2/swati'
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: init - 'init/test/large/seed-0/swati/small'
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: dropout - 0.2
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 02:32:50 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 02:32:51 - 0:00:00 - src vocab size 70
INFO - 10/17/22 02:32:51 - 0:00:00 - trg vocab size 71
INFO - 10/17/22 02:32:51 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:32:51 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 02:32:51 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(70, 100, padding_idx=0)
                                       (trg_embed): Embedding(71, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.2, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.2, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=71, bias=True)
                                       (dropout): Dropout(p=0.2, inplace=False)
                                     )
INFO - 10/17/22 02:32:51 - 0:00:00 - number of parameter 1222371
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: seed - 0
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: train - ['data/swati/swati.train']
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: dev - ['data/swati/swati.dev']
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: test - ['data/swati/swati.test']
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: model - 'model/test/hardattention/small/transformer0.2/swati'
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: load - ''
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: bs - 20
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: epochs - 50
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: patience - 0
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: max_norm - 0
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: saveall - False
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: shuffle - False
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: init - ''
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: dropout - 0.2
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: embed_dim - 100
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: src_layer - 1
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: src_hs - 200
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: trg_hs - 200
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: nb_sample - 2
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: indtag - False
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: mono - False
INFO - 10/17/22 07:05:09 - 0:00:00 - command line argument: bestacc - False
INFO - 10/17/22 07:05:09 - 0:00:00 - src vocab size 70
INFO - 10/17/22 07:05:09 - 0:00:00 - trg vocab size 71
INFO - 10/17/22 07:05:09 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 07:05:09 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/17/22 07:05:09 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(70, 100, padding_idx=0)
                                       (trg_embed): Embedding(71, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.2, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.2, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=71, bias=True)
                                       (dropout): Dropout(p=0.2, inplace=False)
                                     )
INFO - 10/17/22 07:05:09 - 0:00:00 - number of parameter 1222371
INFO - 10/17/22 07:05:11 - 0:00:02 - maximum training 27000 steps (50 epochs)
INFO - 10/17/22 07:05:11 - 0:00:02 - evaluate every 1 epochs
INFO - 10/17/22 07:05:11 - 0:00:02 - At 0-th epoch with lr 0.001000.
INFO - 10/17/22 07:05:24 - 0:00:16 - Running average train loss is 0.4366777005053505 at epoch 0
INFO - 10/17/22 07:05:24 - 0:00:16 - At 1-th epoch with lr 0.001000.
INFO - 10/17/22 07:05:37 - 0:00:28 - Running average train loss is 0.09156795276708349 at epoch 1
INFO - 10/17/22 07:05:37 - 0:00:29 - Average dev loss is 0.04861334406046404 at epoch 1
INFO - 10/17/22 07:05:38 - 0:00:30 - dev accuracy is 82.7543 at epoch 1
INFO - 10/17/22 07:05:38 - 0:00:30 - dev phenome error rate is 0.0403 at epoch 1
INFO - 10/17/22 07:05:38 - 0:00:30 - At 2-th epoch with lr 0.001000.
INFO - 10/17/22 07:05:51 - 0:00:43 - Running average train loss is 0.058351039890786285 at epoch 2
INFO - 10/17/22 07:05:52 - 0:00:43 - Average dev loss is 0.041422285268911056 at epoch 2
INFO - 10/17/22 07:05:52 - 0:00:44 - dev accuracy is 86.3524 at epoch 2
INFO - 10/17/22 07:05:52 - 0:00:44 - dev phenome error rate is 0.0349 at epoch 2
INFO - 10/17/22 07:05:52 - 0:00:44 - At 3-th epoch with lr 0.001000.
INFO - 10/17/22 07:06:05 - 0:00:57 - Running average train loss is 0.043062358779436045 at epoch 3
INFO - 10/17/22 07:06:06 - 0:00:57 - Average dev loss is 0.03397234095070787 at epoch 3
INFO - 10/17/22 07:06:06 - 0:00:58 - dev accuracy is 89.0819 at epoch 3
INFO - 10/17/22 07:06:06 - 0:00:58 - dev phenome error rate is 0.0218 at epoch 3
INFO - 10/17/22 07:06:06 - 0:00:58 - At 4-th epoch with lr 0.001000.
INFO - 10/17/22 07:06:19 - 0:01:11 - Running average train loss is 0.03597117846128876 at epoch 4
INFO - 10/17/22 07:06:20 - 0:01:11 - Average dev loss is 0.03115448635179308 at epoch 4
INFO - 10/17/22 07:06:20 - 0:01:12 - dev accuracy is 88.2134 at epoch 4
INFO - 10/17/22 07:06:20 - 0:01:12 - dev phenome error rate is 0.0223 at epoch 4
INFO - 10/17/22 07:06:20 - 0:01:12 - At 5-th epoch with lr 0.001000.
INFO - 10/17/22 07:06:33 - 0:01:25 - Running average train loss is 0.029194995058329638 at epoch 5
INFO - 10/17/22 07:06:34 - 0:01:25 - Average dev loss is 0.021828493052722747 at epoch 5
INFO - 10/17/22 07:06:34 - 0:01:26 - dev accuracy is 92.1836 at epoch 5
INFO - 10/17/22 07:06:34 - 0:01:26 - dev phenome error rate is 0.0148 at epoch 5
INFO - 10/17/22 07:06:34 - 0:01:26 - At 6-th epoch with lr 0.001000.
INFO - 10/17/22 07:06:47 - 0:01:39 - Running average train loss is 0.02715748976765166 at epoch 6
INFO - 10/17/22 07:06:48 - 0:01:39 - Average dev loss is 0.028486104063362022 at epoch 6
INFO - 10/17/22 07:06:48 - 0:01:40 - dev accuracy is 92.6799 at epoch 6
INFO - 10/17/22 07:06:48 - 0:01:40 - dev phenome error rate is 0.0144 at epoch 6
INFO - 10/17/22 07:06:48 - 0:01:40 - At 7-th epoch with lr 0.000500.
INFO - 10/17/22 07:07:01 - 0:01:53 - Running average train loss is 0.01558899598797628 at epoch 7
INFO - 10/17/22 07:07:02 - 0:01:53 - Average dev loss is 0.0063274831333762485 at epoch 7
INFO - 10/17/22 07:07:02 - 0:01:54 - dev accuracy is 97.5186 at epoch 7
INFO - 10/17/22 07:07:02 - 0:01:54 - dev phenome error rate is 0.0043 at epoch 7
INFO - 10/17/22 07:07:02 - 0:01:54 - At 8-th epoch with lr 0.000500.
INFO - 10/17/22 07:07:15 - 0:02:07 - Running average train loss is 0.00937074497552304 at epoch 8
INFO - 10/17/22 07:07:16 - 0:02:07 - Average dev loss is 0.004458771347816326 at epoch 8
INFO - 10/17/22 07:07:16 - 0:02:08 - dev accuracy is 98.263 at epoch 8
INFO - 10/17/22 07:07:16 - 0:02:08 - dev phenome error rate is 0.0038 at epoch 8
INFO - 10/17/22 07:07:16 - 0:02:08 - At 9-th epoch with lr 0.000500.
INFO - 10/17/22 07:07:29 - 0:02:21 - Running average train loss is 0.008361356273855092 at epoch 9
INFO - 10/17/22 07:07:30 - 0:02:21 - Average dev loss is 0.00552959678626158 at epoch 9
INFO - 10/17/22 07:07:30 - 0:02:22 - dev accuracy is 97.7667 at epoch 9
INFO - 10/17/22 07:07:30 - 0:02:22 - dev phenome error rate is 0.0127 at epoch 9
INFO - 10/17/22 07:07:30 - 0:02:22 - At 10-th epoch with lr 0.000250.
INFO - 10/17/22 07:07:43 - 0:02:35 - Running average train loss is 0.005926908265704427 at epoch 10
INFO - 10/17/22 07:07:44 - 0:02:35 - Average dev loss is 0.002372588739860846 at epoch 10
INFO - 10/17/22 07:07:44 - 0:02:36 - dev accuracy is 98.7593 at epoch 10
INFO - 10/17/22 07:07:44 - 0:02:36 - dev phenome error rate is 0.002 at epoch 10
INFO - 10/17/22 07:07:44 - 0:02:36 - At 11-th epoch with lr 0.000250.
INFO - 10/17/22 07:07:57 - 0:02:49 - Running average train loss is 0.004463467379833606 at epoch 11
INFO - 10/17/22 07:07:58 - 0:02:49 - Average dev loss is 0.0020777990628428394 at epoch 11
INFO - 10/17/22 07:07:58 - 0:02:50 - dev accuracy is 99.3797 at epoch 11
INFO - 10/17/22 07:07:58 - 0:02:50 - dev phenome error rate is 0.0015 at epoch 11
INFO - 10/17/22 07:07:58 - 0:02:50 - At 12-th epoch with lr 0.000250.
INFO - 10/17/22 07:08:11 - 0:03:03 - Running average train loss is 0.004136000777577499 at epoch 12
INFO - 10/17/22 07:08:12 - 0:03:03 - Average dev loss is 0.00174856499810024 at epoch 12
INFO - 10/17/22 07:08:12 - 0:03:04 - dev accuracy is 99.5037 at epoch 12
INFO - 10/17/22 07:08:12 - 0:03:04 - dev phenome error rate is 0.0007 at epoch 12
INFO - 10/17/22 07:08:12 - 0:03:04 - At 13-th epoch with lr 0.000250.
INFO - 10/17/22 07:08:25 - 0:03:17 - Running average train loss is 0.003919204020389265 at epoch 13
INFO - 10/17/22 07:08:26 - 0:03:17 - Average dev loss is 0.0014102800630805884 at epoch 13
INFO - 10/17/22 07:08:26 - 0:03:18 - dev accuracy is 99.6278 at epoch 13
INFO - 10/17/22 07:08:26 - 0:03:18 - dev phenome error rate is 0.0006 at epoch 13
INFO - 10/17/22 07:08:26 - 0:03:18 - At 14-th epoch with lr 0.000250.
INFO - 10/17/22 07:08:39 - 0:03:30 - Running average train loss is 0.003770587647718289 at epoch 14
INFO - 10/17/22 07:08:39 - 0:03:31 - Average dev loss is 0.0018095350926025141 at epoch 14
INFO - 10/17/22 07:08:40 - 0:03:31 - dev accuracy is 99.7519 at epoch 14
INFO - 10/17/22 07:08:40 - 0:03:31 - dev phenome error rate is 0.0005 at epoch 14
INFO - 10/17/22 07:08:40 - 0:03:31 - At 15-th epoch with lr 0.000125.
INFO - 10/17/22 07:08:53 - 0:03:44 - Running average train loss is 0.0031264082781692396 at epoch 15
INFO - 10/17/22 07:08:53 - 0:03:45 - Average dev loss is 0.0010216042505312038 at epoch 15
INFO - 10/17/22 07:08:54 - 0:03:45 - dev accuracy is 99.8759 at epoch 15
INFO - 10/17/22 07:08:54 - 0:03:45 - dev phenome error rate is 0.0002 at epoch 15
INFO - 10/17/22 07:08:54 - 0:03:45 - At 16-th epoch with lr 0.000125.
INFO - 10/17/22 07:09:07 - 0:03:58 - Running average train loss is 0.0024910701105168467 at epoch 16
INFO - 10/17/22 07:09:07 - 0:03:58 - Average dev loss is 0.0008480839420641401 at epoch 16
INFO - 10/17/22 07:09:08 - 0:03:59 - dev accuracy is 99.7519 at epoch 16
INFO - 10/17/22 07:09:08 - 0:03:59 - dev phenome error rate is 0.0004 at epoch 16
INFO - 10/17/22 07:09:08 - 0:03:59 - At 17-th epoch with lr 0.000125.
INFO - 10/17/22 07:09:20 - 0:04:12 - Running average train loss is 0.0021077520427988257 at epoch 17
INFO - 10/17/22 07:09:21 - 0:04:12 - Average dev loss is 0.0008987393750296043 at epoch 17
INFO - 10/17/22 07:09:21 - 0:04:13 - dev accuracy is 99.7519 at epoch 17
INFO - 10/17/22 07:09:21 - 0:04:13 - dev phenome error rate is 0.0004 at epoch 17
INFO - 10/17/22 07:09:21 - 0:04:13 - At 18-th epoch with lr 0.000063.
INFO - 10/17/22 07:09:34 - 0:04:26 - Running average train loss is 0.0018998102516451143 at epoch 18
INFO - 10/17/22 07:09:35 - 0:04:26 - Average dev loss is 0.0006448578772135618 at epoch 18
INFO - 10/17/22 07:09:35 - 0:04:27 - dev accuracy is 99.8759 at epoch 18
INFO - 10/17/22 07:09:35 - 0:04:27 - dev phenome error rate is 0.0002 at epoch 18
INFO - 10/17/22 07:09:35 - 0:04:27 - At 19-th epoch with lr 0.000063.
INFO - 10/17/22 07:09:48 - 0:04:39 - Running average train loss is 0.0019070127341331467 at epoch 19
INFO - 10/17/22 07:09:48 - 0:04:40 - Average dev loss is 0.0006130478402189544 at epoch 19
INFO - 10/17/22 07:09:49 - 0:04:40 - dev accuracy is 99.8759 at epoch 19
INFO - 10/17/22 07:09:49 - 0:04:40 - dev phenome error rate is 0.0002 at epoch 19
INFO - 10/17/22 07:09:49 - 0:04:40 - At 20-th epoch with lr 0.000063.
INFO - 10/17/22 07:10:02 - 0:04:53 - Running average train loss is 0.0017221541222035605 at epoch 20
INFO - 10/17/22 07:10:02 - 0:04:53 - Average dev loss is 0.0007115528591115166 at epoch 20
INFO - 10/17/22 07:10:03 - 0:04:54 - dev accuracy is 99.8759 at epoch 20
INFO - 10/17/22 07:10:03 - 0:04:54 - dev phenome error rate is 0.0002 at epoch 20
INFO - 10/17/22 07:10:03 - 0:04:54 - At 21-th epoch with lr 0.000031.
INFO - 10/17/22 07:10:15 - 0:05:07 - Running average train loss is 0.001495981102706773 at epoch 21
INFO - 10/17/22 07:10:16 - 0:05:07 - Average dev loss is 0.0005646480565162535 at epoch 21
INFO - 10/17/22 07:10:16 - 0:05:08 - dev accuracy is 99.8759 at epoch 21
INFO - 10/17/22 07:10:16 - 0:05:08 - dev phenome error rate is 0.0002 at epoch 21
INFO - 10/17/22 07:10:16 - 0:05:08 - At 22-th epoch with lr 0.000031.
INFO - 10/17/22 07:10:29 - 0:05:20 - Running average train loss is 0.001470089428996154 at epoch 22
INFO - 10/17/22 07:10:29 - 0:05:21 - Average dev loss is 0.0005685587539792996 at epoch 22
INFO - 10/17/22 07:10:30 - 0:05:21 - dev accuracy is 99.8759 at epoch 22
INFO - 10/17/22 07:10:30 - 0:05:21 - dev phenome error rate is 0.0002 at epoch 22
INFO - 10/17/22 07:10:30 - 0:05:21 - At 23-th epoch with lr 0.000016.
INFO - 10/17/22 07:10:43 - 0:05:34 - Running average train loss is 0.0014344650833798503 at epoch 23
INFO - 10/17/22 07:10:43 - 0:05:34 - Average dev loss is 0.0005434559438813098 at epoch 23
INFO - 10/17/22 07:10:44 - 0:05:35 - dev accuracy is 99.8759 at epoch 23
INFO - 10/17/22 07:10:44 - 0:05:35 - dev phenome error rate is 0.0002 at epoch 23
INFO - 10/17/22 07:10:44 - 0:05:35 - At 24-th epoch with lr 0.000016.
INFO - 10/17/22 07:10:56 - 0:05:48 - Running average train loss is 0.0014371451426861178 at epoch 24
INFO - 10/17/22 07:10:57 - 0:05:48 - Average dev loss is 0.0005175929069688815 at epoch 24
INFO - 10/17/22 07:10:57 - 0:05:49 - dev accuracy is 99.8759 at epoch 24
INFO - 10/17/22 07:10:57 - 0:05:49 - dev phenome error rate is 0.0002 at epoch 24
INFO - 10/17/22 07:10:57 - 0:05:49 - At 25-th epoch with lr 0.000016.
INFO - 10/17/22 07:11:10 - 0:06:01 - Running average train loss is 0.0013925664077221343 at epoch 25
INFO - 10/17/22 07:11:10 - 0:06:02 - Average dev loss is 0.0004991919091413298 at epoch 25
INFO - 10/17/22 07:11:11 - 0:06:02 - dev accuracy is 99.8759 at epoch 25
INFO - 10/17/22 07:11:11 - 0:06:02 - dev phenome error rate is 0.0002 at epoch 25
INFO - 10/17/22 07:11:11 - 0:06:02 - At 26-th epoch with lr 0.000016.
INFO - 10/17/22 07:11:24 - 0:06:15 - Running average train loss is 0.001453031318885257 at epoch 26
INFO - 10/17/22 07:11:24 - 0:06:15 - Average dev loss is 0.0005146839326968162 at epoch 26
INFO - 10/17/22 07:11:25 - 0:06:16 - dev accuracy is 99.8759 at epoch 26
INFO - 10/17/22 07:11:25 - 0:06:16 - dev phenome error rate is 0.0002 at epoch 26
INFO - 10/17/22 07:11:25 - 0:06:16 - At 27-th epoch with lr 0.000010.
INFO - 10/17/22 07:11:37 - 0:06:29 - Running average train loss is 0.0013567746742578662 at epoch 27
INFO - 10/17/22 07:11:37 - 0:06:29 - Average dev loss is 0.0004866970747806826 at epoch 27
INFO - 10/17/22 07:11:38 - 0:06:30 - dev accuracy is 99.8759 at epoch 27
INFO - 10/17/22 07:11:38 - 0:06:30 - dev phenome error rate is 0.0002 at epoch 27
INFO - 10/17/22 07:11:38 - 0:06:30 - At 28-th epoch with lr 0.000010.
INFO - 10/17/22 07:11:51 - 0:06:42 - Running average train loss is 0.0012356191408259662 at epoch 28
INFO - 10/17/22 07:11:51 - 0:06:43 - Average dev loss is 0.00046322205852683746 at epoch 28
INFO - 10/17/22 07:11:52 - 0:06:43 - dev accuracy is 99.8759 at epoch 28
INFO - 10/17/22 07:11:52 - 0:06:43 - dev phenome error rate is 0.0002 at epoch 28
INFO - 10/17/22 07:11:52 - 0:06:43 - At 29-th epoch with lr 0.000010.
INFO - 10/17/22 07:12:04 - 0:06:56 - Running average train loss is 0.0012742566471287218 at epoch 29
INFO - 10/17/22 07:12:05 - 0:06:56 - Average dev loss is 0.00046496504492771 at epoch 29
INFO - 10/17/22 07:12:05 - 0:06:57 - dev accuracy is 99.8759 at epoch 29
INFO - 10/17/22 07:12:05 - 0:06:57 - dev phenome error rate is 0.0002 at epoch 29
INFO - 10/17/22 07:12:05 - 0:06:57 - Early stopping triggered with epoch 29 (previous dev loss: 0.000463, current: 0.000465)
INFO - 10/17/22 07:12:05 - 0:06:57 - loading model/test/hardattention/small/transformer0.2/swati.nll_0.0005.acc_99.8759.per_0.0002.epoch_28 for testing
INFO - 10/17/22 07:12:05 - 0:06:57 - load model in model/test/hardattention/small/transformer0.2/swati.nll_0.0005.acc_99.8759.per_0.0002.epoch_28
INFO - 10/17/22 07:12:06 - 0:06:57 - Average dev loss is 0.00046322205852683746 at epoch -1
INFO - 10/17/22 07:12:06 - 0:06:57 - decoding dev set
INFO - 10/17/22 07:12:07 - 0:06:58 - finished decoding 1079 dev instance
INFO - 10/17/22 07:12:07 - 0:06:58 - DEV accuracy is 99.8759 at epoch -1
INFO - 10/17/22 07:12:07 - 0:06:58 - DEV phenome error rate is 0.0002 at epoch -1
INFO - 10/17/22 07:12:07 - 0:06:58 - DEV swati acc 99.8759 per 0.0002
INFO - 10/17/22 07:12:09 - 0:07:00 - Average test loss is 0.42610383854108924 at epoch -1
INFO - 10/17/22 07:12:09 - 0:07:00 - decoding test set
INFO - 10/17/22 07:12:14 - 0:07:05 - finished decoding 5639 test instance
INFO - 10/17/22 07:12:14 - 0:07:05 - TEST accuracy is 73.2639 at epoch -1
INFO - 10/17/22 07:12:14 - 0:07:05 - TEST phenome error rate is 0.0523 at epoch -1
INFO - 10/17/22 07:12:14 - 0:07:05 - TEST swati acc 73.2639 per 0.0523
