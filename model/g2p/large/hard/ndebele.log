INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: seed - 0
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: train - ['data/ndebele/ndebele.train']
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: dev - ['data/ndebele/ndebele.dev']
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: test - ['data/ndebele/ndebele.test']
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: model - 'model/g2p/large/hard/ndebele'
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: load - ''
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: bs - 20
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: epochs - 50
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: patience - 0
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: max_norm - 5.0
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: saveall - False
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: shuffle - False
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: init - 'init/g2p/large/seed-0/ndebele'
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: dropout - 0.4
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: embed_dim - 200
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: src_layer - 2
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: src_hs - 400
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: trg_hs - 400
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: nb_sample - 4
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: indtag - False
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: mono - False
INFO - 10/05/22 20:52:34 - 0:00:00 - command line argument: bestacc - False
INFO - 10/05/22 20:52:34 - 0:00:00 - src vocab size 68
INFO - 10/05/22 20:52:34 - 0:00:00 - trg vocab size 66
INFO - 10/05/22 20:52:34 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/05/22 20:52:34 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', "'", '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/05/22 20:52:34 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(68, 200, padding_idx=0)
                                       (trg_embed): Embedding(66, 200, padding_idx=0)
                                       (enc_rnn): LSTM(200, 400, num_layers=2, dropout=0.4, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(200, 400)
                                         )
                                         (dropout): Dropout(p=0.4, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=800, out_features=400, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=1200, out_features=1200, bias=True)
                                       (final_out): Linear(in_features=1200, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.4, inplace=False)
                                     )
INFO - 10/05/22 20:52:34 - 0:00:00 - number of parameter 8603666
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: seed - 0
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: train - ['data/ndebele/ndebele.train']
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: dev - ['data/ndebele/ndebele.dev']
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: test - ['data/ndebele/ndebele.test']
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: model - 'model/g2p/large/hard/ndebele'
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: load - ''
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: bs - 20
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: epochs - 50
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: patience - 0
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: max_norm - 5.0
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: saveall - False
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: shuffle - False
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: init - 'init/g2p/large/seed-0/ndebele'
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: dropout - 0.4
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: embed_dim - 200
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: src_layer - 2
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: src_hs - 400
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: trg_hs - 400
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: nb_sample - 4
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: indtag - False
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: mono - False
INFO - 10/05/22 21:03:10 - 0:00:00 - command line argument: bestacc - False
INFO - 10/05/22 21:03:10 - 0:00:00 - src vocab size 68
INFO - 10/05/22 21:03:10 - 0:00:00 - trg vocab size 66
INFO - 10/05/22 21:03:10 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/05/22 21:03:10 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', "'", '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/05/22 21:03:10 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(68, 200, padding_idx=0)
                                       (trg_embed): Embedding(66, 200, padding_idx=0)
                                       (enc_rnn): LSTM(200, 400, num_layers=2, dropout=0.4, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(200, 400)
                                         )
                                         (dropout): Dropout(p=0.4, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=800, out_features=400, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=1200, out_features=1200, bias=True)
                                       (final_out): Linear(in_features=1200, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.4, inplace=False)
                                     )
INFO - 10/05/22 21:03:10 - 0:00:00 - number of parameter 8603666
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: seed - 0
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: train - ['data/ndebele/ndebele.train']
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: dev - ['data/ndebele/ndebele.dev']
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: test - ['data/ndebele/ndebele.test']
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: model - 'model/g2p/large/hard/ndebele'
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: load - ''
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: bs - 20
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: epochs - 50
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: patience - 0
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: max_norm - 5.0
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: saveall - False
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: shuffle - False
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: init - 'init/g2p/large/seed-0/ndebele'
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: dropout - 0.4
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: embed_dim - 200
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: src_layer - 2
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: src_hs - 400
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: trg_hs - 400
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: nb_sample - 4
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: indtag - False
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: mono - False
INFO - 10/05/22 21:06:37 - 0:00:00 - command line argument: bestacc - False
INFO - 10/05/22 21:06:37 - 0:00:00 - src vocab size 68
INFO - 10/05/22 21:06:37 - 0:00:00 - trg vocab size 66
INFO - 10/05/22 21:06:37 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/05/22 21:06:37 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', "'", '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/05/22 21:06:37 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(68, 200, padding_idx=0)
                                       (trg_embed): Embedding(66, 200, padding_idx=0)
                                       (enc_rnn): LSTM(200, 400, num_layers=2, dropout=0.4, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(200, 400)
                                         )
                                         (dropout): Dropout(p=0.4, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=800, out_features=400, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=1200, out_features=1200, bias=True)
                                       (final_out): Linear(in_features=1200, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.4, inplace=False)
                                     )
INFO - 10/05/22 21:06:37 - 0:00:00 - number of parameter 8603666
INFO - 10/05/22 21:06:39 - 0:00:02 - dump to init/g2p/large/seed-0/ndebele
INFO - 10/05/22 21:06:39 - 0:00:02 - maximum training 32350 steps (50 epochs)
INFO - 10/05/22 21:06:39 - 0:00:02 - evaluate every 1 epochs
INFO - 10/05/22 21:06:39 - 0:00:02 - At 0-th epoch with lr 0.001000.
INFO - 10/05/22 21:07:00 - 0:00:24 - Running average train loss is 0.4909946959252704 at epoch 0
INFO - 10/05/22 21:07:00 - 0:00:24 - At 1-th epoch with lr 0.001000.
INFO - 10/05/22 21:07:22 - 0:00:45 - Running average train loss is 0.18937006653783126 at epoch 1
INFO - 10/05/22 21:07:22 - 0:00:46 - Average dev loss is 0.14525898339656684 at epoch 1
INFO - 10/05/22 21:07:23 - 0:00:47 - dev accuracy is 56.0252 at epoch 1
INFO - 10/05/22 21:07:23 - 0:00:47 - dev phenome error rate is 0.0921 at epoch 1
INFO - 10/05/22 21:07:24 - 0:00:47 - At 2-th epoch with lr 0.001000.
INFO - 10/05/22 21:07:45 - 0:01:08 - Running average train loss is 0.13941666273719744 at epoch 2
INFO - 10/05/22 21:07:45 - 0:01:09 - Average dev loss is 0.1208742534311918 at epoch 2
INFO - 10/05/22 21:07:47 - 0:01:10 - dev accuracy is 61.1511 at epoch 2
INFO - 10/05/22 21:07:47 - 0:01:10 - dev phenome error rate is 0.109 at epoch 2
INFO - 10/05/22 21:07:47 - 0:01:11 - At 3-th epoch with lr 0.001000.
INFO - 10/05/22 21:08:08 - 0:01:32 - Running average train loss is 0.12066015916828993 at epoch 3
INFO - 10/05/22 21:08:09 - 0:01:32 - Average dev loss is 0.09285106997077282 at epoch 3
INFO - 10/05/22 21:08:10 - 0:01:33 - dev accuracy is 69.8741 at epoch 3
INFO - 10/05/22 21:08:10 - 0:01:33 - dev phenome error rate is 0.0607 at epoch 3
INFO - 10/05/22 21:08:10 - 0:01:34 - At 4-th epoch with lr 0.001000.
INFO - 10/05/22 21:08:31 - 0:01:55 - Running average train loss is 0.10174099576459418 at epoch 4
INFO - 10/05/22 21:08:32 - 0:01:55 - Average dev loss is 0.07740067349603542 at epoch 4
INFO - 10/05/22 21:08:33 - 0:01:57 - dev accuracy is 72.2122 at epoch 4
INFO - 10/05/22 21:08:33 - 0:01:57 - dev phenome error rate is 0.0471 at epoch 4
INFO - 10/05/22 21:08:33 - 0:01:57 - At 5-th epoch with lr 0.001000.
INFO - 10/05/22 21:08:54 - 0:02:18 - Running average train loss is 0.0910523539665263 at epoch 5
INFO - 10/05/22 21:08:55 - 0:02:18 - Average dev loss is 0.07417914893191595 at epoch 5
INFO - 10/05/22 21:08:56 - 0:02:20 - dev accuracy is 72.6619 at epoch 5
INFO - 10/05/22 21:08:56 - 0:02:20 - dev phenome error rate is 0.0475 at epoch 5
INFO - 10/05/22 21:08:57 - 0:02:20 - At 6-th epoch with lr 0.001000.
INFO - 10/05/22 21:09:18 - 0:02:41 - Running average train loss is 0.08430399366120421 at epoch 6
INFO - 10/05/22 21:09:18 - 0:02:42 - Average dev loss is 0.06082550401871021 at epoch 6
INFO - 10/05/22 21:09:19 - 0:02:43 - dev accuracy is 77.6079 at epoch 6
INFO - 10/05/22 21:09:19 - 0:02:43 - dev phenome error rate is 0.0339 at epoch 6
INFO - 10/05/22 21:09:20 - 0:02:43 - At 7-th epoch with lr 0.001000.
INFO - 10/05/22 21:09:41 - 0:03:04 - Running average train loss is 0.07146774112229658 at epoch 7
INFO - 10/05/22 21:09:42 - 0:03:05 - Average dev loss is 0.061581279050845365 at epoch 7
INFO - 10/05/22 21:09:43 - 0:03:06 - dev accuracy is 77.6079 at epoch 7
INFO - 10/05/22 21:09:43 - 0:03:06 - dev phenome error rate is 0.0357 at epoch 7
INFO - 10/05/22 21:09:43 - 0:03:06 - At 8-th epoch with lr 0.000500.
INFO - 10/05/22 21:10:04 - 0:03:27 - Running average train loss is 0.04877878640529338 at epoch 8
INFO - 10/05/22 21:10:05 - 0:03:28 - Average dev loss is 0.04225945484179717 at epoch 8
INFO - 10/05/22 21:10:06 - 0:03:29 - dev accuracy is 83.2734 at epoch 8
INFO - 10/05/22 21:10:06 - 0:03:29 - dev phenome error rate is 0.0212 at epoch 8
INFO - 10/05/22 21:10:06 - 0:03:29 - At 9-th epoch with lr 0.000500.
INFO - 10/05/22 21:10:27 - 0:03:50 - Running average train loss is 0.03985140726713023 at epoch 9
INFO - 10/05/22 21:10:28 - 0:03:51 - Average dev loss is 0.03708262746938719 at epoch 9
INFO - 10/05/22 21:10:29 - 0:03:52 - dev accuracy is 84.4424 at epoch 9
INFO - 10/05/22 21:10:29 - 0:03:52 - dev phenome error rate is 0.0193 at epoch 9
INFO - 10/05/22 21:10:29 - 0:03:52 - At 10-th epoch with lr 0.000500.
INFO - 10/05/22 21:10:50 - 0:04:13 - Running average train loss is 0.03523799134677469 at epoch 10
INFO - 10/05/22 21:10:51 - 0:04:14 - Average dev loss is 0.037867723380287106 at epoch 10
INFO - 10/05/22 21:10:52 - 0:04:15 - dev accuracy is 85.1619 at epoch 10
INFO - 10/05/22 21:10:52 - 0:04:15 - dev phenome error rate is 0.0184 at epoch 10
INFO - 10/05/22 21:10:52 - 0:04:15 - At 11-th epoch with lr 0.000250.
INFO - 10/05/22 21:11:13 - 0:04:37 - Running average train loss is 0.028411185167732732 at epoch 11
INFO - 10/05/22 21:11:14 - 0:04:37 - Average dev loss is 0.031838682093299354 at epoch 11
INFO - 10/05/22 21:11:15 - 0:04:38 - dev accuracy is 86.9604 at epoch 11
INFO - 10/05/22 21:11:15 - 0:04:38 - dev phenome error rate is 0.0193 at epoch 11
INFO - 10/05/22 21:11:16 - 0:04:39 - At 12-th epoch with lr 0.000250.
INFO - 10/05/22 21:11:37 - 0:05:00 - Running average train loss is 0.02384966976888092 at epoch 12
INFO - 10/05/22 21:11:37 - 0:05:01 - Average dev loss is 0.027642543923754533 at epoch 12
INFO - 10/05/22 21:11:38 - 0:05:02 - dev accuracy is 88.1295 at epoch 12
INFO - 10/05/22 21:11:38 - 0:05:02 - dev phenome error rate is 0.0121 at epoch 12
INFO - 10/05/22 21:11:39 - 0:05:02 - At 13-th epoch with lr 0.000250.
INFO - 10/05/22 21:12:00 - 0:05:23 - Running average train loss is 0.022830960105628156 at epoch 13
INFO - 10/05/22 21:12:00 - 0:05:24 - Average dev loss is 0.028975127660669387 at epoch 13
INFO - 10/05/22 21:12:02 - 0:05:25 - dev accuracy is 89.0288 at epoch 13
INFO - 10/05/22 21:12:02 - 0:05:25 - dev phenome error rate is 0.011 at epoch 13
INFO - 10/05/22 21:12:02 - 0:05:26 - At 14-th epoch with lr 0.000125.
INFO - 10/05/22 21:12:24 - 0:05:47 - Running average train loss is 0.019694701900887065 at epoch 14
INFO - 10/05/22 21:12:24 - 0:05:48 - Average dev loss is 0.0241274441484935 at epoch 14
INFO - 10/05/22 21:12:25 - 0:05:49 - dev accuracy is 89.6583 at epoch 14
INFO - 10/05/22 21:12:25 - 0:05:49 - dev phenome error rate is 0.0109 at epoch 14
INFO - 10/05/22 21:12:26 - 0:05:49 - At 15-th epoch with lr 0.000125.
INFO - 10/05/22 21:12:47 - 0:06:10 - Running average train loss is 0.017353298908158548 at epoch 15
INFO - 10/05/22 21:12:48 - 0:06:11 - Average dev loss is 0.023650173092475878 at epoch 15
INFO - 10/05/22 21:12:49 - 0:06:12 - dev accuracy is 89.3885 at epoch 15
INFO - 10/05/22 21:12:49 - 0:06:12 - dev phenome error rate is 0.0116 at epoch 15
INFO - 10/05/22 21:12:49 - 0:06:12 - At 16-th epoch with lr 0.000125.
INFO - 10/05/22 21:13:10 - 0:06:34 - Running average train loss is 0.0172403763290178 at epoch 16
INFO - 10/05/22 21:13:11 - 0:06:34 - Average dev loss is 0.024009866369529984 at epoch 16
INFO - 10/05/22 21:13:12 - 0:06:35 - dev accuracy is 89.7482 at epoch 16
INFO - 10/05/22 21:13:12 - 0:06:35 - dev phenome error rate is 0.011 at epoch 16
INFO - 10/05/22 21:13:12 - 0:06:36 - At 17-th epoch with lr 0.000063.
INFO - 10/05/22 21:13:33 - 0:06:57 - Running average train loss is 0.016448063096837637 at epoch 17
INFO - 10/05/22 21:13:34 - 0:06:57 - Average dev loss is 0.019480957547560906 at epoch 17
INFO - 10/05/22 21:13:35 - 0:06:59 - dev accuracy is 90.3777 at epoch 17
INFO - 10/05/22 21:13:35 - 0:06:59 - dev phenome error rate is 0.0107 at epoch 17
INFO - 10/05/22 21:13:36 - 0:07:00 - At 18-th epoch with lr 0.000063.
INFO - 10/05/22 21:13:57 - 0:07:21 - Running average train loss is 0.015229446044259373 at epoch 18
INFO - 10/05/22 21:13:58 - 0:07:21 - Average dev loss is 0.01996507569968414 at epoch 18
INFO - 10/05/22 21:13:59 - 0:07:22 - dev accuracy is 90.4676 at epoch 18
INFO - 10/05/22 21:13:59 - 0:07:22 - dev phenome error rate is 0.0102 at epoch 18
INFO - 10/05/22 21:13:59 - 0:07:23 - At 19-th epoch with lr 0.000031.
INFO - 10/05/22 21:14:21 - 0:07:44 - Running average train loss is 0.01523062462020245 at epoch 19
INFO - 10/05/22 21:14:21 - 0:07:45 - Average dev loss is 0.018061106790824292 at epoch 19
INFO - 10/05/22 21:14:22 - 0:07:46 - dev accuracy is 90.6475 at epoch 19
INFO - 10/05/22 21:14:22 - 0:07:46 - dev phenome error rate is 0.0101 at epoch 19
INFO - 10/05/22 21:14:23 - 0:07:46 - At 20-th epoch with lr 0.000031.
INFO - 10/05/22 21:14:44 - 0:08:07 - Running average train loss is 0.014667990868817583 at epoch 20
INFO - 10/05/22 21:14:44 - 0:08:08 - Average dev loss is 0.01784582385309757 at epoch 20
INFO - 10/05/22 21:14:46 - 0:08:09 - dev accuracy is 91.0072 at epoch 20
INFO - 10/05/22 21:14:46 - 0:08:09 - dev phenome error rate is 0.0095 at epoch 20
INFO - 10/05/22 21:14:46 - 0:08:09 - At 21-th epoch with lr 0.000031.
INFO - 10/05/22 21:15:07 - 0:08:30 - Running average train loss is 0.013950530517570331 at epoch 21
INFO - 10/05/22 21:15:08 - 0:08:31 - Average dev loss is 0.017113601555152295 at epoch 21
INFO - 10/05/22 21:15:09 - 0:08:32 - dev accuracy is 91.0971 at epoch 21
INFO - 10/05/22 21:15:09 - 0:08:32 - dev phenome error rate is 0.0105 at epoch 21
INFO - 10/05/22 21:15:09 - 0:08:32 - At 22-th epoch with lr 0.000031.
INFO - 10/05/22 21:15:30 - 0:08:53 - Running average train loss is 0.01428232750717919 at epoch 22
INFO - 10/05/22 21:15:31 - 0:08:54 - Average dev loss is 0.017286103102378547 at epoch 22
INFO - 10/05/22 21:15:32 - 0:08:55 - dev accuracy is 90.9173 at epoch 22
INFO - 10/05/22 21:15:32 - 0:08:55 - dev phenome error rate is 0.0106 at epoch 22
INFO - 10/05/22 21:15:32 - 0:08:56 - At 23-th epoch with lr 0.000016.
INFO - 10/05/22 21:15:53 - 0:09:17 - Running average train loss is 0.014896784394467033 at epoch 23
INFO - 10/05/22 21:15:54 - 0:09:17 - Average dev loss is 0.01591705321871604 at epoch 23
INFO - 10/05/22 21:15:55 - 0:09:18 - dev accuracy is 91.277 at epoch 23
INFO - 10/05/22 21:15:55 - 0:09:18 - dev phenome error rate is 0.0101 at epoch 23
INFO - 10/05/22 21:15:55 - 0:09:19 - At 24-th epoch with lr 0.000016.
INFO - 10/05/22 21:16:16 - 0:09:40 - Running average train loss is 0.014185925153763518 at epoch 24
INFO - 10/05/22 21:16:17 - 0:09:41 - Average dev loss is 0.015415452382204911 at epoch 24
INFO - 10/05/22 21:16:18 - 0:09:42 - dev accuracy is 91.8165 at epoch 24
INFO - 10/05/22 21:16:18 - 0:09:42 - dev phenome error rate is 0.0096 at epoch 24
INFO - 10/05/22 21:16:18 - 0:09:42 - At 25-th epoch with lr 0.000016.
INFO - 10/05/22 21:16:40 - 0:10:03 - Running average train loss is 0.013815517168257449 at epoch 25
INFO - 10/05/22 21:16:40 - 0:10:04 - Average dev loss is 0.015089466869651985 at epoch 25
INFO - 10/05/22 21:16:41 - 0:10:05 - dev accuracy is 91.8165 at epoch 25
INFO - 10/05/22 21:16:41 - 0:10:05 - dev phenome error rate is 0.0088 at epoch 25
INFO - 10/05/22 21:16:42 - 0:10:05 - At 26-th epoch with lr 0.000016.
INFO - 10/05/22 21:17:03 - 0:10:26 - Running average train loss is 0.014007083373549114 at epoch 26
INFO - 10/05/22 21:17:03 - 0:10:27 - Average dev loss is 0.015157915427027126 at epoch 26
INFO - 10/05/22 21:17:05 - 0:10:28 - dev accuracy is 91.7266 at epoch 26
INFO - 10/05/22 21:17:05 - 0:10:28 - dev phenome error rate is 0.0093 at epoch 26
INFO - 10/05/22 21:17:05 - 0:10:28 - At 27-th epoch with lr 0.000010.
INFO - 10/05/22 21:17:26 - 0:10:49 - Running average train loss is 0.014467580028117953 at epoch 27
INFO - 10/05/22 21:17:27 - 0:10:50 - Average dev loss is 0.01408351741802807 at epoch 27
INFO - 10/05/22 21:17:28 - 0:10:51 - dev accuracy is 92.6259 at epoch 27
INFO - 10/05/22 21:17:28 - 0:10:51 - dev phenome error rate is 0.0081 at epoch 27
INFO - 10/05/22 21:17:28 - 0:10:51 - At 28-th epoch with lr 0.000010.
INFO - 10/05/22 21:17:49 - 0:11:13 - Running average train loss is 0.01422021837658184 at epoch 28
INFO - 10/05/22 21:17:50 - 0:11:13 - Average dev loss is 0.014150180762562041 at epoch 28
INFO - 10/05/22 21:17:51 - 0:11:14 - dev accuracy is 92.536 at epoch 28
INFO - 10/05/22 21:17:51 - 0:11:14 - dev phenome error rate is 0.008 at epoch 28
INFO - 10/05/22 21:17:51 - 0:11:14 - Early stopping triggered with epoch 28 (previous dev loss: 0.014084, current: 0.014150)
INFO - 10/05/22 21:17:51 - 0:11:14 - loading model/g2p/large/hard/ndebele.nll_0.0141.acc_92.6259.per_0.0081.epoch_27 for testing
INFO - 10/05/22 21:17:51 - 0:11:14 - load model in model/g2p/large/hard/ndebele.nll_0.0141.acc_92.6259.per_0.0081.epoch_27
INFO - 10/05/22 21:17:52 - 0:11:15 - Average dev loss is 0.014083518107564976 at epoch -1
INFO - 10/05/22 21:17:52 - 0:11:15 - decoding dev set
INFO - 10/05/22 21:17:54 - 0:11:17 - finished decoding 1292 dev instance
INFO - 10/05/22 21:17:54 - 0:11:17 - DEV accuracy is 92.6259 at epoch -1
INFO - 10/05/22 21:17:54 - 0:11:17 - DEV phenome error rate is 0.0081 at epoch -1
INFO - 10/05/22 21:17:54 - 0:11:17 - DEV ndebele acc 92.6259 per 0.0081
INFO - 10/05/22 21:17:55 - 0:11:18 - Average test loss is 0.3377031503478065 at epoch -1
INFO - 10/05/22 21:17:55 - 0:11:18 - decoding test set
INFO - 10/05/22 21:17:59 - 0:11:22 - finished decoding 2552 test instance
INFO - 10/05/22 21:17:59 - 0:11:22 - TEST accuracy is 53.5616 at epoch -1
INFO - 10/05/22 21:17:59 - 0:11:22 - TEST phenome error rate is 0.1064 at epoch -1
INFO - 10/05/22 21:17:59 - 0:11:22 - TEST ndebele acc 53.5616 per 0.1064
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: seed - 0
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: train - ['data/ndebele/ndebele.train']
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: dev - ['data/ndebele/ndebele.dev']
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: test - ['data/ndebele/ndebele.test']
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: model - 'model/g2p/large/hard/ndebele'
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: load - ''
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: bs - 20
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: epochs - 50
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: max_steps - 0
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: total_eval - -1
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: lr - 0.001
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: momentum - 0.9
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: estop - 1e-08
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: cooldown - 0
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: patience - 0
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: max_norm - 5.0
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: gpuid - [0]
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: saveall - False
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: shuffle - False
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: cleanup_anyway - False
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: init - 'init/g2p/large/seed-0/ndebele'
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: dropout - 0.4
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: embed_dim - 200
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: nb_heads - 4
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: src_layer - 2
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: trg_layer - 1
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: src_hs - 400
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: trg_hs - 400
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: nb_sample - 4
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: wid_siz - 11
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: indtag - False
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: mono - False
INFO - 10/05/22 22:11:00 - 0:00:00 - command line argument: bestacc - False
INFO - 10/05/22 22:11:00 - 0:00:00 - src vocab size 68
INFO - 10/05/22 22:11:00 - 0:00:00 - trg vocab size 66
INFO - 10/05/22 22:11:00 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/05/22 22:11:00 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', "'", '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 10/05/22 22:11:00 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(68, 200, padding_idx=0)
                                       (trg_embed): Embedding(66, 200, padding_idx=0)
                                       (enc_rnn): LSTM(200, 400, num_layers=2, dropout=0.4, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(200, 400)
                                         )
                                         (dropout): Dropout(p=0.4, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=800, out_features=400, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=1200, out_features=1200, bias=True)
                                       (final_out): Linear(in_features=1200, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.4, inplace=False)
                                     )
INFO - 10/05/22 22:11:00 - 0:00:00 - number of parameter 8603666
INFO - 10/05/22 22:11:03 - 0:00:03 - load from init/g2p/large/seed-0/ndebele
INFO - 10/05/22 22:11:03 - 0:00:03 - maximum training 32350 steps (50 epochs)
INFO - 10/05/22 22:11:03 - 0:00:03 - evaluate every 1 epochs
INFO - 10/05/22 22:11:03 - 0:00:03 - At 0-th epoch with lr 0.001000.
INFO - 10/05/22 22:11:25 - 0:00:24 - Running average train loss is 0.49190738217954105 at epoch 0
INFO - 10/05/22 22:11:25 - 0:00:24 - At 1-th epoch with lr 0.001000.
INFO - 10/05/22 22:11:46 - 0:00:46 - Running average train loss is 0.18774365673454874 at epoch 1
INFO - 10/05/22 22:11:46 - 0:00:46 - Average dev loss is 0.14195273507099884 at epoch 1
INFO - 10/05/22 22:11:47 - 0:00:47 - dev accuracy is 56.1151 at epoch 1
INFO - 10/05/22 22:11:47 - 0:00:47 - dev phenome error rate is 0.0862 at epoch 1
INFO - 10/05/22 22:11:48 - 0:00:48 - At 2-th epoch with lr 0.001000.
INFO - 10/05/22 22:12:08 - 0:01:08 - Running average train loss is 0.14383948763610774 at epoch 2
INFO - 10/05/22 22:12:08 - 0:01:08 - Average dev loss is 0.12832624333409162 at epoch 2
INFO - 10/05/22 22:12:10 - 0:01:10 - dev accuracy is 58.6331 at epoch 2
INFO - 10/05/22 22:12:10 - 0:01:10 - dev phenome error rate is 0.1055 at epoch 2
INFO - 10/05/22 22:12:10 - 0:01:10 - At 3-th epoch with lr 0.001000.
INFO - 10/05/22 22:12:30 - 0:01:30 - Running average train loss is 0.11866413949883703 at epoch 3
INFO - 10/05/22 22:12:31 - 0:01:31 - Average dev loss is 0.09574972359606852 at epoch 3
INFO - 10/05/22 22:12:32 - 0:01:32 - dev accuracy is 67.2662 at epoch 3
INFO - 10/05/22 22:12:32 - 0:01:32 - dev phenome error rate is 0.0699 at epoch 3
INFO - 10/05/22 22:12:32 - 0:01:32 - At 4-th epoch with lr 0.001000.
INFO - 10/05/22 22:12:52 - 0:01:52 - Running average train loss is 0.10698076112590257 at epoch 4
INFO - 10/05/22 22:12:53 - 0:01:53 - Average dev loss is 0.08336439178540156 at epoch 4
INFO - 10/05/22 22:12:54 - 0:01:54 - dev accuracy is 71.7626 at epoch 4
INFO - 10/05/22 22:12:54 - 0:01:54 - dev phenome error rate is 0.0681 at epoch 4
INFO - 10/05/22 22:12:55 - 0:01:55 - At 5-th epoch with lr 0.001000.
INFO - 10/05/22 22:13:15 - 0:02:15 - Running average train loss is 0.0878588492597757 at epoch 5
INFO - 10/05/22 22:13:15 - 0:02:15 - Average dev loss is 0.0703522335164822 at epoch 5
INFO - 10/05/22 22:13:16 - 0:02:16 - dev accuracy is 73.1115 at epoch 5
INFO - 10/05/22 22:13:16 - 0:02:16 - dev phenome error rate is 0.0422 at epoch 5
INFO - 10/05/22 22:13:17 - 0:02:17 - At 6-th epoch with lr 0.001000.
INFO - 10/05/22 22:13:37 - 0:02:37 - Running average train loss is 0.08184661689449038 at epoch 6
INFO - 10/05/22 22:13:38 - 0:02:37 - Average dev loss is 0.06893013429183226 at epoch 6
INFO - 10/05/22 22:13:39 - 0:02:39 - dev accuracy is 74.8201 at epoch 6
INFO - 10/05/22 22:13:39 - 0:02:39 - dev phenome error rate is 0.0464 at epoch 6
INFO - 10/05/22 22:13:39 - 0:02:39 - At 7-th epoch with lr 0.001000.
INFO - 10/05/22 22:13:59 - 0:02:59 - Running average train loss is 0.0798149266808511 at epoch 7
INFO - 10/05/22 22:13:59 - 0:02:59 - Average dev loss is 0.06917509260372473 at epoch 7
INFO - 10/05/22 22:14:01 - 0:03:01 - dev accuracy is 77.8777 at epoch 7
INFO - 10/05/22 22:14:01 - 0:03:01 - dev phenome error rate is 0.0344 at epoch 7
INFO - 10/05/22 22:14:01 - 0:03:01 - At 8-th epoch with lr 0.000500.
INFO - 10/05/22 22:14:21 - 0:03:21 - Running average train loss is 0.054122174718637464 at epoch 8
INFO - 10/05/22 22:14:22 - 0:03:21 - Average dev loss is 0.04274160158462249 at epoch 8
INFO - 10/05/22 22:14:23 - 0:03:23 - dev accuracy is 84.7122 at epoch 8
INFO - 10/05/22 22:14:23 - 0:03:23 - dev phenome error rate is 0.02 at epoch 8
INFO - 10/05/22 22:14:23 - 0:03:23 - At 9-th epoch with lr 0.000500.
INFO - 10/05/22 22:14:43 - 0:03:43 - Running average train loss is 0.040169930509097264 at epoch 9
INFO - 10/05/22 22:14:44 - 0:03:43 - Average dev loss is 0.04032100852435598 at epoch 9
INFO - 10/05/22 22:14:45 - 0:03:45 - dev accuracy is 84.8022 at epoch 9
INFO - 10/05/22 22:14:45 - 0:03:45 - dev phenome error rate is 0.0177 at epoch 9
INFO - 10/05/22 22:14:45 - 0:03:45 - At 10-th epoch with lr 0.000500.
INFO - 10/05/22 22:15:05 - 0:04:05 - Running average train loss is 0.03490769643720867 at epoch 10
INFO - 10/05/22 22:15:06 - 0:04:06 - Average dev loss is 0.038966823709555544 at epoch 10
INFO - 10/05/22 22:15:07 - 0:04:07 - dev accuracy is 85.4317 at epoch 10
INFO - 10/05/22 22:15:07 - 0:04:07 - dev phenome error rate is 0.0166 at epoch 10
INFO - 10/05/22 22:15:07 - 0:04:07 - At 11-th epoch with lr 0.000500.
INFO - 10/05/22 22:15:27 - 0:04:27 - Running average train loss is 0.031941074339983846 at epoch 11
INFO - 10/05/22 22:15:28 - 0:04:28 - Average dev loss is 0.03474822758267132 at epoch 11
INFO - 10/05/22 22:15:29 - 0:04:29 - dev accuracy is 86.6906 at epoch 11
INFO - 10/05/22 22:15:29 - 0:04:29 - dev phenome error rate is 0.0164 at epoch 11
INFO - 10/05/22 22:15:29 - 0:04:29 - At 12-th epoch with lr 0.000500.
INFO - 10/05/22 22:15:49 - 0:04:49 - Running average train loss is 0.031151604445700115 at epoch 12
INFO - 10/05/22 22:15:50 - 0:04:50 - Average dev loss is 0.03263115220559904 at epoch 12
INFO - 10/05/22 22:15:51 - 0:04:51 - dev accuracy is 87.0504 at epoch 12
INFO - 10/05/22 22:15:51 - 0:04:51 - dev phenome error rate is 0.0153 at epoch 12
INFO - 10/05/22 22:15:51 - 0:04:51 - At 13-th epoch with lr 0.000500.
INFO - 10/05/22 22:16:11 - 0:05:11 - Running average train loss is 0.030513174009402864 at epoch 13
INFO - 10/05/22 22:16:12 - 0:05:12 - Average dev loss is 0.03317926161421033 at epoch 13
INFO - 10/05/22 22:16:13 - 0:05:13 - dev accuracy is 87.5899 at epoch 13
INFO - 10/05/22 22:16:13 - 0:05:13 - dev phenome error rate is 0.0152 at epoch 13
INFO - 10/05/22 22:16:13 - 0:05:13 - At 14-th epoch with lr 0.000250.
INFO - 10/05/22 22:16:33 - 0:05:33 - Running average train loss is 0.02500644837942628 at epoch 14
INFO - 10/05/22 22:16:34 - 0:05:34 - Average dev loss is 0.029859606199897824 at epoch 14
INFO - 10/05/22 22:16:35 - 0:05:35 - dev accuracy is 88.5791 at epoch 14
INFO - 10/05/22 22:16:35 - 0:05:35 - dev phenome error rate is 0.0119 at epoch 14
INFO - 10/05/22 22:16:35 - 0:05:35 - At 15-th epoch with lr 0.000250.
INFO - 10/05/22 22:16:55 - 0:05:55 - Running average train loss is 0.020044372047904383 at epoch 15
INFO - 10/05/22 22:16:56 - 0:05:56 - Average dev loss is 0.026371554269168814 at epoch 15
INFO - 10/05/22 22:16:57 - 0:05:57 - dev accuracy is 89.8381 at epoch 15
INFO - 10/05/22 22:16:57 - 0:05:57 - dev phenome error rate is 0.0112 at epoch 15
INFO - 10/05/22 22:16:57 - 0:05:57 - At 16-th epoch with lr 0.000250.
INFO - 10/05/22 22:17:17 - 0:06:17 - Running average train loss is 0.018828350358600893 at epoch 16
INFO - 10/05/22 22:17:18 - 0:06:18 - Average dev loss is 0.02785718966490374 at epoch 16
INFO - 10/05/22 22:17:19 - 0:06:19 - dev accuracy is 89.6583 at epoch 16
INFO - 10/05/22 22:17:19 - 0:06:19 - dev phenome error rate is 0.0108 at epoch 16
INFO - 10/05/22 22:17:19 - 0:06:19 - At 17-th epoch with lr 0.000125.
INFO - 10/05/22 22:17:39 - 0:06:39 - Running average train loss is 0.01647902338079485 at epoch 17
INFO - 10/05/22 22:17:40 - 0:06:40 - Average dev loss is 0.02295334565703972 at epoch 17
INFO - 10/05/22 22:17:41 - 0:06:41 - dev accuracy is 90.4676 at epoch 17
INFO - 10/05/22 22:17:41 - 0:06:41 - dev phenome error rate is 0.0107 at epoch 17
INFO - 10/05/22 22:17:41 - 0:06:41 - At 18-th epoch with lr 0.000125.
INFO - 10/05/22 22:18:01 - 0:07:01 - Running average train loss is 0.015487486801370747 at epoch 18
INFO - 10/05/22 22:18:02 - 0:07:02 - Average dev loss is 0.022691638690706055 at epoch 18
INFO - 10/05/22 22:18:03 - 0:07:03 - dev accuracy is 90.2878 at epoch 18
INFO - 10/05/22 22:18:03 - 0:07:03 - dev phenome error rate is 0.0105 at epoch 18
INFO - 10/05/22 22:18:03 - 0:07:03 - At 19-th epoch with lr 0.000125.
INFO - 10/05/22 22:18:23 - 0:07:23 - Running average train loss is 0.01445881761337013 at epoch 19
INFO - 10/05/22 22:18:24 - 0:07:24 - Average dev loss is 0.022526048028913254 at epoch 19
INFO - 10/05/22 22:18:25 - 0:07:25 - dev accuracy is 90.6475 at epoch 19
INFO - 10/05/22 22:18:25 - 0:07:25 - dev phenome error rate is 0.0108 at epoch 19
INFO - 10/05/22 22:18:25 - 0:07:25 - At 20-th epoch with lr 0.000125.
INFO - 10/05/22 22:18:45 - 0:07:45 - Running average train loss is 0.014054173480041348 at epoch 20
INFO - 10/05/22 22:18:46 - 0:07:45 - Average dev loss is 0.02193029725100272 at epoch 20
INFO - 10/05/22 22:18:47 - 0:07:47 - dev accuracy is 90.8273 at epoch 20
INFO - 10/05/22 22:18:47 - 0:07:47 - dev phenome error rate is 0.0103 at epoch 20
INFO - 10/05/22 22:18:47 - 0:07:47 - At 21-th epoch with lr 0.000125.
INFO - 10/05/22 22:19:07 - 0:08:07 - Running average train loss is 0.013744480592048247 at epoch 21
INFO - 10/05/22 22:19:08 - 0:08:08 - Average dev loss is 0.021484366331536036 at epoch 21
INFO - 10/05/22 22:19:09 - 0:08:09 - dev accuracy is 90.7374 at epoch 21
INFO - 10/05/22 22:19:09 - 0:08:09 - dev phenome error rate is 0.011 at epoch 21
INFO - 10/05/22 22:19:09 - 0:08:09 - At 22-th epoch with lr 0.000125.
INFO - 10/05/22 22:19:29 - 0:08:29 - Running average train loss is 0.01328901935856749 at epoch 22
INFO - 10/05/22 22:19:30 - 0:08:29 - Average dev loss is 0.02180815571381782 at epoch 22
INFO - 10/05/22 22:19:31 - 0:08:31 - dev accuracy is 90.8273 at epoch 22
INFO - 10/05/22 22:19:31 - 0:08:31 - dev phenome error rate is 0.01 at epoch 22
INFO - 10/05/22 22:19:31 - 0:08:31 - At 23-th epoch with lr 0.000063.
INFO - 10/05/22 22:19:51 - 0:08:51 - Running average train loss is 0.013202792332733304 at epoch 23
INFO - 10/05/22 22:19:51 - 0:08:51 - Average dev loss is 0.019313936378771008 at epoch 23
INFO - 10/05/22 22:19:53 - 0:08:53 - dev accuracy is 91.0971 at epoch 23
INFO - 10/05/22 22:19:53 - 0:08:53 - dev phenome error rate is 0.0103 at epoch 23
INFO - 10/05/22 22:19:53 - 0:08:53 - At 24-th epoch with lr 0.000063.
INFO - 10/05/22 22:20:13 - 0:09:13 - Running average train loss is 0.012164891623154893 at epoch 24
INFO - 10/05/22 22:20:13 - 0:09:13 - Average dev loss is 0.01842712278280837 at epoch 24
INFO - 10/05/22 22:20:15 - 0:09:14 - dev accuracy is 91.1871 at epoch 24
INFO - 10/05/22 22:20:15 - 0:09:14 - dev phenome error rate is 0.0102 at epoch 24
INFO - 10/05/22 22:20:15 - 0:09:15 - At 25-th epoch with lr 0.000063.
INFO - 10/05/22 22:20:35 - 0:09:35 - Running average train loss is 0.011742844481317693 at epoch 25
INFO - 10/05/22 22:20:35 - 0:09:35 - Average dev loss is 0.019077379662149514 at epoch 25
INFO - 10/05/22 22:20:36 - 0:09:36 - dev accuracy is 91.0971 at epoch 25
INFO - 10/05/22 22:20:36 - 0:09:36 - dev phenome error rate is 0.0105 at epoch 25
INFO - 10/05/22 22:20:37 - 0:09:37 - At 26-th epoch with lr 0.000031.
INFO - 10/05/22 22:20:57 - 0:09:57 - Running average train loss is 0.012501580658104448 at epoch 26
INFO - 10/05/22 22:20:57 - 0:09:57 - Average dev loss is 0.01694396772251751 at epoch 26
INFO - 10/05/22 22:20:58 - 0:09:58 - dev accuracy is 91.5468 at epoch 26
INFO - 10/05/22 22:20:58 - 0:09:58 - dev phenome error rate is 0.0099 at epoch 26
INFO - 10/05/22 22:20:59 - 0:09:58 - At 27-th epoch with lr 0.000031.
INFO - 10/05/22 22:21:19 - 0:10:18 - Running average train loss is 0.011763376534223366 at epoch 27
INFO - 10/05/22 22:21:19 - 0:10:19 - Average dev loss is 0.01688963020883071 at epoch 27
INFO - 10/05/22 22:21:20 - 0:10:20 - dev accuracy is 91.3669 at epoch 27
INFO - 10/05/22 22:21:20 - 0:10:20 - dev phenome error rate is 0.0102 at epoch 27
INFO - 10/05/22 22:21:21 - 0:10:21 - At 28-th epoch with lr 0.000031.
INFO - 10/05/22 22:21:41 - 0:10:41 - Running average train loss is 0.01137104138235437 at epoch 28
INFO - 10/05/22 22:21:41 - 0:10:41 - Average dev loss is 0.01649621027485969 at epoch 28
INFO - 10/05/22 22:21:42 - 0:10:42 - dev accuracy is 91.4568 at epoch 28
INFO - 10/05/22 22:21:42 - 0:10:42 - dev phenome error rate is 0.01 at epoch 28
INFO - 10/05/22 22:21:43 - 0:10:42 - At 29-th epoch with lr 0.000031.
INFO - 10/05/22 22:22:03 - 0:11:02 - Running average train loss is 0.011077393427747769 at epoch 29
INFO - 10/05/22 22:22:03 - 0:11:03 - Average dev loss is 0.016988078856733268 at epoch 29
INFO - 10/05/22 22:22:04 - 0:11:04 - dev accuracy is 91.5468 at epoch 29
INFO - 10/05/22 22:22:04 - 0:11:04 - dev phenome error rate is 0.0096 at epoch 29
INFO - 10/05/22 22:22:05 - 0:11:05 - At 30-th epoch with lr 0.000016.
INFO - 10/05/22 22:22:25 - 0:11:25 - Running average train loss is 0.012695334586748491 at epoch 30
INFO - 10/05/22 22:22:25 - 0:11:25 - Average dev loss is 0.01481991762904307 at epoch 30
INFO - 10/05/22 22:22:26 - 0:11:26 - dev accuracy is 92.2662 at epoch 30
INFO - 10/05/22 22:22:26 - 0:11:26 - dev phenome error rate is 0.0091 at epoch 30
INFO - 10/05/22 22:22:27 - 0:11:27 - At 31-th epoch with lr 0.000016.
INFO - 10/05/22 22:22:47 - 0:11:47 - Running average train loss is 0.01164826235257649 at epoch 31
INFO - 10/05/22 22:22:47 - 0:11:47 - Average dev loss is 0.014465314059410816 at epoch 31
INFO - 10/05/22 22:22:48 - 0:11:48 - dev accuracy is 92.446 at epoch 31
INFO - 10/05/22 22:22:48 - 0:11:48 - dev phenome error rate is 0.0092 at epoch 31
INFO - 10/05/22 22:22:49 - 0:11:49 - At 32-th epoch with lr 0.000016.
INFO - 10/05/22 22:23:09 - 0:12:09 - Running average train loss is 0.011747822566465308 at epoch 32
INFO - 10/05/22 22:23:09 - 0:12:09 - Average dev loss is 0.014303167444617989 at epoch 32
INFO - 10/05/22 22:23:10 - 0:12:10 - dev accuracy is 92.8058 at epoch 32
INFO - 10/05/22 22:23:10 - 0:12:10 - dev phenome error rate is 0.0088 at epoch 32
INFO - 10/05/22 22:23:11 - 0:12:10 - At 33-th epoch with lr 0.000016.
INFO - 10/05/22 22:23:31 - 0:12:31 - Running average train loss is 0.011492983558718289 at epoch 33
INFO - 10/05/22 22:23:31 - 0:12:31 - Average dev loss is 0.014456941901097217 at epoch 33
INFO - 10/05/22 22:23:32 - 0:12:32 - dev accuracy is 92.8957 at epoch 33
INFO - 10/05/22 22:23:32 - 0:12:32 - dev phenome error rate is 0.0088 at epoch 33
INFO - 10/05/22 22:23:33 - 0:12:32 - At 34-th epoch with lr 0.000010.
INFO - 10/05/22 22:23:53 - 0:12:52 - Running average train loss is 0.012264568429732468 at epoch 34
INFO - 10/05/22 22:23:53 - 0:12:53 - Average dev loss is 0.012964250267787764 at epoch 34
INFO - 10/05/22 22:23:54 - 0:12:54 - dev accuracy is 93.0755 at epoch 34
INFO - 10/05/22 22:23:54 - 0:12:54 - dev phenome error rate is 0.0085 at epoch 34
INFO - 10/05/22 22:23:54 - 0:12:54 - At 35-th epoch with lr 0.000010.
INFO - 10/05/22 22:24:15 - 0:13:14 - Running average train loss is 0.011875589076298976 at epoch 35
INFO - 10/05/22 22:24:15 - 0:13:15 - Average dev loss is 0.012684777336947334 at epoch 35
INFO - 10/05/22 22:24:16 - 0:13:16 - dev accuracy is 93.4353 at epoch 35
INFO - 10/05/22 22:24:16 - 0:13:16 - dev phenome error rate is 0.0082 at epoch 35
INFO - 10/05/22 22:24:16 - 0:13:16 - At 36-th epoch with lr 0.000010.
INFO - 10/05/22 22:24:36 - 0:13:36 - Running average train loss is 0.011800667490218903 at epoch 36
INFO - 10/05/22 22:24:37 - 0:13:37 - Average dev loss is 0.012728252603063503 at epoch 36
INFO - 10/05/22 22:24:38 - 0:13:38 - dev accuracy is 93.1655 at epoch 36
INFO - 10/05/22 22:24:38 - 0:13:38 - dev phenome error rate is 0.0085 at epoch 36
INFO - 10/05/22 22:24:38 - 0:13:38 - Early stopping triggered with epoch 36 (previous dev loss: 0.012685, current: 0.012728)
INFO - 10/05/22 22:24:38 - 0:13:38 - loading model/g2p/large/hard/ndebele.nll_0.0127.acc_93.4353.per_0.0082.epoch_35 for testing
INFO - 10/05/22 22:24:38 - 0:13:38 - load model in model/g2p/large/hard/ndebele.nll_0.0127.acc_93.4353.per_0.0082.epoch_35
INFO - 10/05/22 22:24:39 - 0:13:39 - Average dev loss is 0.012684777067848839 at epoch -1
INFO - 10/05/22 22:24:39 - 0:13:39 - decoding dev set
INFO - 10/05/22 22:24:41 - 0:13:41 - finished decoding 1292 dev instance
INFO - 10/05/22 22:24:41 - 0:13:41 - DEV accuracy is 93.4353 at epoch -1
INFO - 10/05/22 22:24:41 - 0:13:41 - DEV phenome error rate is 0.0082 at epoch -1
INFO - 10/05/22 22:24:41 - 0:13:41 - DEV ndebele acc 93.4353 per 0.0082
INFO - 10/05/22 22:24:42 - 0:13:42 - Average test loss is 0.3676687589031644 at epoch -1
INFO - 10/05/22 22:24:42 - 0:13:42 - decoding test set
INFO - 10/05/22 22:24:46 - 0:13:46 - finished decoding 2552 test instance
INFO - 10/05/22 22:24:46 - 0:13:46 - TEST accuracy is 53.0094 at epoch -1
INFO - 10/05/22 22:24:46 - 0:13:46 - TEST phenome error rate is 0.1086 at epoch -1
INFO - 10/05/22 22:24:46 - 0:13:46 - TEST ndebele acc 53.0094 per 0.1086
