INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: seed - 0
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: train - ['data2/xhosa/xhosa.train']
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: dev - ['data2/xhosa/xhosa.dev']
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: test - ['data2/xhosa/xhosa.test']
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: model - 'model/test2/dropout/large/test0.4/xhosa'
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: load - ''
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: bs - 20
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: epochs - 50
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: max_steps - 0
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: total_eval - -1
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: lr - 0.001
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: momentum - 0.9
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: estop - 1e-08
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: cooldown - 0
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: patience - 0
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: max_norm - 5.0
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: gpuid - [0]
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: saveall - False
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: shuffle - False
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: cleanup_anyway - True
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: init - ''
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: dropout - 0.4
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: embed_dim - 200
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: nb_heads - 4
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: src_layer - 2
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: trg_layer - 1
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: src_hs - 400
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: trg_hs - 400
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: nb_sample - 4
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: wid_siz - 11
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: indtag - False
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: mono - False
INFO - 11/06/22 03:13:28 - 0:00:00 - command line argument: bestacc - False
INFO - 11/06/22 03:13:28 - 0:00:00 - src vocab size 69
INFO - 11/06/22 03:13:28 - 0:00:00 - trg vocab size 66
INFO - 11/06/22 03:13:28 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 11/06/22 03:13:28 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 11/06/22 03:13:28 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(69, 200, padding_idx=0)
                                       (trg_embed): Embedding(66, 200, padding_idx=0)
                                       (enc_rnn): LSTM(200, 400, num_layers=2, dropout=0.4, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(200, 400)
                                         )
                                         (dropout): Dropout(p=0.4, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=800, out_features=400, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=1200, out_features=1200, bias=True)
                                       (final_out): Linear(in_features=1200, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.4, inplace=False)
                                     )
INFO - 11/06/22 03:13:28 - 0:00:00 - number of parameter 8603866
INFO - 11/06/22 03:13:31 - 0:00:03 - maximum training 20450 steps (50 epochs)
INFO - 11/06/22 03:13:31 - 0:00:03 - evaluate every 1 epochs
INFO - 11/06/22 03:13:31 - 0:00:03 - At 0-th epoch with lr 0.001000.
INFO - 11/06/22 03:13:47 - 0:00:18 - Running average train loss is 0.6504270857732861 at epoch 0
INFO - 11/06/22 03:13:47 - 0:00:18 - At 1-th epoch with lr 0.001000.
INFO - 11/06/22 03:14:02 - 0:00:34 - Running average train loss is 0.24326873532425802 at epoch 1
INFO - 11/06/22 03:14:03 - 0:00:35 - Average dev loss is 0.16544548746036447 at epoch 1
INFO - 11/06/22 03:14:04 - 0:00:36 - dev accuracy is 53.1938 at epoch 1
INFO - 11/06/22 03:14:04 - 0:00:36 - dev phenome error rate is 0.1276 at epoch 1
INFO - 11/06/22 03:14:04 - 0:00:36 - At 2-th epoch with lr 0.001000.
INFO - 11/06/22 03:14:20 - 0:00:51 - Running average train loss is 0.19277077589029204 at epoch 2
INFO - 11/06/22 03:14:20 - 0:00:52 - Average dev loss is 0.15519010486162227 at epoch 2
INFO - 11/06/22 03:14:21 - 0:00:53 - dev accuracy is 55.5066 at epoch 2
INFO - 11/06/22 03:14:21 - 0:00:53 - dev phenome error rate is 0.1314 at epoch 2
INFO - 11/06/22 03:14:21 - 0:00:53 - At 3-th epoch with lr 0.001000.
INFO - 11/06/22 03:14:37 - 0:01:09 - Running average train loss is 0.163841831937323 at epoch 3
INFO - 11/06/22 03:14:37 - 0:01:09 - Average dev loss is 0.13309509841644246 at epoch 3
INFO - 11/06/22 03:14:38 - 0:01:10 - dev accuracy is 61.8943 at epoch 3
INFO - 11/06/22 03:14:38 - 0:01:10 - dev phenome error rate is 0.0976 at epoch 3
INFO - 11/06/22 03:14:39 - 0:01:10 - At 4-th epoch with lr 0.001000.
INFO - 11/06/22 03:14:54 - 0:01:26 - Running average train loss is 0.13745368754805445 at epoch 4
INFO - 11/06/22 03:14:54 - 0:01:26 - Average dev loss is 0.13793414839259957 at epoch 4
INFO - 11/06/22 03:14:55 - 0:01:27 - dev accuracy is 61.3436 at epoch 4
INFO - 11/06/22 03:14:55 - 0:01:27 - dev phenome error rate is 0.1 at epoch 4
INFO - 11/06/22 03:14:56 - 0:01:27 - At 5-th epoch with lr 0.000500.
INFO - 11/06/22 03:15:11 - 0:01:43 - Running average train loss is 0.08991330793733118 at epoch 5
INFO - 11/06/22 03:15:11 - 0:01:43 - Average dev loss is 0.09813913265648096 at epoch 5
INFO - 11/06/22 03:15:12 - 0:01:44 - dev accuracy is 69.8238 at epoch 5
INFO - 11/06/22 03:15:12 - 0:01:44 - dev phenome error rate is 0.0728 at epoch 5
INFO - 11/06/22 03:15:12 - 0:01:44 - At 6-th epoch with lr 0.000500.
INFO - 11/06/22 03:15:28 - 0:02:00 - Running average train loss is 0.06998370758606198 at epoch 6
INFO - 11/06/22 03:15:28 - 0:02:00 - Average dev loss is 0.09612130887968384 at epoch 6
INFO - 11/06/22 03:15:29 - 0:02:01 - dev accuracy is 72.3568 at epoch 6
INFO - 11/06/22 03:15:29 - 0:02:01 - dev phenome error rate is 0.0673 at epoch 6
INFO - 11/06/22 03:15:30 - 0:02:01 - At 7-th epoch with lr 0.000500.
INFO - 11/06/22 03:15:45 - 0:02:17 - Running average train loss is 0.06078983550495069 at epoch 7
INFO - 11/06/22 03:15:45 - 0:02:17 - Average dev loss is 0.09368669541309708 at epoch 7
INFO - 11/06/22 03:15:46 - 0:02:18 - dev accuracy is 71.0352 at epoch 7
INFO - 11/06/22 03:15:46 - 0:02:18 - dev phenome error rate is 0.072 at epoch 7
INFO - 11/06/22 03:15:47 - 0:02:18 - At 8-th epoch with lr 0.000500.
INFO - 11/06/22 03:16:02 - 0:02:34 - Running average train loss is 0.05395554773700777 at epoch 8
INFO - 11/06/22 03:16:03 - 0:02:34 - Average dev loss is 0.09955276937588402 at epoch 8
INFO - 11/06/22 03:16:03 - 0:02:35 - dev accuracy is 71.4758 at epoch 8
INFO - 11/06/22 03:16:03 - 0:02:35 - dev phenome error rate is 0.0664 at epoch 8
INFO - 11/06/22 03:16:04 - 0:02:35 - At 9-th epoch with lr 0.000250.
INFO - 11/06/22 03:16:21 - 0:02:52 - Running average train loss is 0.03929191549971226 at epoch 9
INFO - 11/06/22 03:16:21 - 0:02:53 - Average dev loss is 0.09297309625569893 at epoch 9
INFO - 11/06/22 03:16:22 - 0:02:54 - dev accuracy is 74.2291 at epoch 9
INFO - 11/06/22 03:16:22 - 0:02:54 - dev phenome error rate is 0.0621 at epoch 9
INFO - 11/06/22 03:16:22 - 0:02:54 - At 10-th epoch with lr 0.000250.
INFO - 11/06/22 03:16:40 - 0:03:12 - Running average train loss is 0.032238163523066306 at epoch 10
INFO - 11/06/22 03:16:41 - 0:03:12 - Average dev loss is 0.08884588908404112 at epoch 10
INFO - 11/06/22 03:16:41 - 0:03:13 - dev accuracy is 75.0 at epoch 10
INFO - 11/06/22 03:16:41 - 0:03:13 - dev phenome error rate is 0.0618 at epoch 10
INFO - 11/06/22 03:16:42 - 0:03:13 - At 11-th epoch with lr 0.000250.
INFO - 11/06/22 03:16:57 - 0:03:29 - Running average train loss is 0.02806152692599755 at epoch 11
INFO - 11/06/22 03:16:58 - 0:03:30 - Average dev loss is 0.0921321298684115 at epoch 11
INFO - 11/06/22 03:16:59 - 0:03:31 - dev accuracy is 74.5595 at epoch 11
INFO - 11/06/22 03:16:59 - 0:03:31 - dev phenome error rate is 0.0621 at epoch 11
INFO - 11/06/22 03:17:00 - 0:03:31 - At 12-th epoch with lr 0.000125.
INFO - 11/06/22 03:17:15 - 0:03:47 - Running average train loss is 0.02192728374037245 at epoch 12
INFO - 11/06/22 03:17:16 - 0:03:47 - Average dev loss is 0.09020567640824162 at epoch 12
INFO - 11/06/22 03:17:17 - 0:03:48 - dev accuracy is 74.8899 at epoch 12
INFO - 11/06/22 03:17:17 - 0:03:48 - dev phenome error rate is 0.0625 at epoch 12
INFO - 11/06/22 03:17:17 - 0:03:48 - At 13-th epoch with lr 0.000063.
INFO - 11/06/22 03:17:32 - 0:04:04 - Running average train loss is 0.01839958045353844 at epoch 13
INFO - 11/06/22 03:17:33 - 0:04:04 - Average dev loss is 0.08969236078226696 at epoch 13
INFO - 11/06/22 03:17:34 - 0:04:05 - dev accuracy is 75.5507 at epoch 13
INFO - 11/06/22 03:17:34 - 0:04:05 - dev phenome error rate is 0.0586 at epoch 13
INFO - 11/06/22 03:17:34 - 0:04:06 - At 14-th epoch with lr 0.000031.
INFO - 11/06/22 03:17:50 - 0:04:21 - Running average train loss is 0.016626979780558743 at epoch 14
INFO - 11/06/22 03:17:50 - 0:04:22 - Average dev loss is 0.08957376831170658 at epoch 14
INFO - 11/06/22 03:17:51 - 0:04:23 - dev accuracy is 75.5507 at epoch 14
INFO - 11/06/22 03:17:51 - 0:04:23 - dev phenome error rate is 0.059 at epoch 14
INFO - 11/06/22 03:17:51 - 0:04:23 - At 15-th epoch with lr 0.000016.
INFO - 11/06/22 03:18:07 - 0:04:38 - Running average train loss is 0.014835151503304325 at epoch 15
INFO - 11/06/22 03:18:07 - 0:04:39 - Average dev loss is 0.0896301212437127 at epoch 15
INFO - 11/06/22 03:18:08 - 0:04:40 - dev accuracy is 75.5507 at epoch 15
INFO - 11/06/22 03:18:08 - 0:04:40 - dev phenome error rate is 0.0595 at epoch 15
INFO - 11/06/22 03:18:08 - 0:04:40 - At 16-th epoch with lr 0.000010.
INFO - 11/06/22 03:18:24 - 0:04:55 - Running average train loss is 0.014738069690677421 at epoch 16
INFO - 11/06/22 03:18:24 - 0:04:56 - Average dev loss is 0.09004516478465951 at epoch 16
INFO - 11/06/22 03:18:25 - 0:04:57 - dev accuracy is 75.4405 at epoch 16
INFO - 11/06/22 03:18:25 - 0:04:57 - dev phenome error rate is 0.0594 at epoch 16
INFO - 11/06/22 03:18:25 - 0:04:57 - Early stopping triggered with epoch 16 (previous dev loss: 0.089630, current: 0.090045)
INFO - 11/06/22 03:18:25 - 0:04:57 - loading model/test2/dropout/large/test0.4/xhosa.nll_0.0897.acc_75.5507.per_0.0586.epoch_13 for testing
INFO - 11/06/22 03:18:25 - 0:04:57 - load model in model/test2/dropout/large/test0.4/xhosa.nll_0.0897.acc_75.5507.per_0.0586.epoch_13
INFO - 11/06/22 03:18:25 - 0:04:57 - Average dev loss is 0.08969236092398995 at epoch -1
INFO - 11/06/22 03:18:25 - 0:04:57 - decoding dev set
INFO - 11/06/22 03:18:27 - 0:04:59 - finished decoding 908 dev instance
INFO - 11/06/22 03:18:27 - 0:04:59 - DEV accuracy is 75.5507 at epoch -1
INFO - 11/06/22 03:18:27 - 0:04:59 - DEV phenome error rate is 0.0586 at epoch -1
INFO - 11/06/22 03:18:27 - 0:04:59 - DEV xhosa acc 75.5507 per 0.0586
INFO - 11/06/22 03:18:29 - 0:05:00 - Average test loss is 0.31705161286147915 at epoch -1
INFO - 11/06/22 03:18:29 - 0:05:00 - decoding test set
INFO - 11/06/22 03:18:33 - 0:05:05 - finished decoding 3003 test instance
INFO - 11/06/22 03:18:33 - 0:05:05 - TEST accuracy is 54.8072 at epoch -1
INFO - 11/06/22 03:18:33 - 0:05:05 - TEST phenome error rate is 0.1178 at epoch -1
INFO - 11/06/22 03:18:33 - 0:05:05 - TEST xhosa acc 54.8072 per 0.1178
