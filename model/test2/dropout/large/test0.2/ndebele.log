INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: seed - 0
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: train - ['data2/ndebele/ndebele.train']
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: dev - ['data2/ndebele/ndebele.dev']
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: test - ['data2/ndebele/ndebele.test']
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: model - 'model/test2/dropout/large/test0.2/ndebele'
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: load - ''
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: bs - 20
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: epochs - 50
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: max_steps - 0
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: total_eval - -1
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: lr - 0.001
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: momentum - 0.9
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: estop - 1e-08
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: cooldown - 0
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: patience - 0
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: max_norm - 5.0
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: gpuid - [0]
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: saveall - False
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: shuffle - False
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: cleanup_anyway - True
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: init - ''
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: dropout - 0.2
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: embed_dim - 200
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: nb_heads - 4
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: src_layer - 2
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: trg_layer - 1
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: src_hs - 400
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: trg_hs - 400
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: nb_sample - 4
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: wid_siz - 11
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: indtag - False
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: mono - False
INFO - 11/06/22 02:52:05 - 0:00:00 - command line argument: bestacc - False
INFO - 11/06/22 02:52:05 - 0:00:00 - src vocab size 68
INFO - 11/06/22 02:52:05 - 0:00:00 - trg vocab size 66
INFO - 11/06/22 02:52:05 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 11/06/22 02:52:05 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', "'", '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 11/06/22 02:52:05 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(68, 200, padding_idx=0)
                                       (trg_embed): Embedding(66, 200, padding_idx=0)
                                       (enc_rnn): LSTM(200, 400, num_layers=2, dropout=0.2, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(200, 400)
                                         )
                                         (dropout): Dropout(p=0.2, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=800, out_features=400, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=1200, out_features=1200, bias=True)
                                       (final_out): Linear(in_features=1200, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.2, inplace=False)
                                     )
INFO - 11/06/22 02:52:05 - 0:00:00 - number of parameter 8603666
INFO - 11/06/22 02:52:08 - 0:00:03 - maximum training 16300 steps (50 epochs)
INFO - 11/06/22 02:52:08 - 0:00:03 - evaluate every 1 epochs
INFO - 11/06/22 02:52:08 - 0:00:03 - At 0-th epoch with lr 0.001000.
INFO - 11/06/22 02:52:20 - 0:00:15 - Running average train loss is 0.623465877849083 at epoch 0
INFO - 11/06/22 02:52:20 - 0:00:15 - At 1-th epoch with lr 0.001000.
INFO - 11/06/22 02:52:31 - 0:00:26 - Running average train loss is 0.21970655040049847 at epoch 1
INFO - 11/06/22 02:52:31 - 0:00:26 - Average dev loss is 0.19448899860317642 at epoch 1
INFO - 11/06/22 02:52:32 - 0:00:27 - dev accuracy is 45.0763 at epoch 1
INFO - 11/06/22 02:52:32 - 0:00:27 - dev phenome error rate is 0.1289 at epoch 1
INFO - 11/06/22 02:52:32 - 0:00:27 - At 2-th epoch with lr 0.001000.
INFO - 11/06/22 02:52:44 - 0:00:39 - Running average train loss is 0.17916128475881793 at epoch 2
INFO - 11/06/22 02:52:44 - 0:00:39 - Average dev loss is 0.179459185012289 at epoch 2
INFO - 11/06/22 02:52:45 - 0:00:40 - dev accuracy is 49.3759 at epoch 2
INFO - 11/06/22 02:52:45 - 0:00:40 - dev phenome error rate is 0.1114 at epoch 2
INFO - 11/06/22 02:52:45 - 0:00:40 - At 3-th epoch with lr 0.001000.
INFO - 11/06/22 02:52:56 - 0:00:51 - Running average train loss is 0.15279872497783664 at epoch 3
INFO - 11/06/22 02:52:57 - 0:00:52 - Average dev loss is 0.17758992153245048 at epoch 3
INFO - 11/06/22 02:52:57 - 0:00:52 - dev accuracy is 50.4854 at epoch 3
INFO - 11/06/22 02:52:57 - 0:00:52 - dev phenome error rate is 0.1099 at epoch 3
INFO - 11/06/22 02:52:58 - 0:00:53 - At 4-th epoch with lr 0.001000.
INFO - 11/06/22 02:53:09 - 0:01:04 - Running average train loss is 0.13029586050682274 at epoch 4
INFO - 11/06/22 02:53:09 - 0:01:04 - Average dev loss is 0.16543784586561694 at epoch 4
INFO - 11/06/22 02:53:10 - 0:01:05 - dev accuracy is 53.9528 at epoch 4
INFO - 11/06/22 02:53:10 - 0:01:05 - dev phenome error rate is 0.1025 at epoch 4
INFO - 11/06/22 02:53:10 - 0:01:05 - At 5-th epoch with lr 0.001000.
INFO - 11/06/22 02:53:23 - 0:01:18 - Running average train loss is 0.11130587809199205 at epoch 5
INFO - 11/06/22 02:53:23 - 0:01:18 - Average dev loss is 0.16054316146953687 at epoch 5
INFO - 11/06/22 02:53:24 - 0:01:19 - dev accuracy is 55.8946 at epoch 5
INFO - 11/06/22 02:53:24 - 0:01:19 - dev phenome error rate is 0.1133 at epoch 5
INFO - 11/06/22 02:53:24 - 0:01:19 - At 6-th epoch with lr 0.001000.
INFO - 11/06/22 02:53:37 - 0:01:32 - Running average train loss is 0.09434687788455398 at epoch 6
INFO - 11/06/22 02:53:37 - 0:01:32 - Average dev loss is 0.14890537451247912 at epoch 6
INFO - 11/06/22 02:53:38 - 0:01:33 - dev accuracy is 58.8072 at epoch 6
INFO - 11/06/22 02:53:38 - 0:01:33 - dev phenome error rate is 0.0864 at epoch 6
INFO - 11/06/22 02:53:38 - 0:01:33 - At 7-th epoch with lr 0.001000.
INFO - 11/06/22 02:53:50 - 0:01:45 - Running average train loss is 0.08932627154731311 at epoch 7
INFO - 11/06/22 02:53:50 - 0:01:45 - Average dev loss is 0.15163295796594103 at epoch 7
INFO - 11/06/22 02:53:51 - 0:01:46 - dev accuracy is 58.3911 at epoch 7
INFO - 11/06/22 02:53:51 - 0:01:46 - dev phenome error rate is 0.1024 at epoch 7
INFO - 11/06/22 02:53:52 - 0:01:47 - At 8-th epoch with lr 0.000500.
INFO - 11/06/22 02:54:04 - 0:01:59 - Running average train loss is 0.05956361492227283 at epoch 8
INFO - 11/06/22 02:54:04 - 0:01:59 - Average dev loss is 0.13069133722298854 at epoch 8
INFO - 11/06/22 02:54:05 - 0:02:00 - dev accuracy is 61.9972 at epoch 8
INFO - 11/06/22 02:54:05 - 0:02:00 - dev phenome error rate is 0.0782 at epoch 8
INFO - 11/06/22 02:54:05 - 0:02:00 - At 9-th epoch with lr 0.000500.
INFO - 11/06/22 02:54:17 - 0:02:12 - Running average train loss is 0.0426664213689924 at epoch 9
INFO - 11/06/22 02:54:18 - 0:02:13 - Average dev loss is 0.13677600579890045 at epoch 9
INFO - 11/06/22 02:54:19 - 0:02:14 - dev accuracy is 62.8294 at epoch 9
INFO - 11/06/22 02:54:19 - 0:02:14 - dev phenome error rate is 0.073 at epoch 9
INFO - 11/06/22 02:54:19 - 0:02:14 - At 10-th epoch with lr 0.000250.
INFO - 11/06/22 02:54:31 - 0:02:26 - Running average train loss is 0.0317441023631947 at epoch 10
INFO - 11/06/22 02:54:32 - 0:02:27 - Average dev loss is 0.1291415689362062 at epoch 10
INFO - 11/06/22 02:54:32 - 0:02:27 - dev accuracy is 63.1068 at epoch 10
INFO - 11/06/22 02:54:32 - 0:02:27 - dev phenome error rate is 0.0697 at epoch 10
INFO - 11/06/22 02:54:33 - 0:02:28 - At 11-th epoch with lr 0.000250.
INFO - 11/06/22 02:54:45 - 0:02:40 - Running average train loss is 0.027401037331373414 at epoch 11
INFO - 11/06/22 02:54:45 - 0:02:40 - Average dev loss is 0.13628753848575256 at epoch 11
INFO - 11/06/22 02:54:46 - 0:02:41 - dev accuracy is 63.3842 at epoch 11
INFO - 11/06/22 02:54:46 - 0:02:41 - dev phenome error rate is 0.0704 at epoch 11
INFO - 11/06/22 02:54:46 - 0:02:41 - At 12-th epoch with lr 0.000125.
INFO - 11/06/22 02:54:59 - 0:02:54 - Running average train loss is 0.02283183248439358 at epoch 12
INFO - 11/06/22 02:54:59 - 0:02:54 - Average dev loss is 0.13196483979354034 at epoch 12
INFO - 11/06/22 02:55:00 - 0:02:55 - dev accuracy is 65.4646 at epoch 12
INFO - 11/06/22 02:55:00 - 0:02:55 - dev phenome error rate is 0.0671 at epoch 12
INFO - 11/06/22 02:55:00 - 0:02:55 - At 13-th epoch with lr 0.000063.
INFO - 11/06/22 02:55:12 - 0:03:07 - Running average train loss is 0.02046589551499239 at epoch 13
INFO - 11/06/22 02:55:13 - 0:03:08 - Average dev loss is 0.1308733708149678 at epoch 13
INFO - 11/06/22 02:55:13 - 0:03:08 - dev accuracy is 64.6325 at epoch 13
INFO - 11/06/22 02:55:13 - 0:03:08 - dev phenome error rate is 0.0667 at epoch 13
INFO - 11/06/22 02:55:14 - 0:03:09 - At 14-th epoch with lr 0.000031.
INFO - 11/06/22 02:55:26 - 0:03:21 - Running average train loss is 0.018895192268915884 at epoch 14
INFO - 11/06/22 02:55:26 - 0:03:21 - Average dev loss is 0.1312876386014191 at epoch 14
INFO - 11/06/22 02:55:27 - 0:03:22 - dev accuracy is 65.3259 at epoch 14
INFO - 11/06/22 02:55:27 - 0:03:22 - dev phenome error rate is 0.067 at epoch 14
INFO - 11/06/22 02:55:27 - 0:03:22 - At 15-th epoch with lr 0.000016.
INFO - 11/06/22 02:55:39 - 0:03:34 - Running average train loss is 0.018016842651706576 at epoch 15
INFO - 11/06/22 02:55:40 - 0:03:35 - Average dev loss is 0.1318281533548961 at epoch 15
INFO - 11/06/22 02:55:41 - 0:03:36 - dev accuracy is 66.1581 at epoch 15
INFO - 11/06/22 02:55:41 - 0:03:36 - dev phenome error rate is 0.0649 at epoch 15
INFO - 11/06/22 02:55:41 - 0:03:36 - At 16-th epoch with lr 0.000010.
INFO - 11/06/22 02:55:53 - 0:03:48 - Running average train loss is 0.017946543198070302 at epoch 16
INFO - 11/06/22 02:55:53 - 0:03:48 - Average dev loss is 0.1319708857383277 at epoch 16
INFO - 11/06/22 02:55:54 - 0:03:49 - dev accuracy is 65.8807 at epoch 16
INFO - 11/06/22 02:55:54 - 0:03:49 - dev phenome error rate is 0.0648 at epoch 16
INFO - 11/06/22 02:55:54 - 0:03:49 - Early stopping triggered with epoch 16 (previous dev loss: 0.131828, current: 0.131971)
INFO - 11/06/22 02:55:54 - 0:03:49 - loading model/test2/dropout/large/test0.2/ndebele.nll_0.1318.acc_66.1581.per_0.0649.epoch_15 for testing
INFO - 11/06/22 02:55:54 - 0:03:49 - load model in model/test2/dropout/large/test0.2/ndebele.nll_0.1318.acc_66.1581.per_0.0649.epoch_15
INFO - 11/06/22 02:55:54 - 0:03:49 - Average dev loss is 0.13182815103917508 at epoch -1
INFO - 11/06/22 02:55:54 - 0:03:49 - decoding dev set
INFO - 11/06/22 02:55:56 - 0:03:51 - finished decoding 723 dev instance
INFO - 11/06/22 02:55:56 - 0:03:51 - DEV accuracy is 66.1581 at epoch -1
INFO - 11/06/22 02:55:56 - 0:03:51 - DEV phenome error rate is 0.0649 at epoch -1
INFO - 11/06/22 02:55:56 - 0:03:51 - DEV ndebele acc 66.1581 per 0.0649
INFO - 11/06/22 02:55:57 - 0:03:52 - Average test loss is 0.2994491386343725 at epoch -1
INFO - 11/06/22 02:55:57 - 0:03:52 - decoding test set
INFO - 11/06/22 02:56:01 - 0:03:56 - finished decoding 2552 test instance
INFO - 11/06/22 02:56:01 - 0:03:56 - TEST accuracy is 51.6842 at epoch -1
INFO - 11/06/22 02:56:01 - 0:03:56 - TEST phenome error rate is 0.1109 at epoch -1
INFO - 11/06/22 02:56:01 - 0:03:56 - TEST ndebele acc 51.6842 per 0.1109
