INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: seed - 0
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: train - ['data2/swati/swati.train']
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: dev - ['data2/swati/swati.dev']
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: test - ['data2/swati/swati.test']
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: model - 'model/test2/dropout/small/test0.1/swati'
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: load - ''
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: bs - 20
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: epochs - 50
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: max_steps - 0
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: total_eval - -1
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: lr - 0.001
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: momentum - 0.9
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: estop - 1e-08
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: cooldown - 0
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: patience - 0
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: max_norm - 0
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: gpuid - [0]
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: saveall - False
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: shuffle - False
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: cleanup_anyway - True
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: init - 'init/test/large/seed-0/swati'
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: dropout - 0.1
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: embed_dim - 100
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: nb_heads - 4
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: src_layer - 1
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: trg_layer - 1
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: src_hs - 200
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: trg_hs - 200
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: nb_sample - 2
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: wid_siz - 11
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: indtag - False
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: mono - False
INFO - 11/06/22 03:31:37 - 0:00:00 - command line argument: bestacc - False
INFO - 11/06/22 03:31:37 - 0:00:00 - src vocab size 69
INFO - 11/06/22 03:31:37 - 0:00:00 - trg vocab size 70
INFO - 11/06/22 03:31:37 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 11/06/22 03:31:37 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 11/06/22 03:31:37 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(69, 100, padding_idx=0)
                                       (trg_embed): Embedding(70, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.1, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.1, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=70, bias=True)
                                       (dropout): Dropout(p=0.1, inplace=False)
                                     )
INFO - 11/06/22 03:31:37 - 0:00:00 - number of parameter 1221570
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: seed - 0
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: train - ['data2/swati/swati.train']
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: dev - ['data2/swati/swati.dev']
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: test - ['data2/swati/swati.test']
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: model - 'model/test2/dropout/small/test0.1/swati'
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: load - ''
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: bs - 20
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: epochs - 50
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: max_steps - 0
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: total_eval - -1
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: lr - 0.001
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: momentum - 0.9
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: estop - 1e-08
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: cooldown - 0
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: patience - 0
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: max_norm - 0
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: gpuid - [0]
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: saveall - False
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: shuffle - False
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: cleanup_anyway - True
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: init - ''
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: dropout - 0.1
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: embed_dim - 100
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: nb_heads - 4
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: src_layer - 1
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: trg_layer - 1
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: src_hs - 200
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: trg_hs - 200
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: nb_sample - 2
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: wid_siz - 11
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: indtag - False
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: mono - False
INFO - 11/06/22 16:38:23 - 0:00:00 - command line argument: bestacc - False
INFO - 11/06/22 16:38:23 - 0:00:00 - src vocab size 69
INFO - 11/06/22 16:38:23 - 0:00:00 - trg vocab size 70
INFO - 11/06/22 16:38:23 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 11/06/22 16:38:23 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '&', "'", '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 11/06/22 16:38:23 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(69, 100, padding_idx=0)
                                       (trg_embed): Embedding(70, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.1, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.1, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=70, bias=True)
                                       (dropout): Dropout(p=0.1, inplace=False)
                                     )
INFO - 11/06/22 16:38:23 - 0:00:00 - number of parameter 1221570
INFO - 11/06/22 16:38:25 - 0:00:03 - maximum training 8550 steps (50 epochs)
INFO - 11/06/22 16:38:25 - 0:00:03 - evaluate every 1 epochs
INFO - 11/06/22 16:38:25 - 0:00:03 - At 0-th epoch with lr 0.001000.
INFO - 11/06/22 16:38:30 - 0:00:07 - Running average train loss is 0.9675608744398195 at epoch 0
INFO - 11/06/22 16:38:30 - 0:00:07 - At 1-th epoch with lr 0.001000.
INFO - 11/06/22 16:38:34 - 0:00:12 - Running average train loss is 0.17663866573432732 at epoch 1
INFO - 11/06/22 16:38:34 - 0:00:12 - Average dev loss is 0.12207985669374466 at epoch 1
INFO - 11/06/22 16:38:35 - 0:00:12 - dev accuracy is 68.3377 at epoch 1
INFO - 11/06/22 16:38:35 - 0:00:12 - dev phenome error rate is 0.0619 at epoch 1
INFO - 11/06/22 16:38:35 - 0:00:12 - At 2-th epoch with lr 0.001000.
INFO - 11/06/22 16:38:39 - 0:00:16 - Running average train loss is 0.1214738819334242 at epoch 2
INFO - 11/06/22 16:38:39 - 0:00:16 - Average dev loss is 0.10278760171250294 at epoch 2
INFO - 11/06/22 16:38:40 - 0:00:17 - dev accuracy is 73.8786 at epoch 2
INFO - 11/06/22 16:38:40 - 0:00:17 - dev phenome error rate is 0.0522 at epoch 2
INFO - 11/06/22 16:38:40 - 0:00:17 - At 3-th epoch with lr 0.001000.
INFO - 11/06/22 16:38:44 - 0:00:21 - Running average train loss is 0.09155956842005253 at epoch 3
INFO - 11/06/22 16:38:44 - 0:00:21 - Average dev loss is 0.09291873989920867 at epoch 3
INFO - 11/06/22 16:38:44 - 0:00:22 - dev accuracy is 75.7256 at epoch 3
INFO - 11/06/22 16:38:44 - 0:00:22 - dev phenome error rate is 0.0434 at epoch 3
INFO - 11/06/22 16:38:44 - 0:00:22 - At 4-th epoch with lr 0.001000.
INFO - 11/06/22 16:38:49 - 0:00:26 - Running average train loss is 0.07600970181761778 at epoch 4
INFO - 11/06/22 16:38:49 - 0:00:26 - Average dev loss is 0.10236997274976027 at epoch 4
INFO - 11/06/22 16:38:49 - 0:00:26 - dev accuracy is 77.0449 at epoch 4
INFO - 11/06/22 16:38:49 - 0:00:26 - dev phenome error rate is 0.0443 at epoch 4
INFO - 11/06/22 16:38:49 - 0:00:26 - At 5-th epoch with lr 0.000500.
INFO - 11/06/22 16:38:54 - 0:00:31 - Running average train loss is 0.05308518321280591 at epoch 5
INFO - 11/06/22 16:38:54 - 0:00:31 - Average dev loss is 0.0790715412677903 at epoch 5
INFO - 11/06/22 16:38:54 - 0:00:31 - dev accuracy is 80.2111 at epoch 5
INFO - 11/06/22 16:38:54 - 0:00:31 - dev phenome error rate is 0.0406 at epoch 5
INFO - 11/06/22 16:38:54 - 0:00:31 - At 6-th epoch with lr 0.000500.
INFO - 11/06/22 16:38:58 - 0:00:36 - Running average train loss is 0.03942528328373592 at epoch 6
INFO - 11/06/22 16:38:59 - 0:00:36 - Average dev loss is 0.07978327131192935 at epoch 6
INFO - 11/06/22 16:38:59 - 0:00:36 - dev accuracy is 80.4749 at epoch 6
INFO - 11/06/22 16:38:59 - 0:00:36 - dev phenome error rate is 0.04 at epoch 6
INFO - 11/06/22 16:38:59 - 0:00:36 - At 7-th epoch with lr 0.000250.
INFO - 11/06/22 16:39:03 - 0:00:41 - Running average train loss is 0.029489883379629482 at epoch 7
INFO - 11/06/22 16:39:03 - 0:00:41 - Average dev loss is 0.07802989627969892 at epoch 7
INFO - 11/06/22 16:39:04 - 0:00:41 - dev accuracy is 81.5303 at epoch 7
INFO - 11/06/22 16:39:04 - 0:00:41 - dev phenome error rate is 0.0384 at epoch 7
INFO - 11/06/22 16:39:04 - 0:00:41 - At 8-th epoch with lr 0.000250.
INFO - 11/06/22 16:39:08 - 0:00:45 - Running average train loss is 0.02573534007026264 at epoch 8
INFO - 11/06/22 16:39:08 - 0:00:45 - Average dev loss is 0.07764310174082455 at epoch 8
INFO - 11/06/22 16:39:09 - 0:00:46 - dev accuracy is 83.3773 at epoch 8
INFO - 11/06/22 16:39:09 - 0:00:46 - dev phenome error rate is 0.0359 at epoch 8
INFO - 11/06/22 16:39:09 - 0:00:46 - At 9-th epoch with lr 0.000250.
INFO - 11/06/22 16:39:13 - 0:00:50 - Running average train loss is 0.023454020727066358 at epoch 9
INFO - 11/06/22 16:39:13 - 0:00:50 - Average dev loss is 0.07788191657317312 at epoch 9
INFO - 11/06/22 16:39:13 - 0:00:51 - dev accuracy is 82.3219 at epoch 9
INFO - 11/06/22 16:39:13 - 0:00:51 - dev phenome error rate is 0.0383 at epoch 9
INFO - 11/06/22 16:39:13 - 0:00:51 - At 10-th epoch with lr 0.000125.
INFO - 11/06/22 16:39:18 - 0:00:55 - Running average train loss is 0.019463941652997675 at epoch 10
INFO - 11/06/22 16:39:18 - 0:00:55 - Average dev loss is 0.07590809238976554 at epoch 10
INFO - 11/06/22 16:39:18 - 0:00:55 - dev accuracy is 83.3773 at epoch 10
INFO - 11/06/22 16:39:18 - 0:00:55 - dev phenome error rate is 0.0351 at epoch 10
INFO - 11/06/22 16:39:18 - 0:00:55 - At 11-th epoch with lr 0.000125.
INFO - 11/06/22 16:39:23 - 0:01:00 - Running average train loss is 0.01915911789602268 at epoch 11
INFO - 11/06/22 16:39:23 - 0:01:00 - Average dev loss is 0.07659476201393102 at epoch 11
INFO - 11/06/22 16:39:23 - 0:01:00 - dev accuracy is 83.3773 at epoch 11
INFO - 11/06/22 16:39:23 - 0:01:00 - dev phenome error rate is 0.0354 at epoch 11
INFO - 11/06/22 16:39:23 - 0:01:00 - At 12-th epoch with lr 0.000063.
INFO - 11/06/22 16:39:27 - 0:01:05 - Running average train loss is 0.017305697276316888 at epoch 12
INFO - 11/06/22 16:39:28 - 0:01:05 - Average dev loss is 0.07637938739437806 at epoch 12
INFO - 11/06/22 16:39:28 - 0:01:05 - dev accuracy is 83.1135 at epoch 12
INFO - 11/06/22 16:39:28 - 0:01:05 - dev phenome error rate is 0.0356 at epoch 12
INFO - 11/06/22 16:39:28 - 0:01:05 - At 13-th epoch with lr 0.000031.
INFO - 11/06/22 16:39:32 - 0:01:09 - Running average train loss is 0.016008413835205355 at epoch 13
INFO - 11/06/22 16:39:32 - 0:01:10 - Average dev loss is 0.0762639063361444 at epoch 13
INFO - 11/06/22 16:39:33 - 0:01:10 - dev accuracy is 83.1135 at epoch 13
INFO - 11/06/22 16:39:33 - 0:01:10 - dev phenome error rate is 0.0356 at epoch 13
INFO - 11/06/22 16:39:33 - 0:01:10 - At 14-th epoch with lr 0.000016.
INFO - 11/06/22 16:39:37 - 0:01:14 - Running average train loss is 0.015563331657751022 at epoch 14
INFO - 11/06/22 16:39:37 - 0:01:14 - Average dev loss is 0.0765861204188121 at epoch 14
INFO - 11/06/22 16:39:37 - 0:01:15 - dev accuracy is 83.3773 at epoch 14
INFO - 11/06/22 16:39:37 - 0:01:15 - dev phenome error rate is 0.0347 at epoch 14
INFO - 11/06/22 16:39:38 - 0:01:15 - At 15-th epoch with lr 0.000010.
INFO - 11/06/22 16:39:42 - 0:01:19 - Running average train loss is 0.014986468142726354 at epoch 15
INFO - 11/06/22 16:39:42 - 0:01:19 - Average dev loss is 0.07669319192829885 at epoch 15
INFO - 11/06/22 16:39:42 - 0:01:19 - dev accuracy is 83.6412 at epoch 15
INFO - 11/06/22 16:39:42 - 0:01:19 - dev phenome error rate is 0.0337 at epoch 15
INFO - 11/06/22 16:39:42 - 0:01:19 - Early stopping triggered with epoch 15 (previous dev loss: 0.076586, current: 0.076693)
INFO - 11/06/22 16:39:42 - 0:01:19 - loading model/test2/dropout/small/test0.1/swati.nll_0.0766.acc_83.3773.per_0.0347.epoch_14 for testing
INFO - 11/06/22 16:39:42 - 0:01:19 - load model in model/test2/dropout/small/test0.1/swati.nll_0.0766.acc_83.3773.per_0.0347.epoch_14
INFO - 11/06/22 16:39:42 - 0:01:20 - Average dev loss is 0.0765861204188121 at epoch -1
INFO - 11/06/22 16:39:42 - 0:01:20 - decoding dev set
INFO - 11/06/22 16:39:43 - 0:01:20 - finished decoding 379 dev instance
INFO - 11/06/22 16:39:43 - 0:01:20 - DEV accuracy is 83.3773 at epoch -1
INFO - 11/06/22 16:39:43 - 0:01:20 - DEV phenome error rate is 0.0347 at epoch -1
INFO - 11/06/22 16:39:43 - 0:01:20 - DEV swati acc 83.3773 per 0.0347
INFO - 11/06/22 16:39:45 - 0:01:22 - Average test loss is 0.28755361222866793 at epoch -1
INFO - 11/06/22 16:39:45 - 0:01:22 - decoding test set
INFO - 11/06/22 16:39:50 - 0:01:27 - finished decoding 5639 test instance
INFO - 11/06/22 16:39:50 - 0:01:27 - TEST accuracy is 70.2778 at epoch -1
INFO - 11/06/22 16:39:50 - 0:01:27 - TEST phenome error rate is 0.0595 at epoch -1
INFO - 11/06/22 16:39:50 - 0:01:27 - TEST swati acc 70.2778 per 0.0595
