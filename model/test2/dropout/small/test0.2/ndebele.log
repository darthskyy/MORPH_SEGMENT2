INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: seed - 0
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: train - ['data2/ndebele/ndebele.train']
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: dev - ['data2/ndebele/ndebele.dev']
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: test - ['data2/ndebele/ndebele.test']
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: model - 'model/test2/dropout/small/test0.2/ndebele'
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: load - ''
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: bs - 20
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: epochs - 50
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: max_steps - 0
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: total_eval - -1
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: lr - 0.001
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: momentum - 0.9
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: estop - 1e-08
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: cooldown - 0
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: patience - 0
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: max_norm - 0
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: gpuid - [0]
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: saveall - False
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: shuffle - False
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: cleanup_anyway - True
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: init - ''
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: dropout - 0.2
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: embed_dim - 100
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: nb_heads - 4
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: src_layer - 1
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: trg_layer - 1
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: src_hs - 200
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: trg_hs - 200
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: nb_sample - 2
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: wid_siz - 11
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: indtag - False
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: mono - False
INFO - 11/06/22 16:34:51 - 0:00:00 - command line argument: bestacc - False
INFO - 11/06/22 16:34:51 - 0:00:00 - src vocab size 68
INFO - 11/06/22 16:34:51 - 0:00:00 - trg vocab size 66
INFO - 11/06/22 16:34:51 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 11/06/22 16:34:51 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', "'", '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 11/06/22 16:34:51 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(68, 100, padding_idx=0)
                                       (trg_embed): Embedding(66, 100, padding_idx=0)
                                       (enc_rnn): LSTM(100, 200, dropout=0.2, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(100, 200)
                                         )
                                         (dropout): Dropout(p=0.2, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.2, inplace=False)
                                     )
INFO - 11/06/22 16:34:51 - 0:00:00 - number of parameter 1218666
INFO - 11/06/22 16:34:54 - 0:00:03 - maximum training 16300 steps (50 epochs)
INFO - 11/06/22 16:34:54 - 0:00:03 - evaluate every 1 epochs
INFO - 11/06/22 16:34:54 - 0:00:03 - At 0-th epoch with lr 0.001000.
INFO - 11/06/22 16:35:03 - 0:00:12 - Running average train loss is 0.706365633870195 at epoch 0
INFO - 11/06/22 16:35:03 - 0:00:12 - At 1-th epoch with lr 0.001000.
INFO - 11/06/22 16:35:12 - 0:00:21 - Running average train loss is 0.22674167613310317 at epoch 1
INFO - 11/06/22 16:35:12 - 0:00:21 - Average dev loss is 0.18945226194085302 at epoch 1
INFO - 11/06/22 16:35:13 - 0:00:22 - dev accuracy is 44.9376 at epoch 1
INFO - 11/06/22 16:35:13 - 0:00:22 - dev phenome error rate is 0.1238 at epoch 1
INFO - 11/06/22 16:35:13 - 0:00:22 - At 2-th epoch with lr 0.001000.
INFO - 11/06/22 16:35:22 - 0:00:31 - Running average train loss is 0.17142724829720207 at epoch 2
INFO - 11/06/22 16:35:22 - 0:00:31 - Average dev loss is 0.1584527649589487 at epoch 2
INFO - 11/06/22 16:35:23 - 0:00:32 - dev accuracy is 49.5146 at epoch 2
INFO - 11/06/22 16:35:23 - 0:00:32 - dev phenome error rate is 0.1148 at epoch 2
INFO - 11/06/22 16:35:23 - 0:00:32 - At 3-th epoch with lr 0.001000.
INFO - 11/06/22 16:35:31 - 0:00:41 - Running average train loss is 0.13909596284748588 at epoch 3
INFO - 11/06/22 16:35:32 - 0:00:41 - Average dev loss is 0.14314351532910322 at epoch 3
INFO - 11/06/22 16:35:32 - 0:00:42 - dev accuracy is 55.7559 at epoch 3
INFO - 11/06/22 16:35:32 - 0:00:42 - dev phenome error rate is 0.0962 at epoch 3
INFO - 11/06/22 16:35:32 - 0:00:42 - At 4-th epoch with lr 0.001000.
INFO - 11/06/22 16:35:41 - 0:00:50 - Running average train loss is 0.12426199732016932 at epoch 4
INFO - 11/06/22 16:35:42 - 0:00:51 - Average dev loss is 0.13461096121652708 at epoch 4
INFO - 11/06/22 16:35:42 - 0:00:51 - dev accuracy is 58.1137 at epoch 4
INFO - 11/06/22 16:35:42 - 0:00:51 - dev phenome error rate is 0.0911 at epoch 4
INFO - 11/06/22 16:35:42 - 0:00:51 - At 5-th epoch with lr 0.001000.
INFO - 11/06/22 16:35:51 - 0:01:00 - Running average train loss is 0.11085540296201325 at epoch 5
INFO - 11/06/22 16:35:52 - 0:01:01 - Average dev loss is 0.13380160887499112 at epoch 5
INFO - 11/06/22 16:35:52 - 0:01:01 - dev accuracy is 57.2816 at epoch 5
INFO - 11/06/22 16:35:52 - 0:01:01 - dev phenome error rate is 0.0929 at epoch 5
INFO - 11/06/22 16:35:52 - 0:01:01 - At 6-th epoch with lr 0.001000.
INFO - 11/06/22 16:36:01 - 0:01:10 - Running average train loss is 0.09750924256567392 at epoch 6
INFO - 11/06/22 16:36:01 - 0:01:11 - Average dev loss is 0.1325038101624798 at epoch 6
INFO - 11/06/22 16:36:02 - 0:01:11 - dev accuracy is 61.165 at epoch 6
INFO - 11/06/22 16:36:02 - 0:01:11 - dev phenome error rate is 0.0842 at epoch 6
INFO - 11/06/22 16:36:02 - 0:01:11 - At 7-th epoch with lr 0.001000.
INFO - 11/06/22 16:36:11 - 0:01:20 - Running average train loss is 0.08723833493636979 at epoch 7
INFO - 11/06/22 16:36:11 - 0:01:20 - Average dev loss is 0.1267020676184345 at epoch 7
INFO - 11/06/22 16:36:12 - 0:01:21 - dev accuracy is 62.6907 at epoch 7
INFO - 11/06/22 16:36:12 - 0:01:21 - dev phenome error rate is 0.0759 at epoch 7
INFO - 11/06/22 16:36:12 - 0:01:21 - At 8-th epoch with lr 0.001000.
INFO - 11/06/22 16:36:21 - 0:01:30 - Running average train loss is 0.07616014906599478 at epoch 8
INFO - 11/06/22 16:36:21 - 0:01:30 - Average dev loss is 0.1427073415268112 at epoch 8
INFO - 11/06/22 16:36:22 - 0:01:31 - dev accuracy is 61.8585 at epoch 8
INFO - 11/06/22 16:36:22 - 0:01:31 - dev phenome error rate is 0.0819 at epoch 8
INFO - 11/06/22 16:36:22 - 0:01:31 - At 9-th epoch with lr 0.000500.
INFO - 11/06/22 16:36:31 - 0:01:40 - Running average train loss is 0.057682374052337705 at epoch 9
INFO - 11/06/22 16:36:31 - 0:01:40 - Average dev loss is 0.12332118765727894 at epoch 9
INFO - 11/06/22 16:36:32 - 0:01:41 - dev accuracy is 65.0485 at epoch 9
INFO - 11/06/22 16:36:32 - 0:01:41 - dev phenome error rate is 0.0723 at epoch 9
INFO - 11/06/22 16:36:32 - 0:01:41 - At 10-th epoch with lr 0.000500.
INFO - 11/06/22 16:36:41 - 0:01:50 - Running average train loss is 0.048791656336330015 at epoch 10
INFO - 11/06/22 16:36:41 - 0:01:50 - Average dev loss is 0.12006671334037909 at epoch 10
INFO - 11/06/22 16:36:41 - 0:01:51 - dev accuracy is 65.0485 at epoch 10
INFO - 11/06/22 16:36:41 - 0:01:51 - dev phenome error rate is 0.0707 at epoch 10
INFO - 11/06/22 16:36:41 - 0:01:51 - At 11-th epoch with lr 0.000500.
INFO - 11/06/22 16:36:50 - 0:01:59 - Running average train loss is 0.045600461747862996 at epoch 11
INFO - 11/06/22 16:36:51 - 0:02:00 - Average dev loss is 0.1257883649621461 at epoch 11
INFO - 11/06/22 16:36:51 - 0:02:00 - dev accuracy is 65.3259 at epoch 11
INFO - 11/06/22 16:36:51 - 0:02:00 - dev phenome error rate is 0.0723 at epoch 11
INFO - 11/06/22 16:36:51 - 0:02:00 - At 12-th epoch with lr 0.000250.
INFO - 11/06/22 16:37:00 - 0:02:09 - Running average train loss is 0.03828063456090224 at epoch 12
INFO - 11/06/22 16:37:00 - 0:02:10 - Average dev loss is 0.12056602014077676 at epoch 12
INFO - 11/06/22 16:37:01 - 0:02:10 - dev accuracy is 65.8807 at epoch 12
INFO - 11/06/22 16:37:01 - 0:02:10 - dev phenome error rate is 0.0722 at epoch 12
INFO - 11/06/22 16:37:01 - 0:02:10 - At 13-th epoch with lr 0.000125.
INFO - 11/06/22 16:37:10 - 0:02:19 - Running average train loss is 0.033572926723106876 at epoch 13
INFO - 11/06/22 16:37:10 - 0:02:19 - Average dev loss is 0.11895664428939691 at epoch 13
INFO - 11/06/22 16:37:11 - 0:02:20 - dev accuracy is 65.8807 at epoch 13
INFO - 11/06/22 16:37:11 - 0:02:20 - dev phenome error rate is 0.0713 at epoch 13
INFO - 11/06/22 16:37:11 - 0:02:20 - At 14-th epoch with lr 0.000125.
