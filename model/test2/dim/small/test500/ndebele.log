INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: seed - 0
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: train - ['data2/ndebele/ndebele.train']
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: dev - ['data2/ndebele/ndebele.dev']
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: test - ['data2/ndebele/ndebele.test']
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: model - 'model/test2/dim/small/test500/ndebele'
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: load - ''
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: bs - 20
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: epochs - 50
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: max_steps - 0
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: warmup_steps - 4000
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: total_eval - -1
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: optimizer - <Optimizer.adam: 'adam'>
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: scheduler - <Scheduler.reducewhenstuck: 'reducewhenstuck'>
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: lr - 0.001
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: min_lr - 1e-05
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: momentum - 0.9
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: beta1 - 0.9
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: beta2 - 0.999
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: estop - 1e-08
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: cooldown - 0
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: patience - 0
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: discount_factor - 0.5
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: max_norm - 0
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: gpuid - [0]
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: loglevel - 'info'
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: saveall - False
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: shuffle - False
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: cleanup_anyway - True
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: dataset - <Data.g2p: 'g2p'>
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: max_seq_len - 128
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: max_decode_len - 128
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: decode_beam_size - 5
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: init - ''
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: dropout - 0.5
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: embed_dim - 500
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: nb_heads - 4
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: src_layer - 1
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: trg_layer - 1
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: src_hs - 200
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: trg_hs - 200
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: label_smooth - 0.0
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: tie_trg_embed - False
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: arch - <Arch.hard: 'hard'>
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: nb_sample - 2
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: wid_siz - 11
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: indtag - False
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: decode - <Decode.greedy: 'greedy'>
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: mono - False
INFO - 11/07/22 11:04:29 - 0:00:00 - command line argument: bestacc - False
INFO - 11/07/22 11:04:29 - 0:00:00 - src vocab size 68
INFO - 11/07/22 11:04:29 - 0:00:00 - trg vocab size 66
INFO - 11/07/22 11:04:29 - 0:00:00 - src vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 11/07/22 11:04:29 - 0:00:00 - trg vocab ['<PAD>', '<BOS>', '<EOS>', '<UNK>', '%', "'", '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']
INFO - 11/07/22 11:04:29 - 0:00:00 - model: HardAttnTransducer(
                                       (src_embed): Embedding(68, 500, padding_idx=0)
                                       (trg_embed): Embedding(66, 500, padding_idx=0)
                                       (enc_rnn): LSTM(500, 200, dropout=0.5, bidirectional=True)
                                       (dec_rnn): StackedLSTM(
                                         (layers): ModuleList(
                                           (0): LSTMCell(500, 200)
                                         )
                                         (dropout): Dropout(p=0.5, inplace=False)
                                       )
                                       (scale_enc_hs): Linear(in_features=400, out_features=200, bias=True)
                                       (attn): Attention()
                                       (linear_out): Linear(in_features=600, out_features=600, bias=True)
                                       (final_out): Linear(in_features=600, out_features=66, bias=True)
                                       (dropout): Dropout(p=0.5, inplace=False)
                                     )
INFO - 11/07/22 11:04:29 - 0:00:00 - number of parameter 2232266
INFO - 11/07/22 11:04:32 - 0:00:03 - maximum training 16300 steps (50 epochs)
INFO - 11/07/22 11:04:32 - 0:00:03 - evaluate every 1 epochs
INFO - 11/07/22 11:04:32 - 0:00:03 - At 0-th epoch with lr 0.001000.
INFO - 11/07/22 11:04:42 - 0:00:13 - Running average train loss is 0.8434078600600453 at epoch 0
INFO - 11/07/22 11:04:42 - 0:00:13 - At 1-th epoch with lr 0.001000.
INFO - 11/07/22 11:04:51 - 0:00:22 - Running average train loss is 0.3238340966814866 at epoch 1
INFO - 11/07/22 11:04:52 - 0:00:22 - Average dev loss is 0.23350267293485436 at epoch 1
INFO - 11/07/22 11:04:52 - 0:00:23 - dev accuracy is 40.638 at epoch 1
INFO - 11/07/22 11:04:52 - 0:00:23 - dev phenome error rate is 0.1354 at epoch 1
INFO - 11/07/22 11:04:52 - 0:00:23 - At 2-th epoch with lr 0.001000.
INFO - 11/07/22 11:05:01 - 0:00:32 - Running average train loss is 0.26136663059012655 at epoch 2
INFO - 11/07/22 11:05:02 - 0:00:32 - Average dev loss is 0.21349844537876747 at epoch 2
INFO - 11/07/22 11:05:02 - 0:00:33 - dev accuracy is 43.9667 at epoch 2
INFO - 11/07/22 11:05:02 - 0:00:33 - dev phenome error rate is 0.1331 at epoch 2
INFO - 11/07/22 11:05:02 - 0:00:33 - At 3-th epoch with lr 0.001000.
INFO - 11/07/22 11:05:12 - 0:00:42 - Running average train loss is 0.2268103072019808 at epoch 3
INFO - 11/07/22 11:05:12 - 0:00:43 - Average dev loss is 0.19303736130933505 at epoch 3
INFO - 11/07/22 11:05:12 - 0:00:43 - dev accuracy is 45.6311 at epoch 3
INFO - 11/07/22 11:05:12 - 0:00:43 - dev phenome error rate is 0.1326 at epoch 3
INFO - 11/07/22 11:05:13 - 0:00:43 - At 4-th epoch with lr 0.001000.
INFO - 11/07/22 11:05:22 - 0:00:52 - Running average train loss is 0.208387876569402 at epoch 4
INFO - 11/07/22 11:05:22 - 0:00:53 - Average dev loss is 0.1879717085409809 at epoch 4
INFO - 11/07/22 11:05:23 - 0:00:53 - dev accuracy is 46.6019 at epoch 4
INFO - 11/07/22 11:05:23 - 0:00:53 - dev phenome error rate is 0.1247 at epoch 4
INFO - 11/07/22 11:05:23 - 0:00:53 - At 5-th epoch with lr 0.001000.
INFO - 11/07/22 11:05:32 - 0:01:03 - Running average train loss is 0.1917856697427349 at epoch 5
INFO - 11/07/22 11:05:32 - 0:01:03 - Average dev loss is 0.1743026395907273 at epoch 5
INFO - 11/07/22 11:05:33 - 0:01:04 - dev accuracy is 49.2372 at epoch 5
INFO - 11/07/22 11:05:33 - 0:01:04 - dev phenome error rate is 0.1194 at epoch 5
INFO - 11/07/22 11:05:33 - 0:01:04 - At 6-th epoch with lr 0.001000.
INFO - 11/07/22 11:05:42 - 0:01:13 - Running average train loss is 0.17463692567922587 at epoch 6
INFO - 11/07/22 11:05:42 - 0:01:13 - Average dev loss is 0.16820865124464035 at epoch 6
INFO - 11/07/22 11:05:43 - 0:01:14 - dev accuracy is 48.2663 at epoch 6
INFO - 11/07/22 11:05:43 - 0:01:14 - dev phenome error rate is 0.1045 at epoch 6
INFO - 11/07/22 11:05:43 - 0:01:14 - At 7-th epoch with lr 0.001000.
INFO - 11/07/22 11:05:52 - 0:01:23 - Running average train loss is 0.16524988248304356 at epoch 7
INFO - 11/07/22 11:05:52 - 0:01:23 - Average dev loss is 0.1637359460866129 at epoch 7
INFO - 11/07/22 11:05:53 - 0:01:24 - dev accuracy is 49.792 at epoch 7
INFO - 11/07/22 11:05:53 - 0:01:24 - dev phenome error rate is 0.1069 at epoch 7
INFO - 11/07/22 11:05:53 - 0:01:24 - At 8-th epoch with lr 0.001000.
INFO - 11/07/22 11:06:02 - 0:01:33 - Running average train loss is 0.15952602413945768 at epoch 8
INFO - 11/07/22 11:06:03 - 0:01:33 - Average dev loss is 0.1607406352822845 at epoch 8
INFO - 11/07/22 11:06:03 - 0:01:34 - dev accuracy is 53.5368 at epoch 8
INFO - 11/07/22 11:06:03 - 0:01:34 - dev phenome error rate is 0.1019 at epoch 8
INFO - 11/07/22 11:06:03 - 0:01:34 - At 9-th epoch with lr 0.001000.
INFO - 11/07/22 11:06:12 - 0:01:43 - Running average train loss is 0.15187785091118577 at epoch 9
INFO - 11/07/22 11:06:13 - 0:01:43 - Average dev loss is 0.16055999051880193 at epoch 9
INFO - 11/07/22 11:06:13 - 0:01:44 - dev accuracy is 52.4272 at epoch 9
INFO - 11/07/22 11:06:13 - 0:01:44 - dev phenome error rate is 0.0968 at epoch 9
INFO - 11/07/22 11:06:13 - 0:01:44 - At 10-th epoch with lr 0.001000.
INFO - 11/07/22 11:06:22 - 0:01:53 - Running average train loss is 0.14387682080840222 at epoch 10
INFO - 11/07/22 11:06:23 - 0:01:54 - Average dev loss is 0.15114602013616948 at epoch 10
INFO - 11/07/22 11:06:23 - 0:01:54 - dev accuracy is 53.3981 at epoch 10
INFO - 11/07/22 11:06:23 - 0:01:54 - dev phenome error rate is 0.1021 at epoch 10
INFO - 11/07/22 11:06:23 - 0:01:54 - At 11-th epoch with lr 0.001000.
INFO - 11/07/22 11:06:33 - 0:02:03 - Running average train loss is 0.13638839860406757 at epoch 11
INFO - 11/07/22 11:06:33 - 0:02:04 - Average dev loss is 0.15064714728174983 at epoch 11
